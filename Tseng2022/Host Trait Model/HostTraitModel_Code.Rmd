---
title: "Orthopoxvirus Host-Trait Model Code"
author: "Katie Tseng, Dan Becker, Colin Carlson, Pilar Fernandez, and Stephanie Seifer"
output:
  pdf_document:
  latex_engine: xelatex
  toc: yes
html_document:
  fig_height: 6
  fig_width: 6
  highlight: tango
  theme: journal
editor_options: 
  chunk_output_type: console
---

Introduction
============  

The following code reproduces the analyses from <...>, pertaining to the host-trait model - the model trained on host traits alone. The code is subdivided into seven parts (see Table of Contents below). To reproduce the analyses pertaining to the link prediction model, please see the markdown file *LinkPrediction_Code.Rmd* located in the [PoxHost repository][1].

To run the following script, three files are required in your working directory:

- *Data_raw.RData*: the raw data file  
- *~/Output/*: folder where all output (e.g., cleaned datasets, model results, figures, and tables) will be saved  
- *MAMMALS.shp*: the shape file of mammal geographical range  
    - Obtained[IUCN Red List Spatial Database][2]  
    - This file (>1GB) is only required in part six: *Mapping Host Distribution*  

[1]: <https://github.com/viralemergence/PoxHost> "PoxHost"
[2]: <https://www.iucnredlist.org/resources/spatial-data-download> "Spatial data download"

Table of Contents
=================

1. Data Preparation {r prep}

2. Phylogenetic Analysis {r phylo}

3. BRT Model {r brt}

4. Model Performance {r perf}

5. Model Predictions {r pred}

6. Mapping Host Distribution {r map}

7. Feature Importance {r feat}

### *Before proceeding, we recommend setting knit options* and your working directory**

```{r knitr}

knitr::opts_chunk$set(eval=F)

```

1. Data Preparation
===================

### *Load required packages and set system*

```{r prep_load}

# Libraries for preparing data for analysis
library(ape)
library(dplyr)
library(nlme)
library(tidyverse)
library(stringr)
library(vroom) 
## treespace dependencies include XQuartz v2.7.11 (https://www.xquartz.org/releases/XQuartz-2.7.11.html) and 'rgl' (https://stackoverflow.com/a/66127391/2554330)
library(rgl) # >install.packages("rgl"); >options(rgl.useNULL=TRUE)
library(treespace) 

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model")

```

### *Load raw data*

```{r prep_raw}

# Load raw data
load("HostTraitModel_RawData.RData")

# Pox data: host-OPV interactions detected via PCR/isolation from Virion database
##virion <- vroom('https://github.com/viralemergence/virion/blob/main/Virion/Virion.csv.gz')
poxdata <- virion %>% filter(VirusGenus == "orthopoxvirus" & (DetectionMethod %in% c("PCR/Sequencing","Isolation/Observation"))) 

# Taxa: mammal species taxonomy from vertlife
##vertlife <- read.csv(url('https://data.vertlife.org/mammaltree/taxonomy_mamPhy_5911species.csv'))
taxa <- vertlife

# Host traits: mammal traits from the COMBINE database <https://doi.org/10.1002/ecy.3344>
##path: ecy3344-sup-0001-datas1.zip > COMBINE_archives > trait_data_imputed.csv)
hostTraits <- combine

# Host tree: mammal phylogeny tree from Dryad, <https://doi.org/10.5061/dryad.tb03d03>
##path: Data_S8_finalFigureFiles > _DATA > MamPhy_fullPosterior_BDvr_Completed_5911sp_topoCons_NDexp_MCC_v2_target.tre)
hostTree <- dryad

# Clean environment
rm(virion, vertlife, dryad, combine)

```

### *Prepare poxdata, aggregating host-virus interactions to the genus-level*  
We collapse our dataframe of host-virus interactions to the host genus-level. For each unique host genus-virus interaction, we create binary variables for whether detection of OPV occurred via PCR or virus isolation (competence) and save as a numeric variable the number of studies for which evidence of OPV detection exists.

```{r prep_poxdata}

# Exclude if host genus
poxdata <- poxdata[!is.na(poxdata$HostGenus),]

# Exclude if virus is NA
poxdata <- poxdata[!is.na(poxdata$Virus),]

# Exclude variola (smallpox) virus
poxdata <- poxdata[!(poxdata$Virus=="variola virus"),]

# Extract PCR-positive df 
pcr <- subset(poxdata[which(poxdata$DetectionMethod=="PCR/Sequencing"),], select=c("Host","HostGenus","Virus"))

# Where species name is NA, replace with "sp."
pcr$Host <- ifelse(is.na(pcr$Host),"sp.",pcr$Host)

# Collapse dataframe to species level, summing the number of observations
pcr$pcr <- 1
pcr <- aggregate(.~Host+HostGenus+Virus, data=pcr, sum)

# Extract virus isolation data 
competence <- subset(poxdata[which(poxdata$DetectionMethod=="Isolation/Observation"),], select=c("Host","HostGenus","Virus"))

# Where species name is NA, replace with "sp."
competence$Host <- ifelse(is.na(competence$Host),"sp.",competence$Host)

# Collapse dataframe to species level, summing the number of observations
competence$competence <- 1
competence <- aggregate(.~Host+HostGenus+Virus, data=competence, sum)

# Merge PCR and competence data
poxdata <- merge(pcr, competence, by=c("Host","HostGenus","Virus"), all=TRUE)

# Create studies variable, summing the number of studies identifying pcr-positive and competent hosts
poxdata$studies <- ifelse(is.na(poxdata$pcr),0,poxdata$pcr) + ifelse(is.na(poxdata$competence),0,poxdata$competence)

# Create binary variables for whether OPV was detected via PCR or competence/virus isolation
poxdata$pcr=ifelse(is.na(poxdata$pcr),0,1)
poxdata$competence=ifelse(is.na(poxdata$competence),0,1)

# Extract binary PCR data for every unique host genus and virus pair in poxdata, classifying a pair as PCR-positive if ANY species within the genus was PCR-positive
bin_pcr <- aggregate(pcr~HostGenus+Virus, data=poxdata, max)

# Extract binary competence data for every unique host genus and virus pair in poxdata, classifying a pair as competent if virus isolation was confirmed for ANY species within the genus.
bin_competence <- aggregate(competence~HostGenus+Virus, data=poxdata, max)

# Extract studies data, summing the number of studies for every unique host genus and virus pair in poxdata
sum_studies <- aggregate(studies~HostGenus+Virus, data=poxdata, sum)

#(8) Merge variables of binary PCR, binary competence and studies
poxdata <- merge(bin_pcr,bin_competence)
poxdata <- merge(poxdata,sum_studies)

#(9) Rename and reformat variables
poxdata <- plyr::rename(poxdata,c('HostGenus'='gen','Virus'='virus'))
poxdata$gen <- str_to_title(poxdata$gen)

#(10) Clean environment
rm(pcr,competence,bin_pcr, bin_competence, sum_studies)

```

### *Merge poxdata with broader mammal taxa to create pseudoabsences*
To allow for out-of-sample predictions, we merge our dataset of known host-virus interactions with the broader mammal taxa from Vertlife to create pseudoabsences. We only keep host genera belonging to orders with known interactions. We also use this opportunity to match the taxonomic names in poxdata to those of the mammal taxonomy from Vertlife.

```{r prep_pseudo}

# Drop duplicate genera in taxa 
gtaxa <- taxa[!duplicated(taxa$gen),]

# Subset only the variables we need from taxa: genus, family, and order
gtaxa <- gtaxa[c('gen','fam','ord')]

# Check for mismatched names between mammal taxa and poxdata
poxdata$gen[!poxdata$gen %in% taxa$gen]

# Merge poxdata with taxa
poxdata <- merge(gtaxa,poxdata,by='gen',all.x=TRUE)

# Keep only genera if they belong to an order with a known interaction, by first subsetting known interactions
keep <- subset(poxdata, pcr==1 | competence==1)

# Denote whether an order in poxdata has a known OPV interaction
poxdata$keep <- ifelse(poxdata$ord %in% keep$ord,TRUE,FALSE)

# Only keep orders (and their associated genera) with a known interaction
poxdata <- subset(poxdata,keep==TRUE)
poxdata$keep=NULL

# Create binary variable for sampled host-OPV pairs
poxdata$sampled=ifelse(is.na(poxdata$pcr) & is.na(poxdata$competence),0,1)

# Calculate the number of pseudoabsences
length(which(is.na(poxdata$virus)))

# Reclassify NAs as pseudo-absences for viral detection
poxdata$pcr=ifelse(is.na(poxdata$pcr),0,poxdata$pcr)
poxdata$competence=ifelse(is.na(poxdata$competence),0,poxdata$competence)
poxdata$studies=ifelse(is.na(poxdata$studies),0,poxdata$studies)

# Replace any potential NA taxonomic values with taxa data based on host genera
poxdata=merge(poxdata,gtaxa,by='gen',all.x=TRUE)
poxdata <- plyr::rename(poxdata,c('fam.y'='fam','ord.y'='ord'))
poxdata$fam.x=NULL
poxdata$ord.x=NULL

# Clean environment
rm(taxa,gtaxa,keep)

```

### *Collapse hostTraits to genus-level*
In preparation of merging host traits with our poxdata, we collapse species-level observations to the genus-level using summary measures. For continuous and integer variables, we take the median. For binary variables, we take the mean as a measure of the proportion of species in a genus having the variable outcome or trait. For categorical variables, we transform the variables into multiple binary variables and then take the mean.

```{r prep_traits}

# Observe variable names
colnames(hostTraits)

# To aggregate continuous/integer variables, use the median as the summary measure
hostTraits_continuous=aggregate(cbind(adult_mass_g,brain_mass_g,adult_body_length_mm,adult_forearm_length_mm,
                                   max_longevity_d,maturity_d,female_maturity_d,male_maturity_d,
                                   age_first_reproduction_d,gestation_length_d,teat_number_n,
                                   litter_size_n,litters_per_year_n,interbirth_interval_d,
                                   neonate_mass_g,weaning_age_d,weaning_mass_g,generation_length_d,
                                   dispersal_km,density_n_km2,home_range_km2,social_group_n,
                                   dphy_invertebrate,dphy_vertebrate,dphy_plant,
                                   det_inv,det_vend,det_vect,det_vfish,det_vunk,det_scav,det_fruit,det_nect,det_seed,det_plantother,det_diet_breadth_n,
                                   upper_elevation_m,lower_elevation_m,altitude_breadth_m,habitat_breadth_n) 
                             ~ order+family+genus, data=hostTraits, FUN=median, na.action=na.pass, na.rm=TRUE)
##'na.action=na.pass, na.rm=TRUE' is specified such that if species w/in a genus has a combination of real values & NAs, the median of real values will be returned (as opposed to omitting the genus or returning NA)

# To aggregate binary variables, use the mean as the summary measure
hostTraits$fossoriality[hostTraits$fossoriality==2]<-0  #recode 0/1
hostTraits_binary=aggregate(cbind(hibernation_torpor,fossoriality,freshwater,marine,terrestrial_non.volant,terrestrial_volant,
                               island_dwelling,disected_by_mountains,glaciation) ~ order+family+genus, data=hostTraits, FUN=mean, na.action=na.pass, na.rm=TRUE)

# To aggregate categorical variables, first transform the variables to binary
hostTraits_cat <- hostTraits

unique(hostTraits_cat$trophic_level)
hostTraits_cat$trophic_herbivores <- ifelse(hostTraits_cat$trophic_level==1,1,0)
hostTraits_cat$trophic_omnivores <- ifelse(hostTraits_cat$trophic_level==2,1,0)
hostTraits_cat$trophic_carnivores <- ifelse(hostTraits_cat$trophic_level==3,1,0)

unique(hostTraits_cat$activity_cycle)
hostTraits_cat$activity_nocturnal <- ifelse(hostTraits_cat$activity_cycle==1,1,0)
hostTraits_cat$activity_crepuscular <- ifelse(hostTraits_cat$activity_cycle==2,1,0)
hostTraits_cat$activity_diurnal <- ifelse(hostTraits_cat$activity_cycle==3,1,0)

unique(hostTraits_cat$foraging_stratum)
hostTraits_cat$forager_marine <- ifelse(hostTraits_cat$foraging_stratum=="M",1,0)
hostTraits_cat$forager_ground <- ifelse(hostTraits_cat$foraging_stratum=="G",1,0) 
hostTraits_cat$forager_scansorial <- ifelse(hostTraits_cat$foraging_stratum=="S",1,0)
hostTraits_cat$forager_arboreal <- ifelse(hostTraits_cat$foraging_stratum=="Ar",1,0)
hostTraits_cat$forager_aerial <- ifelse(hostTraits_cat$foraging_stratum=="A",1,0)

unique(hostTraits_cat$island_endemicity)
hostTraits_cat$island_end_marine <- ifelse(hostTraits_cat$island_endemicity=="Exclusively marine",1,0)
hostTraits_cat$island_end_mainland <- ifelse(hostTraits_cat$island_endemicity=="Occurs on mainland",1,0)
hostTraits_cat$island_end_lgbridge <- ifelse(hostTraits_cat$island_endemicity=="Occurs on large land bridge islands",1,0)
hostTraits_cat$island_end_isolated <- ifelse(hostTraits_cat$island_endemicity=="Occurs only on isolated islands",1,0)

unique(hostTraits_cat$biogeographical_realm)
hostTraits_cat$biogeo_afrotropical <- ifelse(grepl("Afrotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_antarctic <- ifelse(grepl("Antarctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_australasian <- ifelse(grepl("Australasian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_indomalayan <- ifelse(grepl("Indomalayan",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_nearctic <- ifelse(grepl("Nearctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_neotropical <- ifelse(grepl("Neotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_oceanian <- ifelse(grepl("Oceanian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_palearctic <- ifelse(grepl("Palearctic",hostTraits_cat$biogeographical_realm),1,0)

# To aggregate transformed categorical-to-binary variables, use the mean as the summary measure
hostTraits_cat=aggregate(cbind(trophic_herbivores,trophic_omnivores,trophic_carnivores,
                            activity_nocturnal,activity_crepuscular,activity_diurnal,
                            forager_marine,forager_ground,forager_scansorial,forager_arboreal,forager_aerial,
                            island_end_marine,island_end_mainland,island_end_lgbridge,island_end_isolated,
                            biogeo_afrotropical,biogeo_antarctic,biogeo_australasian,biogeo_indomalayan,biogeo_nearctic,biogeo_neotropical,biogeo_oceanian,biogeo_palearctic)
                       ~ order+family+genus, data=hostTraits_cat, FUN=mean, na.action=na.pass, na.rm=TRUE)

# Merge continuous variables with binary variables
hostTraits <- full_join(hostTraits_continuous, hostTraits_binary, by = c("order","family","genus"),keep=TRUE)

# Rename variables and keep only those needed
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits=subset(hostTraits, select=-c(order.y,family.y,genus.y))

# Merge transformed categorical variables
hostTraits <- full_join(hostTraits, hostTraits_cat, by = c("order","family","genus"),keep=TRUE)

# Rename variables and keep only those needed
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits <- subset(hostTraits, select=-c(order.y,family.y,genus.y))

# Clean environment
rm(hostTraits_binary,hostTraits_cat,hostTraits_continuous)

```

### *Trim hostTree to genus-level*
In preparation of trimming the host tree to mirror our poxdata, we trim the tree tips to the genus-level.

```{r prep_tree}

# Relabel 
hostTree$tip.label[hostTree$tip.label=="_Anolis_carolinensis"] <- "Anolis_carolinensis"

# Create dataframe of the species and genus represented in our mammal tree (based on tip label)
tdata <- data.frame(matrix(NA,nrow=length(hostTree$tip.label),ncol=0))
tdata$genus <- sapply(strsplit(hostTree$tip.label,'_'),function(x) paste(x[1],sep='_'))
tdata$species <- hostTree$tip.label

#(3) Collapse tree to genus level
hostTree <- makeCollapsedTree(tree=hostTree,df=tdata[c('genus','species')])

#(4) Clean environment
rm(tdata)

```

### *Check for mismatched genera names in poxdata, hostTraits and hostTree*

```{r prep_names}

# Check if all poxdata genera are in hostTree
poxdata$gtip <- poxdata$gen
hostTree$gtip <- hostTree$tip.label
poxdata$intree <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTree$gtip),'missing','upham')

# Check if all poxdata genera are in hostTraits
hostTraits$gtip <- hostTraits$genus
poxdata$intraits <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTraits$gtip),'missing','traits')

# Create a dataframe of just the observations with mismatched names
fix <- poxdata[c('gtip','intree','intraits')]
fix <- fix[fix$intree=='missing'|fix$intraits=='missing',]
fix <- unique(fix)

# For those with mismatched names, identify homotypic synonyms or proxy species via IUCN (https://www.iucnredlist.org/) and NCBI (http://www.ncbi.nlm.nih.gov/taxonomy)
fix$treename <- NA
fix$traitname <- NA
fix$proxy <- NA
fix$proxy <- ifelse(fix$gtip=="Calassomys","Delomys",fix$proxy)
  ##source: https://academic.oup.com/jmammal/article/95/2/201/860032
fix$traitname <- ifelse(fix$gtip=="Liomys","Heteromys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Oreonax","Lagothrix",fix$traitname)
  ##source: https://www.iucnredlist.org/species/39924/192307818
fix$traitname <- ifelse(fix$gtip=="Paralomys","Phyllotis",fix$traitname)
  ##source: https://www.iucnredlist.org/species/17226/22333354
fix$traitname <- ifelse(fix$gtip=="Pearsonomys","Geoxus",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Pipanacoctomys","Tympanoctomys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/136557/78324400#taxonomy
fix$traitname <- ifelse(fix$gtip=="Pseudalopex","Lycalopex",fix$traitname)
  ##source: https://www.iucnredlist.org/species/6926/87695615
## hostTraits$genus[which(grepl('Tympanoctomys',hostTraits$genus))]

# Merge revised names with poxdata
fix <- subset(fix, select=-c(intree,intraits))
poxdata <- merge(poxdata,fix,by='gtip',all.x=T)

# If 'treename' is missing, first relabel as NA, then relabel with 'gtip'
poxdata$treename <- ifelse(poxdata$treename=='',NA,as.character(poxdata$treename))
poxdata$treename <- ifelse(is.na(poxdata$treename),as.character(poxdata$gtip),as.character(poxdata$treename))

# If 'traitname' is missing, first relabel as NA; If 'traitname' is NA and missing in 'intraits', then relabel with 'proxy'; If 'traitname' is not NA and missing in 'intraits', then relabel with 'traitname'
poxdata$traitname <- ifelse(poxdata$traitname=='',NA,as.character(poxdata$traitname))
poxdata$traitname <- ifelse(poxdata$intraits=='missing' & is.na(poxdata$traitname),as.character(poxdata$proxy),
                      ifelse(poxdata$intraits=='missing' & !is.na(poxdata$traitname),as.character(poxdata$traitname),
                             as.character(poxdata$gtip)))

# Simplify and clean environment
poxdata <- subset(poxdata, select=-c(intree,intraits,proxy))
rm(fix)

```

### *Merge poxdata with hostTraits and trim hostTree to mirror poxdata*

```{r prep_merge}

#(2) Merge traits with poxdata
hostTraits$traitname <- hostTraits$gtip
poxdata <- merge(poxdata,hostTraits,by=c('traitname'),all.x=T)

#(3) Clean up poxdata
poxdata <- plyr::rename(poxdata,c('gtip.x'='gtip'))
poxdata <- subset(poxdata,select=-c(order, family, genus, gtip.y))

#(4) Trim hostTree to mirror poxdata
hostTree <- keep.tip(hostTree,hostTree$tip.label[hostTree$tip.label%in%poxdata$treename])
hostTree$gtip <- NULL
hostTree=makeLabel(hostTree)

#(5) Clean environment
rm(hostTraits)

```

### *Add PubMed citations and evolutionary distinctiveness measure*
We add two additional predictors to our model: (1) the number of PubMed citations per genus as a proxy for sampling effort, and (2) the evolutionary distinctiveness.

```{r prep_cites_ed}

# Load library for PubMed citations
library(easyPubMed)

# Create function to count citations
counter=function(name){
  as.numeric(as.character(get_pubmed_ids(gsub('_','-',name))$Count))
}
citations=c()

# Extract unique genera from poxdata
treename <- unique(poxdata$treename)

# Apply 'counter' function while looping through treenames
for(i in 1:length(treename)) {
  citations[i]=counter(treename[i])
  print(i)
}

# Compile citation numbers in new dataframe
cites <- data.frame(treename=treename,cites=citations)

# Merge cites with poxdata
poxdata <- merge(poxdata,cites,by='treename')

# Load library for evolutionary distinctiveness (ed) measure
library(picante)  #before loading picante, make sure the latest version of the nlme package is loaded
ed <- evol.distinct(hostTree,type='equal.splits') #calculates ed measures for a suite of species by equal splits and fair proportions; returns species score

# Rename variables in ed dataframe
ed <- plyr::rename(ed,c('Species'='treename','w'='ed_equal'))

# Merge ed with poxdata
poxdata <- merge(poxdata,ed,by='treename')

# Clean environment
rm(cites,ed,citations,i,treename,counter)

```

### *Collapse poxdata to genus-level*
Up to this point, each observation has represented a unique host-virus interaction, where some mammal genera are associated (host) with multiple viruses. Here, we drop our 'virus' variable and we collapse our poxdata to the genus-level retaining only unique mammal genera characterized as OPV hosts based on PCR positivity or virus isolation (competence).

```{r prep_genus}

# Remove virus variable
poxdata <- subset(poxdata,select=-c(virus))

# Extract binary PCR data for every unique host genus in poxdata, classifying a genus as PCR positive if they were PCR positive for ANY OPV species.
agg_pcr <- aggregate(pcr~gen, data=poxdata, max)

# Extract binary competence data for every unique host genus in poxdata, classifying a genus as competent if virus isolation was confirmed for ANY OPV species.
agg_competence <- aggregate(competence~gen, data=poxdata, max)

# Extract studies data, summing the number of studies for every unique host genus in poxdata
agg_studies <- aggregate(studies~gen, data=poxdata, sum)

# Drop old variables from poxdata
poxdata$pcr=NULL
poxdata$competence=NULL
poxdata$studies=NULL

# Remove duplicate genera
poxdata <- poxdata[!duplicated(poxdata$gen),]

# merge pcr, competence, and studies data back in
poxdata <- list(poxdata,agg_pcr,agg_competence,agg_studies) %>% reduce(full_join, by='gen')

# Reorder variables
poxdata <- poxdata %>% 
  dplyr::relocate(gen,fam,ord,gtip,treename,traitname,pcr,competence,studies,sampled,cites,ed_equal)

# Clean environment
rm(agg_competence,agg_pcr,agg_studies)

```

### *Save cleaned data*

```{r prep_save}

#Save cleaned data for analysis
save(poxdata, hostTree, file="Output/HostTraitModel_CleanData.RData")

```


2. Phylogenetic Analysis
========================

### *Load required packages and set system*

```{r phylo_load}

# Libraries for phylogenetic analysis
library(ape)
library(caper)
library(data.table)
library(BiocManager)  ## BiocManager::install(c("Biostrings","ggtree"))
library(phylofactor)  ## devtools::install_github('reptalex/phylofactor'); more info at: https://reptalex.github.io/phylofactor/)
library(treeio)       ## BiocManager::install("treeio")
library(ggtree)
library(dplyr)

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model")

```

### *Phylogenetic patterns*
We analyze the raw data comparing the proportion of host genera with known infection by evidence type (PCR vs. virus isolation) and exploring the strength of phylogenetic signal in PCR and virus isolation data.

```{r phylo_signal}

# Load data
load("Output/HostTraitModel_CleanData.RData")
data <- poxdata

# Check that genus name in poxdata is also in hostTree
which(data$treename%in%setdiff(data$treename,hostTree$tip.label))

# Create variables label and Species (required in later functions)
data$label <- data$treename
data$Species <- data$treename  

# Merge phylogeny w/ data ensuring consistent structure & ordering using caper package
cdata=comparative.data(phy=hostTree,data=data,names.col=treename,vcv=T,na.omit=F,warn.dropped=T)
cdata$data$tree=NULL

# What proportion of genera have evidence of infection?
nrow(data)
data %>% count(pcr==1)
round(prop.table(table(data$pcr)),4)*100 
data %>% count(competence==1)
round(prop.table(table(data$competence)),4)*100
##values in each cell are divided by the sum of the 4 cells

# Does the raw data display a phylogenetic signal in response?
set.seed(1)
mod1 <- phylo.d(cdata,binvar=pcr,permut=10000); mod1
set.seed(1)
mod2 <- phylo.d(cdata,binvar=competence,permut=10000); mod2
## D of 0 = Brownian model, D of 1 = random (no phylogenetic signal)

```

### *Phylofactorization*
We conduct phylofactorization using phylofactor::gpf and determine the number of phylogenetic factors (aka clades) to retain by creating a function that applies Holm's sequentially rejective 5% cutoff to adjust for the family-wise error rate.

```{r phylo_factor}

# Create dataframe of taxonomy from cdata
cdata$data$taxonomy=paste(cdata$data$ord,cdata$data$fam,cdata$data$gen,sep='; ')
taxonomy <- data.frame(cdata$data$taxonomy)
names(taxonomy) <- "taxonomy"
taxonomy$Species <- rownames(cdata$data)
taxonomy <- taxonomy[c("Species","taxonomy")]

# Create function to apply Holm rejection procedure, where pf=phylofactor and FWER=family-wise error rate (alpha .05)
HolmProcedure <- function(pf,FWER=0.05){        
  ## get split variable
  cs=names(coef(pf$models[[1]]))[-1]       
      ### returns names of model coefficients (var names) extracted by 'coef' in 
      ### the 1st list element of 'pf$models' minus the 1st element among those 
      ### names; double brackets access a list element
  split=ifelse(length(cs)>1,cs[3],cs[1])         
      ### returns 3rd element in 'cs' if length of the number of elements in 
      ### 'cs' >1; else returns 1st element
  
  ## obtain p values
  if (pf$models[[1]]$family$family%in%c('gaussian',"Gamma","quasipoisson")){                  
      ### if fam$fam of 1st list element of pf$models is in columns 'gaussian'...
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|t|)'])  
      ### then to each element of pf$models, apply summary function w/ argument
      ### 'fit' and assign output to 'pvals'; 
      ### specifically, we use 'summary(fit)' to call the output of 'pf$models',
      ### extracting the 'coefficients' section, whereby we index the column 
      ### named 'Pr(>|t\)' and split the data in that column; see sample output 
      ### of linear model of R for reference (https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R) 
  } else {
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|z|)'])  
      ### else extract p-val based on z statistic
  }
  D <- length(pf$tree$tip.label)                                                              
      ### returns number of elements in pf$tree$tip.label
  
  ## this is the line for Holm's sequentially rejective cutoff, where HB = Target alpha / (n – rank + 1)
  keepers <- pvals<=(FWER/(2*D-3 - 2*(0:(pf$nfactors-1))))                                    
      ### returns TRUE/FALSE if p-values are <= to 0.05/(n-rank+1)
  
  if (!all(keepers)){                            
      ### if not all pvals were keepers (i.e., all items in keepers were true)...
    nfactors <- min(which(!keepers))-1           
      ### then assign nfactors to minimum/earliest position of items in keepers that were false, minus 1.
  } else {
    nfactors <- pf$nfactors                      
      ###:else, assign nfactors as the value of pf$nfactors
  }
  return(nfactors)
}

## get species in a clade
cladeget=function(pf,factor){                        
  ### creates function 'cladeget' w/ arguments 'pf' and 'factor'
  spp=pf$tree$tip.label[pf$groups[[factor]][[1]]]    
    ### returns n'th element of the pf$tree$tip.label based on the value of 
    ### the first component inside the n'th ('factor') component of  'pf$groups'
  return(spp)
}

# Summarize pf (phylofactor) object                               
pfsum=function(pf){                                  
  
  ## get formula
  chars=as.character(pf$frmla.phylo)[-1]  ### returns pf$frmla.phylo minus 1st element
  
  ## response                  
  resp=chars[1]               ###returns 1st element of chars              
  
  ## holm
  hp=HolmProcedure(pf)                      
  
  ## save model
  model=chars[2]                           
  
  ## set key
  setkey(pf$Data,'Species')   ### creates key on sorted pf$Datacolumn 'Species'
  
  ## make data
  dat=data.frame(pf$Data)                            
  
  ## make clade columns in data
  for(i in 1:hp){
    
    dat[,paste0(resp,'_pf',i)]=ifelse(dat$Species%in%cladeget(pf,i),'factor','other')   
    ### paste0 concatenates all elements w/o a separator
    
  }
  
  ## make data frame to store taxa name, response, mean, and other
  results=data.frame(matrix(ncol=6, nrow = hp))                        
  colnames(results)=c('factor','taxa','tips','node',"clade",'other')
  
  ## set taxonomy
  taxonomy=dat[c('Species','taxonomy')]                               
  taxonomy$taxonomy=as.character(taxonomy$taxonomy)
  
  ## loop
  for(i in 1:hp){
    
    ## get taxa
    tx=pf.taxa(pf,taxonomy,factor=i)$group1            #gets taxonomic order
    
    ## get tail
    tx=sapply(strsplit(tx,'; '),function(x) tail(x,1)) #gets tax family as list
    
    ## combine
    tx=paste(tx,collapse=', ')         #collapses tax family into single string
    
    # save
    results[i,'factor']=i         #returns index number in 'factor' column
    results[i,'taxa']=tx          #returns string element (tx) in 'taxa' column
    
    ## get node
    tips=cladeget(pf,i)
    node=ggtree::MRCA(pf$tree,tips)         
    ### MRCA = finds Most Recent Common Ancestor among a vector of tips 
    results[i,'tips']=length(tips)
    results[i,'node']=ifelse(is.null(node) & length(tips)==1,'species',
                             ifelse(is.null(node) & length(tips)!=1,NA,node))
    
    ## get means
    ms=(tapply(dat[,resp],dat[,paste0(resp,'_pf',i)],FUN=mean))   
    ### tapply takes mean of '1 vs. 0' (dat[,resp]) by 'other'/'factor' type (dat[,paste...]
    
    ## add in
    results[i,'clade']=ms['factor']
    results[i,'other']=ms['other']
    
  }
  
  ## return
  return(list(set=dat,results=results))       #returns number of clades with significantly greater propensity of infection adjusting for FWER using Holm rejection procedure
}

# Conduct phylofactorization of infection data
set.seed(1)
pcr_pf=gpf(Data=cdata$data,tree=cdata$phy,
           frmla.phylo=pcr~phylo,
           family=binomial,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize infection PF results
HolmProcedure(pcr_pf)
pcr_pf_results=pfsum(pcr_pf)$results        

# Conduct phylofactorization of competence data
set.seed(1)
hc_pf=gpf(Data=cdata$data,tree=cdata$phy,     
          frmla.phylo=competence~phylo,
          family=binomial,algorithm='phylo',nfactors=2,min.group.size=5)

# Summarize competence PF results
HolmProcedure(hc_pf)
hc_pf_results=pfsum(hc_pf)$results       

```

### *Plot results of phylofactorization*

```{r phylo_results}

# Save tree for plotting
cdata$data$infect=factor(cdata$data$pcr)
cdata$data$comp=factor(cdata$data$competence)
dtree=treeio::full_join(as.treedata(cdata$phy),cdata$data,by="label")

# Fix palette for plotting
AlberPalettes <- c("YlGnBu","Reds","BuPu", "PiYG")
AlberColours <- sapply(AlberPalettes, function(a) RColorBrewer::brewer.pal(5, a)[4])
afun=function(x){
  a=AlberColours[1:x]
  return(a)
}

# Make low and high, and set x max
pcols=afun(2)
plus=1
pplus=plus+1

# Fix taxa font formatting
pcr_pf_results$taxa
pcr_pf_results$taxa[1]="Rodentia"
hc_pf_results$taxa
hc_pf_results$taxa[1]="italic(Felidae)"

# Plot PCR positivity w/ ggtree
pcr_gg=ggtree(dtree,size=0.25)+
  geom_tippoint(aes(colour=infect),shape=15)+
  scale_colour_manual(values=c("grey80","black"))+
  guides(colour="none")   

# Add clades (Rodentia) to plot
for(i in 1:nrow(pcr_pf_results)){
  
  pcr_gg=pcr_gg+
    geom_hilight(node=pcr_pf_results$node[i],
                 alpha=0.25,
                 fill=ifelse(pcr_pf_results$clade>
                               pcr_pf_results$other,pcols[2],pcols[1])[i])+
    geom_cladelabel(node=pcr_pf_results$node[i],
                    label=pcr_pf_results$taxa[i],
                    offset=pplus,
                    hjust=0.75,
                    offset.text=pplus*2,
                    parse=T,
                    angle=90)
}
pcr_gg=pcr_gg

# Plot competence w/ ggtree
comp_gg=ggtree(dtree,size=0.25)+
  geom_tippoint(aes(colour=comp),shape=15)+
  scale_colour_manual(values=c("grey80","black"))+
  guides(colour=F)

# Add clades (Felidae) to plot
for(i in 1:nrow(hc_pf_results)){
  
  comp_gg=comp_gg+
    geom_hilight(node=hc_pf_results$node[i],
                 alpha=0.25,
                 fill=ifelse(hc_pf_results$clade>
                               hc_pf_results$other,pcols[2],pcols[1])[i])+
    geom_cladelabel(node=hc_pf_results$node[i],
                    label=hc_pf_results$taxa[i],
                    offset=pplus,
                    hjust=0.75,
                    offset.text=pplus*2,
                    parse=T,
                    angle=90)
}
comp_gg=comp_gg

# Print tree figures for infection and competence
library(ggpubr)
png("Output/tree_phylofactor_raw.png",width=6,height=6,units="in",res=300)
ggarrange(pcr_gg,comp_gg,ncol=2,widths=c(1.2,1),
          labels=c("(a) RT-PCR","(b) virus isolation"),
          label.x=c(-0.1,-0.2),
          font.label=list(face="plain",size=12))
dev.off()

```

### *Additional phylofactorization models*
We conduct phylofactorization again on infection and competence data but using Pubmed citations as a weight variable in the model. Additionally, we conduct phylofactorization on citations themselves.

```{r phylo_cites}

# Create log-transformed variable of pubmed cites
cdata$data$logcites=log1p(cdata$data$cites)

# Conduct phylofactorization on PCR infection data with Pubmed cites as a weight variable
set.seed(1)
pcr_pf_pm=gpf(Data=cdata$data,tree=cdata$phy,
                 frmla.phylo=pcr~phylo,
                 weights=cdata$data$logcites,
                 family=binomial,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize the results
HolmProcedure(pcr_pf_pm)
pcr_pf_pm_results=pfsum(pcr_pf_pm)$results       

# Conduct phylofactorization on competence data with Pubmed cites as a weight variable
set.seed(1)
hc_pf_pm=gpf(Data=cdata$data,tree=cdata$phy,
                frmla.phylo=competence~phylo,
                weights=cdata$data$logcites,
                family=binomial,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize the results
HolmProcedure(hc_pf_pm)
hc_pf_pm_results=pfsum(hc_pf_pm)$results       

# Conduct phylofactorization on Pubmed cites themselves (where cites is not log1pm-transformed)
set.seed(1)
pm_pf=gpf(Data=cdata$data,tree=cdata$phy,
             frmla.phylo=cites~phylo,
             family=poisson,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize the results
HolmProcedure(pm_pf)
pm_pf_results=pfsum(pm_pf)$results

```


3. BRT Model
============
This chapter builds boosted regression tree models trained on infection and competence data to predict mammal hosts of Orthopoxviruses. An example of how to run this section's code on a high performance computing cluster (HPC) is available on the GitHub PoxHost repository: https://github.com/viralemergence/PoxHost/tree/0a1effef83dbd5f6f3d88c6d0c15c563eb499452/Tseng2022/HPC%20Example_01Jun2023.

### *Load required packages and set system*

```{r brt_load}

# Libraries for BRT model
library(gbm)
library(fastDummies)
library(rsample)
library(ROCR)
library(sciplot)
library(ggplot2)
library(pdp)
library(PresenceAbsence)
library(tidyr)
library(viridis)
library(caper)
library(phylofactor)
library(ggtree)
library(treeio)
library(caret) 
library(InformationValue)
library(mgcv) #for beta regression on performance metrics

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model")

```

### *Create variables of taxonomic family as predictors for the model*

```{r brt_taxo}

# Load data and clean environment
load("Output/HostTraitModel_CleanData.RData")
data <- poxdata
rm(poxdata)

# Classify true negatives
data$type=ifelse(data$pcr==0 & data$competence==0,"true negative","other")

# Which species is competent but not PCR positive?
set=data
set$treename[set$pcr==0 & set$competence==1]

# Tabulate PCR/infection and isolation
set$inf=ifelse(set$pcr==0,"PCR negative","PCR positive")
set$iso=ifelse(set$competence==0,"no isolation","isolation")
table(set$inf,set$iso)

# Make binary variables for each taxonomic family; remove any duplicates
dums=dummy_cols(data["fam"])
dums=dums[!duplicated(dums$fam),]

# Ensure all family vars are factor
for(i in 1:ncol(dums)){
  dums[,i]=factor(dums[,i])
}

# Merge family taxa variables with dataset as predictors
data=merge(data,dums,by="fam",all.x=T)

# Drop unnecessary columns and clean environment
data$traitname=NULL
rm(dums,set,i)

```

### *Assess variation and availability of data*
We explore the variation and availability of our data and drop variables if more than 30% of observations are missing/NA. We ask, are there zero or near-zero variance predictors? And what is the distribution of coverage among our traits?
Figure: *histogram_trait_coverage.png*
Table: *table_trait_coverage.csv*

```{r brt_var}

# Create mode function where for each variable, we will extract the frequency of the most frequently occurring value for that variable, and divide it by the number of non-NA elements in that variable
mode.prop <- function(x) {                
  ux <- unique(x[is.na(x)==FALSE])        # creates array of unique values
  tab <- tabulate(match(na.omit(x), ux))  # creates array of the frequency (number of times) a unique value appears in a column 
  max(tab)/length(x[is.na(x)==FALSE])     # max-frequency / number of elements in each column that are not NA
}

# Assess variation across columns (2 indicates columns)
vars=data.frame(apply(data,2,function(x) mode.prop(x)),
                apply(data,2,function(x) length(unique(x))))    # number of unique elements in each column

# Get names
vars$variables=rownames(vars)
names(vars)=c("var","uniq","column")

# # Round values
# vars$var=round(vars$var,2)

# Label variables "cut" if homogeneous (100%)
vars$keep=ifelse(vars$var<1,"keep","cut")
vars$keep=ifelse(vars$column%in%c('fam','virus','gen','pcr','competence','fam'),'keep',vars$keep) # ensures we keep these columns
vars=vars[order(vars$keep),]

# Trim (creates array of column names to cut and removes from df)
keeps=vars[-which(vars$keep=="cut"),]$column

# Drop if no variation
data=data[keeps]
rm(keeps,vars)

# Assess missing values
mval=data.frame(apply(data,2,function(x) length(x[!is.na(x)])/nrow(data))) # proportion of values that are not NA

# Get names
mval$variables=rownames(mval)
names(mval)=c("comp","column")

# Exclude observations of non-predictor variables from mval dataframe
mval_hist <- mval[-(1:9),]
nrow(mval_hist)

# Plot frequency distribution of coverage among 185 traits
png("Output/histogram_trait_coverage.png", width=4,height=4,units="in",res=600)
ggplot(mval_hist[!mval_hist$column%in%c("gen","treename","pcr","competence","tip.label","fam"),],
       aes(comp))+
  geom_histogram(bins=50)+
  geom_vline(xintercept=0.70,linetype=2,linewidth=0.5)+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  labs(y="Frequency",
       x="Trait coverage across mammal genera")+
  scale_x_continuous(labels = scales::percent)
dev.off()

# Label variables "cut" if >30% values are NA
mval$keep=ifelse(mval$comp>=0.70,"keep","cut")
table(mval$keep)
mval=mval[order(mval$keep),]

# Trim (creates array of column names to cut and removes from df)
keeps=mval[-which(mval$keep=="cut"),]$column

# Drop if not well represented
data=data[keeps]

# Subset data to include only predictor and response variables
set <- subset(data,select=-c(gen,fam,ord,gtip,treename,type,studies,sampled))
## this dataframe will also be used in the next code block

# Create dataframe of trait coverage
table1=data.frame(apply(set,2,function(x) length(x[!is.na(x)])/nrow(set)))
## apply(X, MARGIN,...): "2" indicates applying the function over columns (as opposed to "1")

# Generate 'variable' column from rownames
table1$variables=rownames(table1)

# Rename columns and drop rownames
names(table1)=c("Coverage","Feature")
rownames(table1)=NULL

# Drop predictor variables from list
table1=table1[!table1$Feature%in%c("pcr","competence"),]
table1 <- subset(table1,select=c(Feature,Coverage))

# Output table of trait coverage
write.csv(table1, "Output/table_trait_coverage.csv")

# Check that binary variables are numeric and not factor (with the exception of fam_* variables)
str(set)

# Clean environment
rm(keeps,mval,mval_hist,table1)

```

### Tuning to asses model performance for each combination of tuning parameters
We create a hyperparamter 'grid' that represents different combinations of parameter values for model tuning.
Table: *par_tuning_data_summary.csv*

```{r brt_tuning}

# Hyperparameter tuning ifelse
#hok="ok"
hok="notok"
if(hok!="ok"){
  
  ## hyperparameter grid
  hgrid=expand.grid(n.trees=5000,   #creates df from all combinations of factor vars (1*3*3*1*10=90 obs & 5 vars)
                    interaction.depth=c(2,3,4),
                    shrinkage=c(0.01,0.001,0.0005),
                    n.minobsinnode=4,
                    seed=seq(1,10,by=1))

  # fix trees
  hgrid$n.trees=ifelse(hgrid$shrinkage<0.001,hgrid$n.trees*3,hgrid$n.trees)
  
  ## trees, depth, shrink, min, prop 
  hgrid$id=with(hgrid,paste(n.trees,interaction.depth,shrinkage,n.minobsinnode))   #creates var 'id' concatenating values from each of the specified columns in hgrid
  
  ## sort by id then seed
  hgrid=hgrid[order(hgrid$id,hgrid$seed),]
  
  ## now add rows
  hgrid$row=1:nrow(hgrid)                                        #adds var 'row' based on row number in hgrid
  
  ## factor id
  hgrid$id2=factor(as.numeric(factor(hgrid$id)))                 #creates 9-level factor var 'id2' 
  
  ## function to assess each hyperpar combination
  hfit=function(row,response){
    
    ## make new data
    ndata=set
    
    ## correct response
    ndata$response=ndata[response][,1]                           #creates var 'response'
    
    ## remove raw
    ndata$pcr=NULL
    ndata$competence=NULL
    
    ## use rsample to split
    set.seed(hgrid$seed[row])                                    #sets seed value of 1-10
    split=initial_split(ndata,prop=0.7,strata="response")        #creates single binary split of data into training set and testing set, where 70% of data is retained for modeling/analysis and resampling is created within the 'response' var
    
    ## test and train
    dataTrain=training(split)
    dataTest=testing(split)
    
    ## yTest and yTrain
    yTrain=dataTrain$response                                    #create array of just response values from training and testing set
    yTest=dataTest$response
    
    ## BRT
    set.seed(1)
    gbmOut=gbm(response ~ . ,data=dataTrain,                     #y~x; gbmOut contains list of 29 elements including train.error and valid.error referenced later in gbm.perf()
               n.trees=hgrid$n.trees[row],                       #total number of trees to fit (number of iterations; default is 100)
               distribution="bernoulli",
               shrinkage=hgrid$shrinkage[row],                   #equiv to learning rate or step-size reduction (smaller learning rate requires more trees, default is 0.1)
               interaction.depth=hgrid$interaction.depth[row],   #max depth of each tree (highest level of variable interactions allowed; default is 1)
               n.minobsinnode=hgrid$n.minobsinnode[row],         #min. number of obs in terminal nodes of trees
               cv.folds=5,class.stratify.cv=TRUE,                #no. of cross-val folds to perform; for cv.folds>1, returns estimate of generalization error in 'cv.error'
               bag.fraction=0.5,train.fraction=1,                #fraction of training set obs randomly selected to propose next tree in expansion - this is why we set.seed()
               n.cores=5,                                        #no. of CPU cores to use
               verbose=F)
               # par.details=(gbmParallel(num_threads=5)),
    
    ## performance
    par(mfrow=c(1,1),mar=c(4,4,1,1))                             #sets graphical parameters such that subsequent figure are drawn in a nr-by-nc array by mfrows respectively and gives the number of lines of margin to be specified on the four sides of the plot c(bottom, L, top, R) -> see 'best.iter' plot below 
    best.iter=gbm.perf(gbmOut,method="cv")                       #estimates optimal number of boosting iterations and plots 'training.error' performance measure; cv method extracts this optimal number using cross-validation
    
    ## predict with test data
    preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")  #number of trees based on the optimal number of boosting iterations as set above (5,352) 

    ## known
    result=dataTest$response
    
    # ##estimate threshold value for classification of predicted probability
    # #library(pROC)
    # analysis <- roc(result,preds)  #roc([actual values],[predicted values])
    # e <- cbind(analysis$thresholds,analysis$sensitivities+analysis$specificities) #pulls each array and binds them into dataframe: 1st column are thresholds, 2nd column are sensitivities + specificities
    # 
    # ##optimum threshold value
    # opt_t <- subset(e,e[,2]==max(e[,2]))[,1] #subsets dataframe and returns the max (sens+spec) value of 2nd column of e 
    # #threshold<-opt_t #set as threshold value
    # #threshold = 0.2
    
    ## sensitivity and specificity                              #e.g., test run produced sensitivity of 0 b/c no predictedScores were > 0.5; and specificity of 1 b/c all predictedScores were <0.5
    sen=InformationValue::sensitivity(result,preds)              #calculates sensitivity (# of obs with event AND predicted to have event, divided by # of obs w/ event) for a given logit model where input is the actual binary flag (as numerica vector) for the response variable and the predicted probability scores for each observation; if predicted value is above the threshold (defaults to 0.5), it will be considered an event (1) or else a non-event (0)
    spec=InformationValue::specificity(result,preds)             #calculates specificity (# of obs w/o event AND predicted to not have event, divided by # of obs w/o event)  
    
    ## AUC on train
    auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))   #compute Information Retrieval measures for pairwise loss for a single group, where input is the observed value and the predicted value
    
    ## AUC on test
    auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
    
    ## print
    print(paste("hpar row ",row," done; test AUC is ",auc_test,sep=""))  #prints "hpar row [x] done; test AUC is []"
    
    ## save outputs
    return(list(best=best.iter,                    #saves optimal number of iterations, AUC on training set, AUC on testing set, specificity, sensitivity, and row number as a list
                trainAUC=auc_train,
                testAUC=auc_test,
                spec=spec,
                sen=sen,
                wrow=row))
  }
  
  ## run the function for PCR
  hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="pcr"))
  
  ## get results
  hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
                      sapply(hpars,function(x) x$testAUC),
                      sapply(hpars,function(x) x$spec),
                      sapply(hpars,function(x) x$sen),
                      sapply(hpars,function(x) x$wrow),
                      sapply(hpars,function(x) x$best))
  names(hresults)=c("trainAUC","testAUC",
                    "spec","sen","row","best")
  
  ## combine and save
  hsearch=merge(hresults,hgrid,by="row")
  
  ## save
  hsearch$type="PCR"
  
  ## rerun the function for competence
  hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="competence"))
  
  ## get results
  hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
                      sapply(hpars,function(x) x$testAUC),
                      sapply(hpars,function(x) x$spec),
                      sapply(hpars,function(x) x$sen),
                      sapply(hpars,function(x) x$wrow),
                      sapply(hpars,function(x) x$best))
  names(hresults)=c("trainAUC","testAUC",
                    "spec","sen","row","best")
  
  ## combine and save
  csearch=merge(hresults,hgrid,by="row")
  
  ## assign data type
  csearch$type="competence"
  
  ## combine
  search=rbind.data.frame(csearch,hsearch)
  search$type=factor(search$type,levels=c("PCR","competence"))
  
  ## export
  write.csv(search,"Output/par_tuning_data_summary.csv")
  
}else{
  
  ## load
  search=read.csv("Output/par_tuning_data_summary.csv")
  
}

```

### *Assess model tuning results*
We fit a beta regression model using mgcv::gam to explore the main and interaction effects of tuning parameters, interaction depth and shrinkage, on performance metrics: AUC, sensitivity, and specificity. This model is appropriate for analyzing continuous response variables bounded between 0 and 1 (i.e., beta distributions). Using ANOVA, we then determine whether the coefficients between the two interaction depths, the two shrinkage rates, and the four possible interactions between them are significantly different. Next, we plot the performance of BRTs based on various parameter combinations. Finally, we assess the distribution of best.iter (the optimal number of iterations) to determine the max number of trees to use for model training.
Figure: *boxplot_brt_tuning.png*

```{r brt_tuning_results}

# Convert parameters to factor and relabel values
search$shrinkage=factor(search$shrinkage)  #search=read.csv("Output/par_tuning_data_summary.csv")
lvl=rev(sort(unique(search$shrinkage)))    #sorts unique shrinkage par from large to small
search$shrinkage=factor(search$shrinkage,levels=lvl); rm(lvl)  #applies as factor
search$interaction.depth=factor(search$interaction.depth)
search$type=plyr::revalue(search$type,     #replace specified values w/ new values
                          c("PCR"="RT-PCR",
                            "competence"="virus isolation"))

# Fit beta regression model to the test AUCs of our PCR-based BRTs; ANOVA
mod=gam(testAUC~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to test AUCs of our competence-based BRTs; ANOVA
mod=gam(testAUC~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to sensitivities of our PCR-based BRTs; ANOVA
mod=gam(sen~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to sensitivities of our competence-based BRTs; ANOVA
mod=gam(sen~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to specificities of our PCR-based BRTs; ANOVA
mod=gam(spec~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to specificities of our competence-based BRTs; ANOVA
mod=gam(spec~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

# To plot model tuning performance, transform dataframe from wide to long
search_long=gather(search,measure,value,testAUC:sen)

# Relabel values and convert to factor 
search_long$measure=plyr::revalue(search_long$measure,
                              c("sen"="sensitivity",  
                                "spec"="specificity",
                                "testAUC"="test AUC"))
search_long$measure=factor(search_long$measure,
                       levels=c("test AUC","sensitivity","specificity"))

# Boxplot performance of model tuning with various parameter combinations
png("Output/boxplot_brt_tuning.png",width=5,height=8,units="in",res=600)
set.seed(1)
ggplot(search_long,aes(shrinkage,value,
                   colour=interaction.depth,fill=interaction.depth))+
  geom_boxplot(alpha=0.25)+
  geom_point(alpha=0.75,
             position = position_jitterdodge(dodge.width=0.75))+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  facet_grid(measure~type,scales="free_y",switch="y")+
  theme(strip.placement="outside",
        strip.background=element_blank())+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        strip.text=element_text(size=12))+
  theme(legend.position="top")+
  scale_color_brewer(palette="Pastel2")+
  scale_fill_brewer(palette="Pastel2")+
  guides(colour=guide_legend(title="interaction depth"),
         fill=guide_legend(title="interaction depth"))+
  labs(y=NULL,
       x="learning rate")+
  scale_y_continuous(n.breaks=4)
dev.off()

# To determine optimal parameters for model training, subset tuning results by number of trees
search_nt5000 <- search[search$n.trees==5000,]
search_nt15000 <- search[search$n.trees==15000,]
search_nt5000_sh0.01 <- search_nt5000[search_nt5000$shrinkage==0.010,]  #subset models with shrinkage==0.010
search_nt5000_sh0.001 <- search_nt5000[search_nt5000$shrinkage==0.001,]  #subset models with shrinkage==0.010

# Plot best.iter by evidence type (pcr vs. competence) to see max number of trees to include
search_nt5000 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt15000 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt5000_sh0.01 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt5000_sh0.001 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 

# Clean
rm(search,search_long,hok,mod,search_nt5000,search_nt15000,search_nt5000_sh0.01, search_nt5000_sh0.001)

```

### *BRT function for applying across multiple data partitions*
Here we create our BRT function for model training where we apply the function across multiple data partitions.

```{r brt_partition}

# BRT function to use different data partitions
brt_part=function(seed,response){
  
  ## make new dataset
  ndata=set
  
  ## correct response variable
  ndata$response=ndata[response][,1]
  
  ## remove raw response variables
  ndata$pcr=NULL
  ndata$competence=NULL
  
  ## for BRT where cites is the response variable...
  if(response=="cites"){
    
    ## we add 1 to cites if cites equals 0
    ndata$cites=ifelse(ndata$cites==0,1,ndata$cites)
    
  }else{
    
    ndata=ndata
    
  }
  
  ## use rsample package to split data
  set.seed(seed)
  split=initial_split(ndata,prop=0.7,strata="response")
  
  ## create test and train datasets
  dataTrain=training(split)
  dataTest=testing(split)
  
  ## get response variable for test dataset and train dataset
  yTrain=dataTrain$response
  yTest=dataTest$response
  
  ## save distribution
  dist=ifelse(response=="cites","poisson","bernoulli")
  
  ## save number of trees based on previous plots of optimal iterations
  nt=ifelse(response=="cites",10000,
     ifelse(response=="pcr",4500,5000)) #see plots of best.iter 
  
  ## run BRTs using gbm package
  set.seed(1)
  gbmOut=gbm(response ~ . ,data=dataTrain,
             n.trees=nt,
             distribution=dist,
             shrinkage=0.01, #see plots of best.iter 
             interaction.depth=3,
             n.minobsinnode=4,
             cv.folds=5,class.stratify.cv=TRUE,
             bag.fraction=0.5,train.fraction=1,
             n.cores=5,
             verbose=F)
            # par.details=(gbmParallel(num_threads=5)),

  ## get optimal number of iterations using gbm.perf & set plotting parameters for performance chart generated by gbm.perf
  par(mfrow=c(1,1),mar=c(4,4,1,1))                         
  best.iter=gbm.perf(gbmOut,method="cv")  #estimates optimal number of boosting iterations for a gbm object     
  
  ## predict with test data, applying the optimal number of iterations as n.trees
  preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")
  
  ## save known associations
  result=dataTest$response
  
  ## get sensitivity and specificity
  sen=InformationValue::sensitivity(result,preds)
  spec=InformationValue::specificity(result,preds)
  
  ## get AUC from model training
  auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))
  
  ## get AUC from model test
  auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
  
  ## skip if poisson
  if(response=="cites"){
    
    perf=NA
    
  }else{
    
    ## inner loop if yTest is all 0
    if(var(yTest)==0){
      
      perf=NA
    }else{
      
      ## ROC: create a prediction object using the predicted probabilities and the true class labels (known responses)
      pr=prediction(preds,dataTest$response)    
      
      ## ROC: calculate the desired performance measures specified by the 'measure' argument
      perf=performance(pr,measure="tpr",x.measure="fpr")         #pr=prediction object; measure=performance measure for evaluation; x.measure=second perf measure (2-D)
      
      ## ROC: create dataframe of performance values
      perf=data.frame(perf@x.values,perf@y.values)
      
      ## ROC: rename columns
      names(perf)=c("fpr","tpr")
      
      ## add seed
      perf$seed=seed
      
    }
  }
  
  ## get relative importance
  bars=summary(gbmOut,n.trees=best.iter,plotit=F)
  bars$rel.inf=round(bars$rel.inf,2)

  ## predict with cites
  preds=predict(gbmOut,data,n.trees=best.iter,type="response")
  pred_data=data[c("gtip",'treename',"fam","ord","pcr","competence")]
  pred_data$pred=preds
  pred_data$type=response
  
  ## predict with mean cites
  pdata=data
  pdata$cites=mean(pdata$cites)
  pred_data$cpred=predict(gbmOut,pdata,n.trees=best.iter,type="response")
  
  ## sort by decreasing predicted probability
  pred_data=pred_data[order(pred_data$pred,decreasing=T),]
  
  ## print
  print(paste("BRT ",seed," done; test AUC = ",auc_test,sep=""))
  
  ## save outputs
  return(list(mod=gbmOut,
              best=best.iter,
              trainAUC=auc_train,
              testAUC=auc_test,
              spec=spec,
              sen=sen,
              roc=perf,
              rinf=bars,
              predict=pred_data,
              traindata=dataTrain,
              testdata=dataTest,
              seed=seed))
}

```

### *Apply BRT function across 100 partitions to generate ensemble*

```{r brt_ensemble}

# Apply across 100 splits each
# smax=101
smax=100
pcr_brts=lapply(1:smax,function(x) brt_part(seed=x,response="pcr"))
comp_brts=lapply(1:smax,function(x) brt_part(seed=x,response="competence"))

# Run wos brts
pm_brts=lapply(1:(smax-1),function(x) brt_part(seed=x,response="cites"))

# Save results to working directory
saveRDS(pcr_brts, "Output/pcr_brts.rds")
saveRDS(comp_brts, "Output/pcr_brts.rds")
saveRDS(pm_brts, "Output/pcr_brts.rds")

```


4. Model Performance
====================
In this chapter, we assess the performance of our BRT models trained on PCR and virus isolation data.

### *Load required packages and set system*

```{r perf_load}

#(1) Libraries for BRT figures
library(tidyr)
library(ggplot2)
# library(sciplot)
library(fastDummies)
# library(caper)
library(ape)
# library(phylofactor)
# library(treeio)
# library(ggtree)
library(plotrix) #std.error
library(rstatix) 
library(ggrepel)
library(ggpubr) #ggarrange
library(plyr)

#(2) Clean environment
rm(list=ls()) 
graphics.off()

#(3) Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model")

```

### *Evaluate performance measures *
How accurately did infection and competence BRT models distinguish OPV positive and negative species? We evaluate the mean AUC, sensitivity, and specificity of our models, both combined (net) and independently. 

```{r perf_auc}

#### If needed, increase vector memory in R environment and reboot R before proceeding (https://stackoverflow.com/questions/51295402/r-on-macos-error-vector-memory-exhausted-limit-reached)

#(1) Load data
# load("Output/HostData_results.RData")
# save(pcr_brts,comp_brts,pm_brts,file="Output/HostTraitModel_Results.RData")

pcr_brts <- readRDS("Output/pcr brts.rds")
comp_brts <- readRDS("Output/comp brts.rds")
pm_brts <- readRDS("Output/pm brts.rds")

#(2) Index and save non-missing BRT iterations
pcr_keep=which(!is.na(sapply(pcr_brts,function(x) x$testAUC)))
comp_keep=which(!is.na(sapply(comp_brts,function(x) x$testAUC)))
keep=intersect(pcr_keep,comp_keep)

#(4) Trim 
pcr_brts=pcr_brts[keep]
comp_brts=comp_brts[keep]

#(5) Get net AUC
mean(c(sapply(pcr_brts,function(x) x$testAUC),sapply(comp_brts,function(x) x$testAUC)))
std.error(c(sapply(pcr_brts,function(x) x$testAUC),sapply(comp_brts,function(x) x$testAUC)))

#(6) Get net sensitivity
mean(c(sapply(pcr_brts,function(x) x$sen),sapply(comp_brts,function(x) x$sen)))
std.error(c(sapply(pcr_brts,function(x) x$sen),sapply(comp_brts,function(x) x$sen)))

#(7) Get net specificity
mean(c(sapply(pcr_brts,function(x) x$spec),sapply(comp_brts,function(x) x$spec)))
std.error(c(sapply(pcr_brts,function(x) x$spec),sapply(comp_brts,function(x) x$spec)))

#(8) Get net AUC for cites
mean(sapply(pm_brts,function(x) x$testAUC))
std.error(sapply(pm_brts,function(x) x$testAUC))

#(9) Clean environment
rm(pm_brts)

#(10) Get independent AUC for PCR and Comp models
mean(sapply(pcr_brts,function(x) x$testAUC))
std.error(sapply(pcr_brts,function(x) x$testAUC))
mean(sapply(comp_brts,function(x) x$testAUC))
std.error(sapply(comp_brts,function(x) x$testAUC))

#(11) Get independent sensitivity for PCR and Comp models
mean(sapply(pcr_brts,function(x) x$sen))
std.error(sapply(pcr_brts,function(x) x$sen))
mean(sapply(comp_brts,function(x) x$sen))
std.error(sapply(comp_brts,function(x) x$sen))

#(11) Get independent specificity for PCR and Comp models
mean(sapply(pcr_brts,function(x) x$spec))
std.error(sapply(pcr_brts,function(x) x$spec))
mean(sapply(comp_brts,function(x) x$spec))
std.error(sapply(comp_brts,function(x) x$spec))

```

### *Compare performance between BRTs trained on infection vs. competence*
Is model performance significantly different when training on infection vs. competence data? We create a function to perform an unpaired T-test on the AUC, sensitivity and specificity of the two models and determine the effect size (mean difference) via Cohen's d.

```{r perf_compare}

#(1) Function for extracting data, performing unpaired t-test and determining effect size via Cohen's d
tfun=function(measure){
  
  ## format data
  n=length(sapply(pcr_brts,function(x) x$testAUC))
  adata=data.frame(y=c(sapply(pcr_brts,function(x) x[measure][[1]]),
                       sapply(comp_brts,function(x) x[measure][[1]])),
                   response=c(rep('infection',n),rep('competence',n)),
                   seed=c(sapply(pcr_brts,function(x) x$seed),
                          sapply(comp_brts,function(x) x$seed)))
  rm(n)
  
  ## factor
  adata$response=factor(adata$response,levels=c('infection','competence'))
  
  ## make jitter position
  adata$x=as.numeric(factor(adata$response))
  set.seed(1)
  adata$xj=jitter(adata$x,0.5)
  
  ## fix response
  adata$response2=plyr::revalue(adata$response,c("infection"="RT-PCR",
                                           "competence"="virus isolation"))
  
  ## t-test
  tsum=t.test(y~response,data=adata,
              alternative='two.sided',
              var.equal=F,paired=F)  
  
  ## effect size
  csum=cohens_d(y~response,data=adata,paired=F,var.equal=F)
  
  ## return
  return(list(adata=adata,tsum=tsum,csum=csum))
}

#(2) Compare AUC w/ tfun function; extract t-stat & Cohen's d
adata=tfun("testAUC")
adata$tsum$statistic
adata$csum$effsize

#(4) Compare sensitivity w/ tfun function; extract t-stat & Cohen's d
sedata=tfun("sen")
sedata$tsum$statistic
sedata$csum$effsize

#(6) Compare specificity w/ tfun function; extract t-stat & Cohen's d
spdata=tfun("spec")
spdata$tsum$statistic
spdata$csum$effsize

#(7) Adjust p-values with Benjamini Hochberg correction method
ps=c(adata$tsum$p.value,
     sedata$tsum$p.value,
     spdata$tsum$p.value)
round(p.adjust(ps,method="BH"),4)    #"BH" (aka "fdr") = Benjamini & Hochberg (1995) method control the false discovery rate, the expected proportion of false discoveries amongst the rejected hypotheses (false discovery rate is less stringent condition than family-wise error rate)

```

### *Generate boxplot of model performance*
Figure: *boxplot_model_senspec.png*, *boxplot_model_auc.png*

```{r perf_boxplot}

# Extract sensitivity and specificity data; save as new dataframes
data1=sedata$adata
data2=spdata$adata

# Group observations by type for plotting
data1$type="sensitivity"
data2$type="specificity"

# Aggregate datasets
sdata=rbind.data.frame(data1,data2)
rm(data1,data2)

# Boxplot model performance 
png("Output/boxplot_model_senspec.png",width=4,height=5,units="in",res=300)
set.seed(1)
ggplot(sdata)+
  #geom_violin(aes(x=x,y=auc,group=x),trim=T,scale="count",width=0.5)+
  geom_boxplot(aes(x=x,y=y,group=x),width=0.25,alpha=0.25,outlier.alpha=0)+
  geom_point(aes(x=xj,y=y),size=1.5,alpha=0.5)+
  scale_x_continuous(breaks=c(1,2),
                     labels=levels(sdata$response2),
                     limits=c(0.5,2.5))+
  theme_bw()+
  facet_wrap(~type,scales="free_y",strip.position="left",ncol=1)+
  theme(strip.placement="outside",
        strip.background=element_blank())+
  labs(x="Response variable",
       y=NULL)+
  theme(axis.text.y=element_text(size=10),
        axis.text.x=element_text(size=12),
        axis.title=element_text(size=12),
        strip.text=element_text(size=12))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  guides(colour="none")
dev.off()

# Boxplot of AUC
png("Output/boxplot_model_auc.png",width=4,height=5,units="in",res=300)
set.seed(1)
ggplot(adata$adata)+
  geom_boxplot(aes(x=x,y=y,group=x),width=0.25,alpha=0.25,outlier.alpha=0)+
  geom_point(aes(x=xj,y=y),size=1.5,alpha=0.5)+
  scale_x_continuous(breaks=c(1,2),
                     labels=levels(adata$adata$response2),
                     limits=c(0.5,2.5))+
  theme_bw()+
  labs(x="Response variable",
       y="Area under the curve (AUC)")+
  theme(axis.text=element_text(size=10),
        axis.text.x=element_text(size=12),
        axis.title=element_text(size=12))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  guides(colour="none")
dev.off()

```


5. Model Predictions
====================

In this chapter, we examine predictions from our BRT model, assessing the predicted probabilities of OPV positivity.

### *Load required packages and set system*

```{r pred_load}

#(1) Libraries for BRT figures
library(tidyr)
library(ggplot2)
library(sciplot)
library(fastDummies)
library(caper)
library(ape)
library(phylofactor)
library(plotrix) #std.error
library(rstatix)
library(ggrepel)
library(ggpubr) #ggarrange
library(plyr)
library(dplyr)

#(2) Clean environment
rm(list=ls()) 
graphics.off()

#(3) Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model")

```

### *Extract and save predicted probabilities*
Table: *table_HostTraitModel_predictions.csv*

```{r pred_save}

# Load model predictions
pcr_brts <- readRDS("Output/pcr brts.rds")
comp_brts <- readRDS("Output/comp brts.rds")

# Load cleaned data file
load("Output/HostTraitModel_CleanData.RData")
data <- poxdata

# Make binary columns for each taxonomic family in our dataset
dums=fastDummies::dummy_cols(data["fam"])

# Get only unique observations
dums=dums[!duplicated(dums$fam),]

# Ensure all are factor
for(i in 1:ncol(dums)){
  
  ## column as factor
  dums[,i]=factor(dums[,i])
  
}

# Merge family variables with poxdata
data=merge(data,dums,by="fam",all.x=T)
rm(dums)

# Get predicted probabilities from infection model
pcr_apreds=lapply(pcr_brts,function(x) x$predict)
pcr_apreds=do.call(rbind,pcr_apreds)

# Collapse to mean of predicted probabilities for each unique treename/tip
pcr_apreds=data.frame(aggregate(pred~treename,data=pcr_apreds,mean),
                      aggregate(cpred~treename,data=pcr_apreds,mean)['cpred'], ## holding wos constant
                      aggregate(pcr~treename,data=pcr_apreds,prod)["pcr"],
                      aggregate(competence~treename,data=pcr_apreds,prod)["competence"])

# Generate variable of evidence type for infection model
pcr_apreds$type='PCR'

# Average predictions: competence
comp_apreds=lapply(comp_brts,function(x) x$predict)
comp_apreds=do.call(rbind,comp_apreds)

# Aggregate
comp_apreds=data.frame(aggregate(pred~treename,data=comp_apreds,mean),
                       aggregate(cpred~treename,data=comp_apreds,mean)['cpred'], ## holding wos constant
                       aggregate(pcr~treename,data=comp_apreds,prod)["pcr"],
                       aggregate(competence~treename,data=comp_apreds,prod)["competence"])

# Generate variable of evidence type for competence model
comp_apreds$type='competence'

# Combine predictions from both model types
apreds=rbind.data.frame(pcr_apreds,comp_apreds)

# Add studies variable
apreds=merge(apreds,data[c("treename","studies")],by="treename")

# Generate positivity variable
apreds$positivity=ifelse(apreds$pcr==1 & apreds$type=="PCR",1,
                         ifelse(apreds$competence==1 & apreds$type=='competence',1,0))

# Generate variable of studied (unsampled) or not studied (positive/negative)
apreds$cat=ifelse(apreds$studies==0,"unsampled",
                  ifelse(apreds$positivity==1,"positive","negative"))

# Generate evidence type variable
apreds$type=factor(apreds$type,levels=c("PCR","competence"))
apreds$type2=plyr::revalue(apreds$type,c("PCR"="infection"))

# Transform apreds long to wide
apreds2=tidyr::spread(apreds[c('treename','type','cpred')],type,cpred)
comp_apreds$comp=comp_apreds$competence

# Merge with comp_apreds
apreds2=merge(apreds2,comp_apreds[c("treename","pcr","comp")],by="treename")

# Fix variable names
names(apreds2)=c("treename","pred_pcr","pred_comp","PCR","competence")

# Classify true negatives
data$type=ifelse(data$studies>0 & data$pcr==0 & data$competence==0,"true negative","other")

# Merge with data
apreds2=merge(apreds2,data[c("treename","type","studies","ord","fam","gen")],by='treename')

# Fix cat variable
apreds2$cat=ifelse(apreds2$studies==0,"unsampled",
                   ifelse(apreds2$PCR==0 & apreds2$competence==0,"negative","positive"))

# Make cat variable factor
apreds2$cat=factor(apreds2$cat,c("positive",'negative','unsampled'))
apreds$cat=factor(apreds$cat,levels=levels(apreds2$cat))

# Fix label of type2 variable
apreds$type2=plyr::revalue(apreds$type2,
                     c("infection"="Infection",
                       "competence"="Competence"))

# Save as new dataframe and drop unnecessary variables
preds=apreds2
preds$fam=NULL
preds$gen=NULL

# Write file
write.csv(preds,"Output/table_HostTraitModel_predictions.csv")

```

### *Visualize how predicted probabilities are distributed*
Figures: *plot_pp.png*

```{r pred_figure}

# Load library for color palette; select and re-order colors
remotes::install_github("awhstin/awtools")
library(awtools)
cc=mpalette[2:4] 
cc=rev(cc)

# Density plot of predicted probabilities
densityplot_pp=ggplot(apreds,aes(cpred))+
  geom_density(aes(fill=cat,colour=cat),alpha=0.5)+
  facet_wrap(~type2,ncol=1,strip.position='top',scales="free_y")+
  theme_bw()+
  theme(legend.position="top")+
  labs(x=expression(paste("Predicted probability (",italic(P),") of hosting")))+
  xlim(0,1)+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        legend.title=element_text(size=12),
        legend.text=element_text(size=11),
        strip.text=element_text(size=11),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(20,20,20,20))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  scale_colour_manual(values=cc)+
  scale_fill_manual(values=cc)+
  guides(colour=guide_legend(title="(a) Orthopoxvirus positivity"),
         fill=guide_legend(title="(a) Orthopoxvirus positivity"))
densityplot_pp

# Scatterplot of predicted probabilities
scatterplot_pp=ggplot(apreds2,aes(pred_pcr,pred_comp))+
  geom_point(alpha=0.5,size=2,aes(colour=cat,fill=cat))+
  geom_smooth(method='gam',colour="grey")+
  labs(x=expression(paste(italic(P),' from RT-PCR models')),
       y=expression(paste(italic(P),' from virus isolation models')))+
  theme_bw()+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        legend.title=element_text(size=12),
        legend.text=element_text(size=11),
        strip.text=element_text(size=11),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(20,20,20,20))+
  theme(legend.position="top")+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  scale_colour_manual(values=cc)+
  scale_fill_manual(values=cc)+
  guides(colour=guide_legend(title="(a) Orthohantavirus positivity"),
         fill=guide_legend(title="(a) Orthohantavirus positivity"))
scatterplot_pp

# Combine density plot with scatterplot of predicted probabilities; save
png("Output/plot_pp.png",width=6.5,height=4,units="in",res=300)
plot_pp=ggarrange(densityplot_pp,scatterplot_pp,common.legend=T)
plot_pp
dev.off()

```

### *Explore the effect of threshold moving on binary classification*
We calculate various optimal threshold values and evaluate how threshold moving changes classification of OPV positive vs. negative mammal genera.
Table: *table_predicted_hosts_infection.xlsx*, *table_predicted_hosts_competence.xlsx*

```{r pred_threshold}

# Load libraries
library(PresenceAbsence)
library(openxlsx)

# Load model predictions (predicted probabilities)
set.seed(12345)
pred <- read.csv("/Users/katietseng/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model/Output/table_HostTraitModel_predictions.csv")
# pred <- read.csv("/Users/katietseng/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model/Output/PoxHost_predictions.csv")

# For the infection model, let's calculate the opt. threshold values using different optimization methods (e.g., 80% sensitivity)
ts_pcr <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
                           threshold = 10001,
                           opt.methods = c(2,3,4,5,10),
                           req.sens = 0.80,
                           na.rm = TRUE)

# Get 85% sensitivity threshold
ts_pcr[nrow(ts_pcr) + 1,] <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
                           threshold = 10001,
                           opt.methods = c(10),
                           req.sens = 0.85,
                           na.rm = TRUE)

# Get 90% sensitivity threshold
ts_pcr[nrow(ts_pcr) + 1,] <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
                           threshold = 10001,
                           opt.methods = c(10),
                           req.sens = 0.9,
                           na.rm = TRUE)

# Get 95% sensitivity threshold
ts_pcr[nrow(ts_pcr) + 1,] <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
                           threshold = 10001,
                           opt.methods = c(10),
                           req.sens = 0.95,
                           na.rm = TRUE)

# Create function to apply thresholds to predictions for all mammal genera and only those that are potentially unknown
cut_pcr1 <- function(x) {sum(pred$pred_pcr > x)}
cut_pcr2 <- function(x) {sum(pred$pred_pcr[pred$PCR==0] > x)}

# Let's briefly view the number of predicted hosts based on the various thresholds
sapply(unlist(ts_pcr[2]), cut_pcr1)

# Let's briefly view the number of predicted unknown hosts based on the various thresholds
sapply(unlist(ts_pcr[2]), cut_pcr2)

# Save threshold values
#write.csv(ts_pcr, file='Output/ts_pcr.csv')

# For the competence model, let's calculate the opt. threshold values using different optimization methods (e.g., 80% sensitivity)
ts_comp <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
                           threshold = 10001,
                           opt.methods = c(2,3,4,5,10),
                           req.sens = 0.80,
                           na.rm = TRUE)

# Get 85% sensitivity threshold
ts_comp[nrow(ts_comp) + 1,] <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
                           threshold = 10001,
                           opt.methods = c(10),
                           req.sens = 0.85,
                           na.rm = TRUE)

# Get 90% sensitivity threshold
ts_comp[nrow(ts_comp) + 1,] <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
                           threshold = 10001,
                           opt.methods = c(10),
                           req.sens = 0.9,
                           na.rm = TRUE)

# Get 95% sensitivity threshold
ts_comp[nrow(ts_comp) + 1,] <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
                           threshold = 10001,
                           opt.methods = c(10),
                           req.sens = 0.95,
                           na.rm = TRUE)

# Create function to apply thresholds to predictions for all mammal genera and only those that are potentially unknown
cut_comp1 <- function(x) {sum(pred$pred_comp > x)}
cut_comp2 <- function(x) {sum(pred$pred_comp[pred$competence==0] > x)}

# Let's briefly view the number of predicted hosts based on the various thresholds
sapply(unlist(ts_comp[2]), cut_comp1)

# Let's briefly view the number of predicted unknown hosts based on the various thresholds
sapply(unlist(ts_comp[2]), cut_comp2)
sum(pred$competence)

# Save threshold values
#write.csv(ts_comp, file='Output/ts_comp.csv')

### APPLY THRESHOLDS TO PREDICTIONS ###

# Extract selected optimum threshold values from ts_pcr
ts_pcr_rs0.8 <- as.data.frame(ts_pcr[5,])
ts_pcr_rs0.9 <- as.data.frame(ts_pcr[7,])
ts_pcr_rs0.95 <- as.data.frame(ts_pcr[8,])
ts_pcr_mss3 <- as.data.frame(ts_pcr[2,])

ts_comp_rs0.8 <- as.data.frame(ts_comp[5,])
ts_comp_rs0.9 <- as.data.frame(ts_comp[7,])
ts_comp_rs0.95 <- as.data.frame(ts_comp[8,])
ts_comp_mss3 <- as.data.frame(ts_comp[2,])

# Threshold the results to binary outputs
pred %>%
  mutate(bin_pcr_rs0.8 = ifelse(pred_pcr > ts_pcr_rs0.8$pred_pcr, 1, 0),
         bin_pcr_rs0.9 = ifelse(pred_pcr > ts_pcr_rs0.9$pred_pcr, 1, 0),
         bin_pcr_rs0.95 = ifelse(pred_pcr > ts_pcr_rs0.95$pred_pcr, 1, 0),
         bin_pcr_mss3 = ifelse(pred_pcr > ts_pcr_mss3$pred_pcr, 1, 0),
         bin_comp_rs0.8 = ifelse(pred_comp > ts_comp_rs0.8$pred_comp, 1, 0),
         bin_comp_rs0.9 = ifelse(pred_comp > ts_comp_rs0.9$pred_comp, 1, 0),
         bin_comp_rs0.95 = ifelse(pred_comp > ts_comp_rs0.95$pred_comp, 1, 0),
         bin_comp_mss3 = ifelse(pred_comp > ts_comp_mss3$pred_comp, 1, 0)) -> pred

# Pull out the relevant lists of predicted hosts based on various thresholds
pred %>% filter(PCR==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known_pcr 
pred %>% filter(bin_pcr_rs0.8==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_pcr_rs0.8
pred %>% filter(bin_pcr_rs0.9==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_pcr_rs0.9 
pred %>% filter(bin_pcr_rs0.95==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_pcr_rs0.95
pred %>% filter(bin_pcr_mss3==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_pcr_mss3 
pred %>% filter(competence==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known_comp 
pred %>% filter(bin_comp_rs0.8==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_comp_rs0.8
pred %>% filter(bin_comp_rs0.9==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_comp_rs0.9
pred %>% filter(bin_comp_rs0.95==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_comp_rs0.95
pred %>% filter(bin_comp_mss3==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_comp_mss3 

# Sort and create dataframe of known and unknown hosts (hosts that do not overlap)
pred_kpcr <- as.data.frame(sort(known_pcr)) #n=58
pred_upcr_rs0.8 <- as.data.frame(sort(pred_pcr_rs0.8[!(pred_pcr_rs0.8 %in% known_pcr)])) 
pred_upcr_rs0.9 <- as.data.frame(sort(pred_pcr_rs0.9[!(pred_pcr_rs0.9 %in% known_pcr)])) 
pred_upcr_rs0.95 <- as.data.frame(sort(pred_pcr_rs0.95[!(pred_pcr_rs0.95 %in% known_pcr)]))
pred_upcr_mss3 <- as.data.frame(sort(pred_pcr_mss3[!(pred_pcr_mss3 %in% known_pcr)])) 
pred_kcomp <- as.data.frame(sort(known_comp)) #n=41
pred_ucomp_rs0.8 <- as.data.frame(sort(pred_comp_rs0.8[!(pred_comp_rs0.8 %in% known_comp)]))
pred_ucomp_rs0.9 <- as.data.frame(sort(pred_comp_rs0.9[!(pred_comp_rs0.9 %in% known_comp)]))
pred_ucomp_rs0.95 <- as.data.frame(sort(pred_comp_rs0.95[!(pred_comp_rs0.95 %in% known_comp)]))
pred_ucomp_mss3 <- as.data.frame(sort(pred_comp_mss3[!(pred_comp_mss3 %in% known_comp)])) 

# How many predicted hosts are undiscovered by PCR?
nrow(pred_upcr_rs0.8)
nrow(pred_upcr_rs0.9)
nrow(pred_upcr_rs0.95)
nrow(pred_upcr_mss3)

# How many predicted undiscovered hosts by competence
nrow(pred_ucomp_rs0.8)
nrow(pred_ucomp_rs0.9)
nrow(pred_ucomp_rs0.95)
nrow(pred_ucomp_mss3)

# To export as a single excel sheet, create list of dataframes/tables
list_df <- list(pred_kpcr, pred_upcr_rs0.8, pred_upcr_rs0.9, pred_upcr_rs0.95, pred_upcr_mss3, pred_kcomp, pred_ucomp_rs0.8, pred_ucomp_rs0.9, pred_ucomp_rs0.95, pred_ucomp_mss3)

# Rename variables
list_df <- lapply(list_df, function(x) {colnames(x) <- c("gen"); x})

# Incorporate taxonomic family & order for each model
taxa <- apreds2[,c("gen","fam","ord")] 
taxa <- unique(taxa)
list_df <- lapply(list_df, function(x) {x <- merge(x, taxa, by = "gen", all=FALSE); x})

# Sort by virus, order, family, and genus
list_df <- lapply(list_df, function(x) {x <- x[order(x$ord, x$fam, x$gen),]; x})

# Reorder columns
list_df <- lapply(list_df, function(x) {x <- x[,c("ord","fam","gen")]; x})

# Reformat to proper
library(stringr)
list_df <- lapply(list_df, function(x) {x$fam <- str_to_title(x$fam); x})
list_df <- lapply(list_df, function(x) {x$ord <- str_to_title(x$ord); x})

# Unlist
pred_kpcr <- as.data.frame(list_df[[1]])
pred_upcr_rs0.8 <- as.data.frame(list_df[[2]])
pred_upcr_rs0.9 <- as.data.frame(list_df[[3]])
pred_upcr_rs0.95 <- as.data.frame(list_df[[4]])
pred_upcr_mss3 <- as.data.frame(list_df[[5]])
pred_kcomp <- as.data.frame(list_df[[6]])
pred_ucomp_rs0.8 <- as.data.frame(list_df[[7]])
pred_ucomp_rs0.9 <- as.data.frame(list_df[[8]])
pred_ucomp_rs0.95 <- as.data.frame(list_df[[9]])
pred_ucomp_mss3 <- as.data.frame(list_df[[10]])

# Save for known hosts and unknown hosts where req.sens=0.8, req.sens=0.85, req.sens=0.9, req.sens=0.95, and opt.methods=3 (MaxSensSpec)
pred_pcr <- list('pcr_known'=pred_kpcr, 
                    'pcr_unknown_rs0.8'=pred_upcr_rs0.8, 
                    'pcr_unknown_rs0.9'=pred_upcr_rs0.9, 
                    'pcr_unknown_rs0.95'=pred_upcr_rs0.95, 
                    'pcr_unknown_mss3'=pred_upcr_mss3)
pred_comp <- list('comp_known'=pred_kcomp, 
                    'comp_unknown_rs0.8'=pred_ucomp_rs0.8,
                    'comp_unknown_rs0.9'=pred_ucomp_rs0.9,
                    'comp_unknown_rs0.95'=pred_ucomp_rs0.95, 
                    'comp_unknown_mss3'=pred_ucomp_mss3)
write.xlsx(pred_pcr, file='Output/table_predicted_hosts_infection.xlsx')
write.xlsx(pred_comp, file='Output/table_predicted_hosts_competence.xlsx')

```

### *Explore model correlation and phylogenetic signal*

```{r pred_phylo}

# Test correlation between the predicted probabilities of infection vs. competence models
cor(apreds2$pred_pcr,apreds2$pred_comp,method='spearman') #computes Spearman correlation coefficient
cor.test(apreds2$pred_pcr,apreds2$pred_comp,method='spearman') #tests for correlation b/w paired samples based on Spearman corr test

# Load phylogeny
load("Output/HostTraitModel_CleanData.RData")
# load("/Users/katietseng/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/HPC Example/HostData_clean.RData")
mtree=hostTree

# Label observations in apreds2 that are non-existent in mtree
apreds2$tree=ifelse(apreds2$treename%in%setdiff(apreds2$treename,mtree$tip.label),'cut','keep')
table(apreds2$tree) ## keep: 945

# Trim and match
bdata=subset(apreds2,tree=='keep')
bdata=bdata[match(mtree$tip.label,bdata$treename),]

# Save
bdata$label=bdata$treename
bdata$Species=bdata$treename

# Generate mean of pcr and comp predicted probabilities
bdata <- bdata %>% mutate(pred_mean = rowMeans(across(pred_pcr:pred_comp), na.rm = TRUE))

# Generate variable of whether a link was predicted based on threshold value
bdata$pcr_rs0.8 <- ifelse(bdata$pred_pcr > ts_pcr_rs0.8$pred_pcr, 1, 0)
bdata$comp_rs0.8 <- ifelse(bdata$pred_comp > ts_comp_rs0.8$pred_comp, 1, 0)
bdata$pcrcomp_rs0.8 <- ifelse(bdata$pcr_rs0.8==1 & bdata$comp_rs0.8==1, "Both",
                              ifelse(bdata$pcr_rs0.8==1 & bdata$comp_rs0.8==0, "PCR",
                                     ifelse(bdata$pcr_rs0.8==0 & bdata$comp_rs0.8==1, "Virus isolation", "Not predicted")))
bdata$pcr_mss3 <- ifelse(bdata$pred_pcr > ts_pcr_mss3$pred_pcr, 1, 0)
bdata$comp_mss3 <- ifelse(bdata$pred_comp > ts_comp_mss3$pred_comp, 1, 0)
bdata$pcrcomp_mss3 <- ifelse(bdata$pcr_mss3==1 & bdata$comp_mss3==1, "Both",
                              ifelse(bdata$pcr_mss3==1 & bdata$comp_mss3==0, "PCR",
                                     ifelse(bdata$pcr_mss3==0 & bdata$comp_mss3==1, "Virus isolation", "Not predicted")))

# Make factor
bdata$pcrcomp_rs0.8 <- factor(bdata$pcrcomp_rs0.8,levels=c("PCR","Virus isolation","Both","Not predicted"))
bdata$pcrcomp_mss3 <- factor(bdata$pcrcomp_mss3,levels=c("PCR","Virus isolation","Both","Not predicted"))

# Merge phylogeny with predictions ensuring consistent structure  
cdata=comparative.data(phy=mtree,data=bdata,names.col=treename,vcv=T,na.omit=F,warn.dropped=T)    #vcv=T indicates to include variance covariance array representing phylogeny within the comparative dataset
### Returned error indicating missing values: Error in '.rowNamesDF<- '(x, value = value) : missing values in 'row.names' are not allowed

# Identify which rows are NA
which(is.na(bdata))

# Subsetting only non-missing data
bdata_nonNA = bdata[-which(is.na(bdata)),]

# Try merging again 
cdata=comparative.data(phy=mtree,data=bdata_nonNA,names.col=treename,vcv=T,na.omit=T,warn.dropped=T)

# Fix
cdata$data$tree=NULL

# Measure phylogenetic signal (Pagel's lambda) of model predictions
pcr_lmod=pgls(pred_pcr~1,data=cdata,lambda="ML")     #pgls fits a linear model while taking into account phylogenetic non-independence between data points
comp_lmod=pgls(pred_comp~1,data=cdata,lambda="ML")   #lambda = value for lambda transformation; 'ML' uses maximum likelihood to optimize branch length transformations
###for more info: https://static1.squarespace.com/static/5459da8ae4b042d9849b7a7b/t/57ea64eae58c62718aa34769/1474979059782/Nesin_Winternitz_Practical_1and2.pdf

# Summarize 
summary(pcr_lmod)
summary(comp_lmod)

```

### *Identify taxonomic patterns via phylofactorization*
Table: *table_pf_clades.csv*

```{r pred_pf}

# Extract taxonomy
cdata$data$taxonomy=paste(cdata$data$ord,cdata$data$fam,cdata$data$Species,sep='; ') #We refer to genus as "Species" as this is required in later functions

# Set taxonomy
taxonomy=data.frame(cdata$data$taxonomy)
names(taxonomy)="taxonomy"
taxonomy$Species=rownames(cdata$data)
taxonomy=taxonomy[c("Species","taxonomy")]
taxonomy$taxonomy=as.character(taxonomy$taxonomy)

# Holm rejection procedure (counteracts the problem of multiple comparisons and controls for family-wise error rate)
HolmProcedure <- function(pf,FWER=0.05){
  
  ## get split variable
  cs=names(coef(pf$models[[1]]))[-1]
  split=ifelse(length(cs)>1,cs[3],cs[1])
  
  ## obtain p values
  if (pf$models[[1]]$family$family%in%c('gaussian',"Gamma","quasipoisson")){
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|t|)'])
  } else {
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|z|)'])
  }
  D <- length(pf$tree$tip.label)
  
  ## this is the line for Holm's sequentially rejective cutoff
  keepers <- pvals<=(FWER/(2*D-3 - 2*(0:(pf$nfactors-1))))
  
  
  if (!all(keepers)){
    nfactors <- min(which(!keepers))-1
  } else {
    nfactors <- pf$nfactors
  }
  return(nfactors)
}

# Get species in a clade
cladeget=function(pf,factor){
  spp=pf$tree$tip.label[pf$groups[[factor]][[1]]]
  return(spp)
}

# Summarize pf object 
pfsum=function(pf){
  
  ## get formula
  chars=as.character(pf$frmla.phylo)[-1]
  
  ## response
  resp=chars[1]
  
  ## fix
  resp=ifelse(resp=='cbind(pos, neg)','prevalence',resp)
  
  ## holm
  hp=HolmProcedure(pf)
  
  ## save model
  model=chars[2]
  
  ## set key
  setkey(pf$Data,'Species')
  
  ## make data
  dat=data.frame(pf$Data)
  
  ## make clade columns in data
  for(i in 1:hp){
    
    dat[,paste0(resp,'_pf',i)]=ifelse(dat$Species%in%cladeget(pf,i),'factor','other')
    
  }
  
  ## make data frame to store taxa name, response, mean, and other
  results=data.frame(matrix(ncol=6, nrow = hp))
  colnames(results)=c('factor','taxa','tips','node',"clade",'other')
  
  ## set taxonomy
  taxonomy=dat[c('Species','taxonomy')]
  taxonomy$taxonomy=as.character(taxonomy$taxonomy)
  
  ## loop
  for(i in 1:hp){
    
    ## get taxa
    tx=pf.taxa(pf,taxonomy,factor=i)$group1
    
    ## get tail
    tx=sapply(strsplit(tx,'; '),function(x) tail(x,1))
    
    ## combine
    tx=paste(tx,collapse=', ')
    
    # save
    results[i,'factor']=i
    results[i,'taxa']=tx
    
    ## get node
    tips=cladeget(pf,i)
    node=ggtree::MRCA(pf$tree,tips)
    results[i,'tips']=length(tips)
    results[i,'node']=ifelse(is.null(node) & length(tips)==1,'species',
                             ifelse(is.null(node) & length(tips)!=1,NA,node))
    
    ## get means
    ms=(tapply(dat[,resp],dat[,paste0(resp,'_pf',i)],mean))
    
    ## add in
    results[i,'clade']=ms['factor']
    results[i,'other']=ms['other']
    
  }
  
  ## return
  return(list(set=dat,results=results))
}

# Fix palette
AlberPalettes <- c("YlGnBu","Reds","BuPu", "PiYG")
AlberColours <- sapply(AlberPalettes, function(a) RColorBrewer::brewer.pal(5, a)[4])
afun=function(x){
  a=AlberColours[1:x]
  return(a)
}

# Make low and high
pcols=afun(2)

# Generalized phylofactorization on PCR predictions
set.seed(1)
pcrpred_pf=gpf(Data=cdata$data,tree=cdata$phy,
               frmla.phylo=pred_pcr~phylo,
               family=gaussian,algorithm='phylo',nfactors=10,min.group.size=5)

# Generalized phylofactorization on competence predictions
set.seed(1)
comppred_pf=gpf(Data=cdata$data,tree=cdata$phy,
                frmla.phylo=pred_comp~phylo,
                family=gaussian,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize results of phylofactorization
pcrpred_pf_results=pfsum(pcrpred_pf)$results  # runs pfsum fxn on PCR predictions (pcrpred_pf); HolmProcedure is nested in pfsum
comppred_pf_results=pfsum(comppred_pf)$results

# Add model/evidence type
pcrpred_pf_results$model="infection"
comppred_pf_results$model="competence"

# Bind results of both models
predpfs=rbind.data.frame(pcrpred_pf_results,comppred_pf_results)

# Round probabilities to the 2nd decimal place
predpfs$clade=round(predpfs$clade,2)
predpfs$other=round(predpfs$other,2)

# Save to output folder
write.csv(predpfs,"Output/table_pf_clades.csv")

```

### *Plot predictions on phylogenetic tree*

```{r pred_tree1}

# Load libraries
library(treeio)
library(ggtree)
library(viridis) #library for color palette

# View distribution of predicted probabilities
hist(cdata$data$pred_pcr)
hist(cdata$data$pred_comp)

# Combine tree and data
dtree=treeio::full_join(as.treedata(cdata$phy),cdata$data,by="label")

# Plot base tree
pbase=ggtree(dtree,layout="fan",branch.length="none",size=0.25)

# Get tree data
tdata=pbase$data

# Get tips only
tdata=tdata[which(tdata$isTip==T),]

# Set x max
xmax=max(tdata$x)+10

### VERSION 1 ###
# For each model evidence type, we plot the predicted probabilities of mammal genera as geom segments corresponding to the tips of a circular mammal tree; colored segments correspond to host positivity

# Make data frame
samp=data.frame(x=tdata$x,
                y=tdata$y,
                yend=tdata$y,
                xend_pcr=scales::rescale(cdata$data$pred_pcr,c(max(tdata$x),xmax)),
                xend_comp=scales::rescale(cdata$data$pred_comp,c(max(tdata$x),xmax)),
                pred_pcr=(cdata$data$pred_pcr),
                pred_comp=(cdata$data$pred_comp),
                treename=tdata$label)

# Merge with cat
samp=merge(samp,apreds2[c("treename","cat")],by="treename",all.x=T)

# Plot circular tree base and significant clades identified by phylofactorization on infection model results
gg=pbase
for(i in 1:nrow(pcrpred_pf_results)){
  
  gg=gg+
    geom_hilight(node=pcrpred_pf_results$node[i],
                 alpha=ifelse(pcrpred_pf_results$tips[i]/Ntip(cdata$phy)<0.5,0.5,0.25),
                 fill="black")
}

# Add predicted probabilities as bars colored based on host positivity
p1=gg+
  geom_segment(data=samp,aes(x=x,y=y,xend=xend_pcr,yend=yend,colour=cat),linewidth=0.75)+
  scale_colour_manual(values=cc)+
  scale_fill_manual(values=cc)+
  # guides(colour="none")
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Host positivity")

# Plot circular tree base and significant clades identified by phylofactorization on competence model results
gg=pbase
for(i in 1:nrow(comppred_pf_results)){
  
  gg=gg+
    geom_hilight(node=comppred_pf_results$node[i],
                 alpha=ifelse(comppred_pf_results$tips[i]/Ntip(cdata$phy)<0.5,0.5,0.25),
                 fill="black")
}

# Add predicted probabilities as bars colored based on host positivity
p2=gg+
  geom_segment(data=samp,aes(x=x,y=y,xend=xend_comp,yend=yend,colour=cat),linewidth=0.75)+
  scale_colour_manual(values=cc)+
  scale_fill_manual(values=cc)+
  # guides(colour="none")
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Host positivity")

# Combine plots based on different evidence types
tree_pp_clades=p1+p2
tree_pp_clades=ggarrange(p1,p2,
              labels=c("(b) RT-PCR predictions","(c) Virus isolation predictions"),
              label.x=c(-0.03,-0.1),
              label.y=0.1,
              font.label=list(face="plain",size=13))

# Save and reformat tree plot
png("Output/tree_pp_clades1.png",width=12,height=8,units="in",res=300)
tree_pp_clades
dev.off()

### VERSION 2  ###
# For each model evidence type and various threshold values, we plot the predicted probabilities of mammal genera as geom segments corresponding to the tips of a circular mammal tree; colored segments correspond to host positivity 

# Make dataframe
samp=data.frame(x=tdata$x,
                y=tdata$y,
                yend=tdata$y,
                xend_pcr=scales::rescale(cdata$data$pred_pcr,c(max(tdata$x),xmax)),
                xend_comp=scales::rescale(cdata$data$pred_comp,c(max(tdata$x),xmax)),
                xend_mean=scales::rescale(cdata$data$pred_mean,c(max(tdata$x),xmax)),
                pcr_rs0.8=(cdata$data$pcr_rs0.8),
                pcr_mss3=(cdata$data$pcr_mss3),
                comp_rs0.8=(cdata$data$comp_rs0.8),
                comp_mss3=(cdata$data$comp_mss3),
                factor_pcr_rs0.8=as.factor((cdata$data$pcr_rs0.8)),
                factor_pcr_mss3=as.factor((cdata$data$pcr_mss3)),
                factor_comp_rs0.8=as.factor((cdata$data$comp_rs0.8)),
                factor_comp_mss3=as.factor((cdata$data$comp_mss3)),
                treename=tdata$label)

# Separate df into predicted host genera and non-predicted host genera for different thresholds
samp_nopcr_rs0.8 <- samp[samp$pcr_rs0.8==0,]
samp_pcr_rs0.8 <- samp[samp$pcr_rs0.8>0,] #121
samp_nopcr_mss3 <- samp[samp$pcr_mss3==0,]
samp_pcr_mss3 <- samp[samp$pcr_mss3>0,] #n=136

samp_nocomp_rs0.8 <- samp[samp$comp_rs0.8==0,]
samp_comp_rs0.8 <- samp[samp$comp_rs0.8>0,] #100
samp_nocomp_mss3 <- samp[samp$comp_mss3==0,]
samp_comp_mss3 <- samp[samp$comp_mss3>0,] #191

# Plot base tree and highlight significant clades for PCR model
gg=pbase
for(i in 1:nrow(pcrpred_pf_results)){
  gg=gg+
    geom_hilight(node=pcrpred_pf_results$node[i],
                 alpha=ifelse(pcrpred_pf_results$tips[i]/Ntip(cdata$phy)<0.5,0.5,0.25), 
                 fill="black")
}

# Add PCR pred-probs and assign color based on binary classification assuming rs0.8
p1=gg+
  geom_segment(
    data=samp_nopcr_rs0.8,
    mapping=aes(x=x,y=y,xend=xend_pcr,yend=yend,
                alpha=factor_pcr_rs0.8),
    color="gray", linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(
    data=samp_pcr_rs0.8, 
    mapping=aes(x=x,y=y,xend=xend_pcr,yend=yend,
                colour=factor(factor_pcr_rs0.8)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Evidence type")

# Add PCR pred-probs and assign color based on binary classification assuming mss3
p2=gg+
  geom_segment(
    data=samp_nopcr_mss3,
    mapping=aes(x=x,y=y,xend=xend_pcr,yend=yend,
                alpha=factor_pcr_mss3),
    color="gray", linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(
    data=samp_pcr_mss3, 
    mapping=aes(x=x,y=y,xend=xend_pcr,yend=yend,
                colour=factor(factor_pcr_mss3)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Evidence type")

# Competence
gg=pbase
for(i in 1:nrow(comppred_pf_results)){
  gg=gg+
    geom_hilight(node=comppred_pf_results$node[i],
                 alpha=ifelse(comppred_pf_results$tips[i]/Ntip(cdata$phy)<0.5,0.5,0.25),
                 fill="black")
}

# Add preds to comp results based on rs0.8
p3=gg+
  geom_segment(
    data=samp_nocomp_rs0.8,
    mapping=aes(x=x,y=y,xend=xend_comp,yend=yend,
                alpha=factor_comp_rs0.8),
    color="gray", linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(
    data=samp_comp_rs0.8, 
    mapping=aes(x=x,y=y,xend=xend_comp,yend=yend,
                colour=factor(factor_comp_rs0.8)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Evidence type")

# Add preds to comp results based on mss3
p4=gg+
  geom_segment(
    data=samp_nocomp_mss3,
    mapping=aes(x=x,y=y,xend=xend_comp,yend=yend,
                alpha=factor_comp_mss3),
    color="gray", linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(
    data=samp_comp_mss3, 
    mapping=aes(x=x,y=y,xend=xend_comp,yend=yend,
                colour=factor(factor_comp_mss3)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Evidence type")

pp_tree2=ggarrange(p1,p2,p3,p4,
              labels=c("(A) PCR ReqSens0.8: Th=0.38","(B) PCR MaxSensSpec: Th=0.36", "(C) Comp ReqSens0.8: Th=0.26", "(D) Comp MaxSensSpec: Th=0.22"),
              # font.label(size=10),
              hjust=-0.6,
              label.x=c(0.1,0.1,0.1,0.1),
              label.y=c(1,1,1,1),
              font.label=list(face="plain",size=13),
              ncol=2,nrow=2,
              common.legend = TRUE, legend="left")

#Save
png("Output/tree_pp_clades2.png",width=12,height=8,units="in",res=300)
pp_tree2
dev.off()

### VERSION 3 ###
# For various threshold values, we plot the predicted probabilities of mammal genera as geom segments corresponding to the tips of a circular mammal tree; colored segments correspond to host positivity distinguished by evidence type

#Make dataframe
samp=data.frame(x=tdata$x,
                y=tdata$y,
                yend=tdata$y,
                xend_pcr=scales::rescale(cdata$data$pred_pcr,c(max(tdata$x),xmax)),
                xend_comp=scales::rescale(cdata$data$pred_comp,c(max(tdata$x),xmax)),
                xend_mean=scales::rescale(cdata$data$pred_mean,c(max(tdata$x),xmax)),
                pcrcomp_rs0.8=(cdata$data$pcrcomp_rs0.8),
                pcrcomp_mss3=(cdata$data$pcrcomp_mss3),
                factor_pcr_rs0.8=as.factor((cdata$data$pcr_rs0.8)),
                factor_pcr_mss3=as.factor((cdata$data$pcr_mss3)),
                factor_comp_rs0.8=as.factor((cdata$data$comp_rs0.8)),
                factor_comp_mss3=as.factor((cdata$data$comp_mss3)),
                treename=tdata$label)

#separate df into predicted host genera and non-predicted host genera for different thresholds
samp_no_rs0.8 <- samp[samp$pcrcomp_rs0.8=="Not predicted",]
samp_pcr_rs0.8 <- samp[samp$pcrcomp_rs0.8=="PCR",]
samp_comp_rs0.8 <- samp[samp$pcrcomp_rs0.8=="Virus isolation",]
samp_both_rs0.8 <- samp[samp$pcrcomp_rs0.8=="Both",]
samp_no_mss3 <- samp[samp$pcrcomp_mss3=="Not predicted",]
samp_pcr_mss3 <- samp[samp$pcrcomp_mss3=="PCR",]
samp_comp_mss3 <- samp[samp$pcrcomp_mss3=="Virus isolation",]
samp_both_mss3 <- samp[samp$pcrcomp_mss3=="Both",]

# Plot base tree and highlight significant clades for PCR model
gg=pbase
for(i in 1:nrow(pcrpred_pf_results)){
  gg=gg+
    geom_hilight(node=pcrpred_pf_results$node[i],
                 alpha=ifelse(pcrpred_pf_results$tips[i]/Ntip(cdata$phy)<0.5,0.5,0.25), 
                 fill="black")
}

# Add PCR pred-probs and assign color based on whether host genera had any predicted host-virus links (binary)
p1=gg+
  geom_segment(
    data=samp_no_rs0.8,
    mapping=aes(x=x,y=y,xend=xend_mean,yend=yend,
                alpha=factor_pcr_rs0.8),
    color="gray", linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(
    data=samp_pcr_rs0.8, 
    mapping=aes(x=x,y=y,xend=xend_pcr,yend=yend,
                colour=factor(pcrcomp_rs0.8)),linewidth=0.75,)+
  geom_segment(
    data=samp_comp_rs0.8, 
    mapping=aes(x=x,y=y,xend=xend_comp,yend=yend,
                colour=factor(pcrcomp_rs0.8)),linewidth=0.75,)+
  geom_segment(
    data=samp_both_rs0.8, 
    mapping=aes(x=x,y=y,xend=xend_mean,yend=yend,
                colour=factor(pcrcomp_rs0.8)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Evidence type")
  # geom_text2(aes(subset = !is.na(label)), label = cdata$phy$tip.label, size = 3, color = "black")

# Competence
gg=pbase
for(i in 1:nrow(comppred_pf_results)){
  gg=gg+
    geom_hilight(node=comppred_pf_results$node[i],
                 alpha=ifelse(comppred_pf_results$tips[i]/Ntip(cdata$phy)<0.5,0.5,0.25),
                 fill="black")
}

# Add preds
p2=gg+
  geom_segment(
    data=samp_no_mss3,
    mapping=aes(x=x,y=y,xend=xend_mean,yend=yend,
                alpha=factor_pcr_mss3),
    color="gray", linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(
    data=samp_pcr_mss3, 
    mapping=aes(x=x,y=y,xend=xend_pcr,yend=yend,
                colour=factor(pcrcomp_mss3)),linewidth=0.75,)+
  geom_segment(
    data=samp_comp_mss3, 
    mapping=aes(x=x,y=y,xend=xend_comp,yend=yend,
                colour=factor(pcrcomp_mss3)),linewidth=0.75,)+
  geom_segment(
    data=samp_both_mss3, 
    mapping=aes(x=x,y=y,xend=xend_mean,yend=yend,
                colour=factor(pcrcomp_mss3)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      name="Evidence type")

pp_tree3=ggarrange(p1,p2,
              labels=c("(A) ReqSens0.8; Th_inf=0.38 & Th_comp=0.26","(B) MaxSensSpec; Th_inf=0.36 & Th_comp=0.22"),
              # font.label(size=10),
              hjust=-0.6,
              label.x=c(0.1,0.1),
              label.y=c(1,1),
              font.label=list(face="plain",size=13),
              ncol=1,nrow=2,
              common.legend = TRUE, legend="left")

# Save
png("Output/tree_pp_clades3.png",width=12,height=8,units="in",res=300)
pp_tree3
dev.off()

```


6. Mapping Host Distribution
============================

### *Load required packages and set system*

```{r map_load}

# Libraries for generating maps
library(classInt)
library(tidyverse)
library(raster)
library(rgdal)  # switches to sf in 2023
library(dismo)
library(XML)
library(maps)
library(sp)
library(dplyr)
library(devtools)
install_github("hunzikp/velox", force=TRUE)
library(velox)
library(fasterize)
library(sf)

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model")

```

### *Get relevant lists of hosts for mapping*

```{r map_prep}

# Before proceeding, make sure you have downloaded "MAMMALS.shp" to your working directory. This shape file of mammal geographic range can be obtained from IUCN Red List Spatial Database: <https://www.iucnredlist.org/resources/spatial-data-download>. This file (>1GB) is only required for this section of the code ("6. Mapping Host Distribution").

# Load file
pred <- read.csv("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model/Output/table_HostTraitModel_predictions.csv")

# Optimal thresholds for PCR
t.pcr <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
                            threshold = 10001,
                            opt.methods = 10,
                            req.sens = 0.90,
                            na.rm = TRUE)

# Optimal threshold for competence
t.comp <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
                             threshold = 10001,
                             opt.methods = 10,
                             req.sens = 0.90,
                             na.rm = TRUE)

# Threshold the results to binary outputs
pred %>%
  mutate(bin_comp = (pred_comp > t.comp$pred_comp),
         bin_pcr = (pred_pcr > t.pcr$pred_pcr)) -> pred


# Get the relevant lists of known and predicted hosts for all OPVs keeping pcr and competence predictions separate 
pred %>% filter(PCR==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known_pcr
pred %>% filter(competence==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known_comp
pred %>% filter(bin_pcr==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_pcr
pred %>% filter(bin_comp==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_comp

#Pull out the relevant lists of predicted unknown hosts for all OPVs keeping pcr and competence predictions separate
unk_pcr <- pred_pcr[!(pred_pcr %in% known_pcr)] #n=197
unk_comp <- pred_comp[!(pred_comp %in% known_comp)] #n=118

# Get the relevant lists of known and predicted hosts for all OPVs combining comp and pcr predictions for manuscript
pred %>% filter(competence==1|PCR==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known #71
pred %>% filter(bin_comp==1|bin_pcr==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred.pcrcomp #n=299
sort(pred.pcrcomp[!(pred.pcrcomp %in% known)]) -> unknown #235

```

### *Create map*

```{r map_create}

# Load shape file of mammal geographic range
iucn <- sf::st_read(dsn = "/Users/katietseng/Fernandez Lab Dropbox/Katie Tseng/Mac/Desktop/PoxHost(copy)/data/raw/MAMMALS/MAMMALS.shp", layer='MAMMALS')

# Make a blank raster (must be connected to wifi for the disaggregate function)
r <- raster::disaggregate(getData("worldclim",var="alt",res=2.5)*0,2)

# Create layers
iucn$treename=sapply(strsplit(iucn$binomial,' '),function(x) paste(x[1],sep=' '))

iucn_known <- iucn[iucn$treename %in% known,] #n=1676
iucn_pcrcomp <- iucn[iucn$treename %in% pred.pcrcomp,] #n=1908
iucn_unknown <- iucn[iucn$treename %in% unknown,] #n=1699

map_known <- (fasterize(iucn_known, r, fun="sum"))
map_pcrcomp <- (fasterize(iucn_pcrcomp, r, fun="sum"))
map_unknown <- (fasterize(iucn_unknown, r, fun="sum"))

# Add zeros for the continental area 
fix <- function(x) {sum(x,r,na.rm=TRUE)+r}

map_known <- fix(map_known)
map_pcrcomp <- fix(map_pcrcomp)
map_unknown <- fix(map_unknown)

raster::stack(map_known, map_pcrcomp, map_unknown) %>% raster::trim() -> maps_hosttraits #alternatively, can use tera package

names(maps_hosttraits) <- c('Host traits model - known', 'Host traits model - pred', 'Host traits model - unknown')

# Generate the actual visualization
library(rasterVis)
library(RColorBrewer)

mycolors <- colorRampPalette(rev(brewer.pal(10,"Spectral")))(21)
mycolors[1] <- "#C0C0C0"

png("Output/Map_HostTraits.png",width=10,height=12,units="in",res=300)
rasterVis::levelplot(maps_hosttraits,  
                     col.regions = mycolors,
                     #at = seq(0, 15, 1),
                     alpha = 0.5, 
                     scales=list(alternating=FALSE),
                     par.strip.text=list(cex=0),
                     xlab = NULL, ylab = NULL,
                     labels = labels,
                     maxpixels = 5e6)
dev.off()

```

7. Feature Importance
=====================

In this chapter, we examine predictions from our BRT model identifying and ranking the importance of model features.

### *Load required packages and set system*

```{r pred_load}

# Libraries for BRT figures
library(tidyr)
library(ggplot2)
library(fastDummies)
library(caper)
library(phylofactor)
library(plotrix) #std.error
library(rstatix) 
library(ggrepel)
library(ggpubr) #ggarrange
library(dplyr)

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model")

```

### *Identify and rank relative feature importance*
We compare and contrast the relative feature importance of the predictors in our PCR vs. competence models, determining the mean, variance, and standard error for each model. We then rank features by their relative importance, focusing on the top 10 predictive features. 
Figure: *boxplot_trait_ranking.png*
Table: *table_ranks.csv*

```{r feat_rank}

# Load model predictions
pcr_brts <- readRDS("Output/pcr brts.rds")
comp_brts <- readRDS("Output/comp brts.rds")
pm_brts <- readRDS("Output/pm brts.rds")

# What was the relative importance/influence of each feature in the infection model? Get values.
vinf=lapply(pcr_brts,function(x) x$rinf)
pcr_vinf=do.call(rbind,vinf)

# What was the relative influence of each feature in the competence model? Get values.
vinf=lapply(comp_brts,function(x) x$rinf)
comp_vinf=do.call(rbind,vinf)

# What was the mean, standard error, and variance of feature relative influence in the infection model?
vdata_pcr=data.frame(aggregate(rel.inf~var,data=pcr_vinf,mean),
                     aggregate(rel.inf~var,data=pcr_vinf,std.error)["rel.inf"],
                     aggregate(rel.inf~var,data=pcr_vinf,var)["rel.inf"])
names(vdata_pcr)=c("var","rel.inf","rse","rvar")
vdata_pcr=vdata_pcr[order(vdata_pcr$rel.inf,decreasing=T),]

# What was the mean, standard error, and variance of feature relative influence in the competence model?
vdata_comp=data.frame(aggregate(rel.inf~var,data=comp_vinf,mean),
                      aggregate(rel.inf~var,data=comp_vinf,std.error)["rel.inf"],
                      aggregate(rel.inf~var,data=comp_vinf,var)["rel.inf"])
names(vdata_comp)=c("var","rel.inf","rse","rvar")
vdata_comp=vdata_comp[order(vdata_comp$rel.inf,decreasing=T),]

# How does the average variance compare between the infection and competence model?
mean(vdata_pcr$rvar)
mean(vdata_comp$rvar)

# How does the variance of relative influence compare between the infection and competence model?
var(vdata_pcr$rel.inf)
var(vdata_comp$rel.inf)

# Can we rank features by their relative influence?
vdata_pcr$pcr_rank=1:nrow(vdata_pcr)
vdata_comp$comp_rank=1:nrow(vdata_comp)

# What is their relative influence/importance as a proportion?
vdata_pcr$pcr_imp=vdata_pcr$rel.inf/100
vdata_comp$comp_imp=vdata_comp$rel.inf/100

# Combine the rankings
ranks=merge(vdata_pcr[c("var","pcr_rank","pcr_imp")],
            vdata_comp[c("var","comp_rank","comp_imp")],
            by="var")

# Create a table of ranked features and their relative importance
table_ranks=ranks
table_ranks$feature=table_ranks$var
table_ranks=table_ranks[c("feature","pcr_imp","comp_imp","pcr_rank","comp_rank")]
write.csv(table_ranks,"Output/table_ranks.csv")

# Create a list of the top 10 variables
keep_pcr <- ranks$var[which(ranks$pcr_rank<=10)]
keep_comp <- ranks$var[which(ranks$comp_rank<=10)]

# Get the relative importance values for the top 10 features of the infection model
vinf=lapply(pcr_brts,function(x) x$rinf)
pcr_vinf=do.call(rbind,vinf)
pcr_vinf <- pcr_vinf[which(pcr_vinf$var%in%keep_pcr),]
pcr_vinf$rel.inf <- pcr_vinf$rel.inf/100

# Boxplot relative feature importance for the infection model
boxplot_trait_pcr <- ggplot(pcr_vinf) + ggtitle("(A) Host-trait infection model") +
        geom_boxplot(aes(x=rel.inf, y=reorder(var,rel.inf), group=var), width=0.5, alpha=0.25) +
        theme_bw() +
        labs(x="Relative influence",
             y="Features") + 
        theme(axis.text.y=element_text(size=10),
              axis.text.x=element_text(size=12),
              axis.title.x=element_text(size=12, margin=margin(t=10,r=0,b=0,l=0)),
              axis.title.y=element_text(size=12, margin=margin(t=0,r=10,b=0,l=0)),
              strip.text=element_text(size=12))

# Get the relative importance values for the top 10 features of the competence model
vinf=lapply(comp_brts,function(x) x$rinf)
comp_vinf=do.call(rbind,vinf)
comp_vinf <- comp_vinf[which(comp_vinf$var%in%keep_pcr),]
comp_vinf$rel.inf <- comp_vinf$rel.inf/100

# Boxplot relative feature importance for the competence model
boxplot_trait_comp <- ggplot(comp_vinf) + ggtitle("(B) Host-trait competence model") +
        geom_boxplot(aes(x=rel.inf, y=reorder(var,rel.inf), group=var), width=0.5, alpha=0.25) +
        theme_bw() +
        labs(x="Relative influence",
             y="Features") + 
        theme(axis.text.y=element_text(size=10),
              axis.text.x=element_text(size=12),
              axis.title.x=element_text(size=12, margin=margin(t=10,r=0,b=0,l=0)),
              axis.title.y=element_text(size=12, margin=margin(t=0,r=10,b=0,l=0)),
              strip.text=element_text(size=12))

# Combine boxplots of relative feature importance
png("Output/boxplot_trait_ranking.png",width=10,height=10,units="in",res=300)
ggarrange(boxplot_trait_pcr,boxplot_trait_comp,ncol=2,nrow=1,
          font.label=list(face="plain",size=12))
dev.off()

rm(pcr_vinf,comp_vinf,vinf,boxplot_trait_pcr, keep_comp, keep_pcr, boxplot_trait_comp, vdata_comp,vdata_pcr, table_ranks)

```

### *Identify consistently important and unimportant host traits*
Figure: *scatterplot_trait_ranking.png*

```{r feat_consistent}

# Were the rankings of relative feature importance significantly correlated?
cor.test(ranks$pcr_rank,ranks$comp_rank,method="spearman")

# What if we remove traits with zero/no relative importance and rerank?
ranks2=ranks[-which(ranks$pcr_imp==0 & ranks$comp_imp==0),]
ranks2=ranks2[order(ranks2$pcr_imp,decreasing=T),]
ranks2$pcr_rank=1:nrow(ranks2)
ranks2=ranks2[order(ranks2$comp_imp,decreasing=T),]
ranks2$comp_rank=1:nrow(ranks2)

# Are rankings still correlated after removing traits with zero/no relative importance?
cor.test(ranks2$pcr_rank,ranks2$comp_rank,method="spearman")

# Can we identify features with high residuals?
ranks2$resid=abs(resid(lm(comp_rank~pcr_rank,data=ranks2)))  # extract residuals from linear regression as absolute values

# Plot residuals
plot(ranks2$pcr_rank,ranks2$resid,
     ylab="Residuals",xlab="pcr_rank", 
     main="comp_rank")

# Were any  residual values greater than 10 or greater than 18? Flag residuals.
#ranks2$select=ifelse(ranks2$resid>10,"yes","no")
ranks2$select=ifelse(ranks2$resid>18,"yes","no")
which(ranks2$resid>20) # returns 5 values

# Were any features consistenly high or low ranking across both infection and competence models? Flag.
n=7
ranks2$select=ifelse(ranks2$comp_rank<n & ranks2$pcr_rank<n,"yes",ranks2$select)
ranks2$select=ifelse(ranks2$comp_rank%in%tail(1:nrow(ranks2),n) & ranks2$pcr_rank%in%tail(1:nrow(ranks2),n),"yes",ranks2$select)

# Get the names of consistently high or low ranking features
rset=ranks2
rset$var=ifelse(rset$select=="yes",rset$var,"")

# Plot feature ranking of infection model against competence model and label traits that were consistently important and unimportant
set.seed(1)
png("Output/scatterplot_trait_ranking.png",width=7,height=7,units="in",res=300)
ggplot(ranks2,aes(pcr_rank,comp_rank))+
  geom_text_repel(data=rset,aes(label=var),size=2,force=4,direction="both",
                  segment.size=0.5,segment.color="grey")+
  geom_point()+
  scale_y_reverse(limits=c(max(c(ranks2$comp_rank,ranks2$pcr_rank))+4,0))+
  scale_x_reverse(limits=c(max(c(ranks2$comp_rank,ranks2$pcr_rank))+4,0))+
  theme_bw()+
  labs(x="Feature rank for infection model",y="Feature rank for competence model")+
  theme(axis.text=element_text(size=10),axis.title=element_text(size=12))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))
dev.off()

# Clean environment
rm(rset, n)

```

### *Determine effect directions of each feature on the predicted outcome*
We determine the effect directions of each feature on host prediction using partial dependence plots. These plots allow us to visualize the relationship between a subset of features and the response variable (OPV positivity) while accounting for the average effect of the other predictors in the model.
Figures: *pdplot_trait_effect.png*

```{r feat_effect}

# Download library for partial dependence plots
# detach("package:purrr", unload=TRUE)
library(pdp)
library(gbm)

# Create a function for compiling across BRTs for a given predictor, all else equal
pdp_agg=function(mod,feature){
  
  ## just the plot function
  pdep=plot(mod$mod,feature,
            return.grid=T,
            n.trees=mod$best,
            plot=F,
            continuous.resolution=200,
            type="response")
  
  ## add seed
  pdep$seed=unique(mod$roc$seed)
  
  ## save predictor
  pdep$predictor=pdep[feature][,1]
  
  ## order
  pdep=pdep[order(pdep$predictor),]
  
  ## get rank
  pdep$rank=1:nrow(pdep)
  
  ## save yhat
  pdep$yhat=pdep$y
  
  ## return
  return(pdep)
  
}

# Create a function to plot the PDPs
pdp_plot=function(bmods,feature){
  
  ## pdp_agg
  agg=do.call(rbind,lapply(bmods,function(x) pdp_agg(x,feature)))
  
  ## get class of the feature
  cl=class(data[feature][,1])
  
  ## if else based on type
  if(cl%in%c("numeric","integer")){
    
    ## get element-wise means
    x=with(agg,tapply(predictor,rank,mean))
    y=with(agg,tapply(yhat,rank,mean))
    
    ## save as mean
    pmean=data.frame(predictor=x,yhat=y)
    
    ## get yrange
    yrange=range(agg$yhat,pmean$yhat,na.rm=T)
    
    ## get histogram
    hi=hist(data[feature][,1],breaks=30,plot=F)
    hi=with(hi,data.frame(breaks[1:(length(breaks)-1)],counts))
    names(hi)=c("mids","counts")
    
    ## ggplot it
    ggplot(agg,aes(predictor,yhat,group=seed))+
      
      ## add histogram
      geom_segment(data=hi,inherit.aes=F,
                   aes(x=mids,xend=mids,
                       y=yrange[1],yend=plotrix::rescale(counts,yrange)),
                   size=1,colour="grey",alpha=0.25)+
      
      ## add lines
      geom_line(linewidth=1,alpha=0.25,colour="grey")+
      
      ## add mean
      geom_line(data=pmean,linewidth=2,inherit.aes=F,
                aes(predictor,yhat))+
      
      ## theme
      theme_bw()+
      theme(axis.text=element_text(size=6),
            axis.title=element_text(size=7))+
      theme(axis.title.x=element_text(margin=margin(t=5,r=0,b=0,l=0)))+
      theme(axis.title.y=element_text(margin=margin(t=0,r=5,b=0,l=0)))+
      theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
      labs(x=feature,y="marginal effect")+
      scale_y_continuous(labels=scales::number_format(accuracy=0.01))
    
    ## end numeric
  }else{ ## factor-based plot
    
    ## get element-wise means
    y=with(agg,tapply(yhat,predictor,mean))
    
    ## save as mean
    #pmean=data.frame(predictor=x,yhat=y)
    pmean=data.frame(y)
    names(pmean)="yhat"
    pmean$predictor=rownames(pmean)
    rownames(pmean)=NULL
    
    ## make temp data
    temp=data
    temp$predictor=temp[feature][,1]
    
    ## do nothing
    agg=agg
    pmean=pmean
    temp=temp
    
    ## get yrange
    yrange=range(agg$yhat,pmean$yhat,na.rm=T)
    
    ## fix temp to yrange
    temp$yhat=ifelse(temp$pcr==1,max(yrange),min(yrange))
    
    ## ggplot with rug
    set.seed(1)
    ggplot(agg,aes(predictor,yhat,group=seed))+
      
      ## add individual BRTs
      geom_jitter(size=1,alpha=0.25,colour="grey",width=0.1)+
      
      ## add mean
      geom_point(data=pmean,size=2,inherit.aes=F,shape=15,
                 aes(predictor,yhat))+
      
      ## add rug
      geom_rug(data=temp,inherit.aes=F,
               aes(predictor,yhat),
               sides="b",position="jitter",
               colour="grey",alpha=0.25,
               na.rm=T)+
      
      ## theme
      theme_bw()+
      theme(axis.text=element_text(size=6),
            axis.title=element_text(size=7))+
      theme(axis.title.x=element_text(margin=margin(t=5,r=0,b=0,l=0)))+
      theme(axis.title.y=element_text(margin=margin(t=0,r=5,b=0,l=0)))+
      theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
      labs(x=feature,y="marginal effect")+
      scale_y_continuous(limits=c(yrange[1]-0.01,yrange[2]+0.01),
                         labels=scales::number_format(accuracy=0.01))
    
  }
  
}

# Load cleaned data file
load("Output/HostTraitModel_CleanData.RData")
data <- poxdata

# Make binary columns for each taxonomic family in our dataset
dums=fastDummies::dummy_cols(data["fam"])

# Get only unique observations
dums=dums[!duplicated(dums$fam),]

# Ensure all are factor
for(i in 1:ncol(dums)){
  
  ## column as factor
  dums[,i]=factor(dums[,i])
  
}

# Merge family variables with poxdata
data=merge(data,dums,by="fam",all.x=T)
rm(dums)

# PDPs for top ranking features of the infection model
ranks2=ranks2[order(ranks2$pcr_rank),]
p1=pdp_plot(pcr_brts,ranks2$var[1])
p2=pdp_plot(pcr_brts,ranks2$var[2])
p3=pdp_plot(pcr_brts,ranks2$var[3])
p4=pdp_plot(pcr_brts,ranks2$var[4])
p5=pdp_plot(pcr_brts,ranks2$var[5])
p6=pdp_plot(pcr_brts,ranks2$var[6])
p7=pdp_plot(pcr_brts,ranks2$var[7])
p8=pdp_plot(pcr_brts,ranks2$var[8])
p9=pdp_plot(pcr_brts,ranks2$var[9])
p10=pdp_plot(pcr_brts,ranks2$var[10])

# PDPs for top ranking features of the competence model
ranks2=ranks2[order(ranks2$comp_rank),]
c1=pdp_plot(comp_brts,ranks2$var[1])
c2=pdp_plot(comp_brts,ranks2$var[2])
c3=pdp_plot(comp_brts,ranks2$var[3])
c4=pdp_plot(comp_brts,ranks2$var[4])
c5=pdp_plot(comp_brts,ranks2$var[5])
c6=pdp_plot(comp_brts,ranks2$var[6])
c7=pdp_plot(comp_brts,ranks2$var[7])
c8=pdp_plot(comp_brts,ranks2$var[8])
c9=pdp_plot(comp_brts,ranks2$var[9])
c10=pdp_plot(comp_brts,ranks2$var[10])

# Plot compield PDPs of the top ranked features for both infection and competence models
library(patchwork)
pdplot_pcr <- p1+p2+p3+p4+p5+p6+p7+p8+p9+p10+plot_layout(nrow=10,ncol=1,byrow=F)
pdplot_comp <- c1+c2+c3+c4+c5+c6+c7+c8+c9+c10+plot_layout(nrow=10,ncol=1,byrow=F)
png("Output/pdplot_trait_effect.png",width=4,height=10,units="in",res=300)
ggarrange(pdplot_pcr,pdplot_comp,ncol=2,nrow=2,widths=c(4,4),heights=c(22,1),
          labels=c("(A) Infection model","(B) Competence model"),
          label.x=c(0,-0.1), label.y=0.001,
          font.label=list(face="plain",size=12))
dev.off()

# Clean environment
rm(pdp_agg,pdp_plot,pdp_pcr,pdp_comp,p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,
   c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,
   ranks,ranks2,adata)

```