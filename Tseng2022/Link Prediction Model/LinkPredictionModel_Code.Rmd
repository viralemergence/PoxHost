---
title: "Orthopoxvirus Link Prediction Model Code"
author: "Katie Tseng, Dan Becker, Colin Carlson, Pilar Fernandez, and Stephanie Seifert"
output:
  pdf_document:
  latex_engine: xelatex
  toc: yes
html_document:
  fig_height: 6
  fig_width: 6
  highlight: tango
  theme: journal
editor_options: 
  chunk_output_type: console
---

Introduction
============

The following code reproduces the analyses from <...>, pertaining to the link prediction model. The code is subdivided into five parts (see Table of Contents below). To reproduce the analyses pertaining to the host prediction model, please see the markdown file *HostTraitModel_Code.Rmd* located in the [PoxHost repository][1].

To run the following script, four files are required in your working directory:

- *Data_raw.RData*: the raw data file
- *OPVnew_nowwithVirus.xlsx*: the excel file of OPV genome annotations
- *~/Output/*: folder where all output (e.g., cleaned datasets, model results, figures, and tables) will be saved 
- *MAMMALS.shp*: the shape file of mammal geographical range 
    - Obtained[IUCN Red List Spatial Database][2]  
    - This file (>1GB) is only required in part six: *Mapping Host Distribution*  
[1]: <https://github.com/viralemergence/PoxHost> "PoxHost"
[2]: <https://www.iucnredlist.org/resources/spatial-data-download> "Spatial data download"

Table of Contents
=================

1. Dimension Reduction {r dim}

2. Data Preparation {r prep}

3. BRT Model {r brt}

4. Model Performance {r perf}

5. Model Predictions {r pred}

6. Mapping Host Distribution {r map}

7. Feature Importance {r feat}

### *Before proceeding, we recommend setting knit options* 

```{r, knitr}

knitr::opts_chunk$set(eval=F)

```

1. Dimension Reduction
======================

In this section, we draw from our dataset of annotated OPV genomes (n=197 unique sequences; see genome annotation pipeline in methods section for more information), which compose our known host-OPV associations for incorporation in the link prediction model. Each sequence is classified by its source or virus species and its host, as well as the presence (1) or absence (0) of a suite of OPV accessory genes. Because our data consists of over 981 OPV accessory genes, the goal of this section is to reduce the number of viral predictors for incorporation in the link prediction model, while maintaining maximal variance. Using principal components analysis (PCA), a method of dimension reduction, we distill the variables down to their most important features. We also explore which sequences have the most similar values (aka, how do they group?) in the principal components using k-means clustering. Because we are analyzing presence/absence data (binary variables), we use multiple correspondence analysis (MCA) to further validate our results. Though similar to PCA, MCA is used to analyze datasets with multiple categorical variables. 

### *Load required packages and set system*

```{r dim_load, message=FALSE, warning=FALSE}

# Libraries for preparing data for analysis
library(ape)
library(dplyr)
library(nlme)
library(tidyverse)
library(vroom) 
library(readxl)
library(ggplot2)

# Libraries for PCA (principal components analysis)
library(vegan)
library(factoextra) #fviz_eig
library(ggfortify)

# Libraries for MCA
library(FactoMineR)
library(dplyr)
library(factoextra) #fviz_eig

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

### *Prepare genomic data for dimension reduction*
We clean our sequence data and explore the variability in the data.
Figures: *histogram_var_genes.png*
Tables: *table_frequency_seqbyvirus.csv*

```{r dim_genes}

# Load genome annotations and trim
genes <- read_xlsx("OPVnew_nowwithVirus.xlsx", sheet="PoxHost")

# Rename variables and exclude unnecessary variables
genes <- plyr::rename(genes, c("Virus"="VirusSpecies","Host Genus"="HostGenus","Host Species"="HostSpecies"))
genes <- subset(genes, select=-c(HostSpecies))

# Correct sequence MT903347_1 - 'HostGenus' var lists Family name instead of Genus
genes$HostGenus <- ifelse(genes$HostGenus=="Gliridae","Graphiurus",genes$HostGenus)

# Add unique identifier
genes$rownames <- rownames(genes)
genes$Sequence <- paste(genes$Genome,genes$VirusSpecies,genes$HostGenus,sep="_",genes$rownames)
genes$rownames=NULL
genes <- genes %>% dplyr::select(Sequence, everything())

# View frequency of various virus species
prop_table <- subset(genes, select=-c(Sequence,Genome))
prop_table$Frequency = 1 
prop_table <- aggregate(Frequency ~ VirusSpecies + HostGenus, data=prop_table, FUN=sum)
prop_table <- prop_table[order(prop_table[,c("VirusSpecies")],prop_table[,c("HostGenus")]) ,]
prop_table$Perc <- prop_table$Frequency/sum(prop_table$Frequency)*100
print(prop_table)

# Save frequency table to Output folder
write.csv(prop_table, "Output/table_frequency_seqbyvirus.csv")

# Create function (mode.prop) to assess variation in the presence/absence of OPV genes
mode.prop <- function(x) {                
  ux <- unique(x[is.na(x)==FALSE])        # creates array of unique values
  tab <- tabulate(match(na.omit(x), ux))  # creates array of the frequency (number of times) each unique value appears in the column 
  max(tab)/length(x[is.na(x)==FALSE])     # max-frequency / number of elements in each column that are not NA
}

# Assess variation across columns (2 indicates columns)
vars=data.frame(apply(genes,2,function(x) mode.prop(x)),
                apply(genes,2,function(x) length(unique(x)))) # number of unique elements in each column
vars$variables=rownames(vars)
colnames(vars) <- c("var","uniq","column")

# Trim
vars <- vars[-c(1:4), ]

# Any variables with no variation? If so drop
which(vars$var==1)
# vars <- subset(vars,vars$var<1)

# Visualize distribution of variation
gene_var <- ggplot(vars,
       aes(var))+
  geom_histogram(bins=50)+
  geom_vline(xintercept=0.70,linetype=2,linewidth=0.5)+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  labs(y="Frequency",
       x="Variance in the presence/absence of genes")+
  scale_x_continuous(labels=scales::percent)

# Save figure
png("Output/histogram_var_genes.png", width=4,height=4,units="in",res=600)
gene_var
dev.off()

# Clean environment
rm(list=setdiff(ls(), c("genes")))

```

### *PCA of viral accessory genes*
Using principal components analysis, can we distill the variables down to their most important features? Which genes contribute the most to each feature?
Figure: *histogram_loadings.png*
Table: *table_pca_importance.csv*, *table_ranked_loadings.csv*

```{r dim_pca}

# Apply PCA using stats::prcomp 
pca <- prcomp(genes[,5:985])      #scaling/centering not appropriate
relvar <- pca$sdev^2 / sum(pca$sdev^2)
relvar_per <- round(relvar*100,1)

# View summary results
summary(pca)
View(pca$x) #sequence (individuals)
View(pca$rotation) #genes (variables)

# Table of importance of components: Eigenvalue (variance explained by each PC), SD, proportion of variance, and cumulative proportion
importance <- as.data.frame(t(summary(pca)$importance))
importance$Eigenvalue <- importance$`Standard deviation`^2
importance <- importance %>% dplyr::relocate(Eigenvalue) 
importance <- importance[c(1:12),]
write.csv(importance,"Output/table_pca_importance.csv")

# Table of loadings: Rotation is the matrix of variable loadings where columns are eigenvectors
loadings <- as.data.frame(pca$rotation)
loadings <- loadings[,c(1:10)]
# loadings <- abs(loadings) #get absolute values; why are some loadings > |1|? Loading is the covariances/correlations b/w original vars and unit-scaled components)

### Create a dataframe of ranked loadings with corresponding gene names for each PC1-PC10)

# For each PC/dimension, create a dataframe of gene loadings named after the PC
for(i in 1:ncol(loadings)){
  assign(colnames(loadings)[i], data.frame(loadings[,i]))
}

# Create a list of PC dataframe names, and using lapply, combine the dataframes of PC loadings into a single list
list <- colnames(loadings)       
list_df = lapply(list, get)

# To each dataframe in that list, add corresponding gene name and sort in descending order (genes with highest load value to smallest load value)
for (i in 1:length(list)) {
  colnames(list_df[[i]]) <- "Loadings"
  list_df[[i]]$Gene <- rownames(loadings)
  list_df[[i]]=list_df[[i]][order(-list_df[[i]]$Loadings),]
}

# Create df of just ranked genes by first dropping loadings from the list
genes_df <- list_df
for(i in 1:length(list)) {
  genes_df[[i]]$Loadings=NULL
}

# Next, create an empty matrix with PCs as column names
rank_genes <- data.frame(matrix(ncol=ncol(loadings), nrow=nrow(loadings)))
colnames(rank_genes) <- colnames(loadings)

# To each column of the matrix, add the ranked genes for each PC, and set column names
for(i in 1:length(list)) {
  rank_genes[,i] = genes_df[[i]]
}
rank_genes <- setNames(rank_genes, paste0(names(loadings), '_', 'Gene'))

# Create df of just ranked loadings by first dropping gene names from the list
loadings_df <- list_df
for(i in 1:length(list)) {
  loadings_df[[i]]$Gene=NULL
}

# Next, create an empty matrix with PCs as column names
rank_loadings <- data.frame(matrix(ncol=ncol(loadings), nrow=nrow(loadings)))
colnames(rank_loadings) <- colnames(loadings)

# To each column of the matrix, add the ranked loadings for each PC, and set column names
for(i in 1:length(list)) {
  rank_loadings[,i] = loadings_df[[i]]
}
rank_loadings <- setNames(rank_loadings, paste0(names(loadings), '_', 'Loadings'))

# Now, combine dfs of ranked genes and loadings
rank_PC <- cbind(rank_genes, rank_loadings)
rank_PC <- rank_PC[,order(colnames(rank_PC))] 

# Reorder the columns
rank_PC <- rank_PC %>% relocate(c("PC10_Gene","PC10_Loadings"), .after = last_col())

# Save table of PCA Loadings Ranked
write.csv(rank_PC, "Output/table_ranked_loadings.csv")

# Distribution of loadings for each PC (particularly PC1, PC3, PC4, PC9)
loadings <- as.data.frame(pca$rotation)
loadings <- loadings[,c(1:10)]
loadings_abs <- abs(loadings) #get absolute values

library(reshape2)
hist_loadings=ggplot(melt(loadings),aes(x=value)) + geom_histogram() + facet_wrap(~variable)
hist_loadings_abs=ggplot(melt(loadings_abs),aes(x=value)) + geom_histogram() + facet_wrap(~variable)
hist_loadings_abslim=ggplot(melt(loadings_abs),aes(x=value)) + geom_histogram() + xlim(0.05,0.20) + facet_wrap(~variable)

# Save figure
png("Output/histogram_loadings.png", width=4,height=4,units="in",res=600)
hist_loadings
dev.off()

# Save datafile of PC scores for link prediction
wgs_PCs <- genes[,1:4]
wgs_PCs <- cbind(wgs_PCs, pca$x[,1:10])
save(wgs_PCs, file='Output/wgs_PCs.RData')

# Clean environment
rm(list=setdiff(ls(), c("genes","pca","relvar","relvar_per")))

```

### *PCA visualizations*
Which dimensions contribute the most?
Figures: *screeplot_dim_pca.png*, *screeplot_var_pca.png*, *plot_cumvar_pca.png*, *plot_scores_pca_dim1and2_ellipses.png*, *plot_scores_pca_dim1and2_byvirus.png*, *plot_loadins_pca_dim1and2.png*, *plot_loadings_pca_dim3and4.png*, *biplot_pca_dim1and2.png*,
*biplot_pca_dim1and2_top20.png*

```{r dim_pca_viz}

### Vizualize variance

# Screeplot of variance (eigenvalues) to show the decreasing rate at which variance is explained by additional PCs
png("Output/screeplot_var_pca.png", width=4,height=4,units="in",res=600)
screeplot(pca, type="lines", npcs=15, main="Scree plot of Eigenvalues for the first 15 PCs")
abline(h=1, col="red", lty=5)
legend("topright", legend=c("Eigenvalue = 1"), col=c("red"), lty=5, cex=1)
dev.off()
### suggests cutoff at PC12

# Screeplot of cumulative variance to show the % variance explained by additional PCs
screeplot_var <- barplot(relvar_per[1:10], xlab='PC', ylab='Percentage of explained variances', main='Screeplot of explained variances', names.arg=1:10, las=1, ylim=c(0,max(relvar_per)+10), col='gray')
text(screeplot_var, 0, y=relvar_per[1:10], label=relvar_per[1:10],cex=0.8, pos=3, col="red")

# Plot cumulative variance to show the proportion of variance explained with each add'l PC
cumpro <- cumsum(pca$sdev^2 / sum(pca$sdev^2))
png("Output/plot_cumvar_pca.png", width=4,height=4,units="in",res=600)
plot(cumpro[0:15], xlab = "Dimension", ylab = "Proportion of explained variance", main = "Cumulative variance plot")
abline(v = 10, col="blue", lty=5)
abline(h = 0.7, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC10"), col=c("blue"), lty=5, cex=1)
dev.off()

### Vizualize individuals/scores

# Plot sequences on dim 1 and 2 (with ellipses)
png("Output/plot_scores_pca_dim1and2_ellipses.png", width=6, height=6, units="in", res=600)
fviz_pca_ind(pca, geom.ind = "point", pointshape = 21, pointsize = 2, 
             col.ind = "black", addEllipses = TRUE, label = "var",
             col.var = "black", repel = TRUE,
             alpha.ind = 0.7) +
             ggtitle("PCA Plot of Sequences") +
             theme(plot.title = element_text(hjust = 0.5))
dev.off()

# Plot sequences by virus species for dim 1 and 2
png("Output/plot_scores_pca_dim1and2_byvirus.png", width=6,height=4,units="in",res=600)
autoplot(pca, data = genes, colour = 'VirusSpecies') 
# + ggtitle("Plot of Sequences by Virus Species")
dev.off()

### Vizualize variables/loadings (biplots)

# Plot gene loadings for dim 1 and 2
png("Output/plot_loadins_pca_dim1and2.png", width=6,height=4,units="in",res=600)
fviz_pca_var(pca, 
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             # select.var=list(contrib=50),   # modify the number of loadings to include
             labelsize=1,
             label = c("ind", "ind.sup", "quali", "var", "quanti.sup"))
             # + ggtitle("Plot of Gene Loadings for Dimensions 1 and 2")
dev.off()
### Here we see PC1 has large positive associations with a number of AGs like ADZ29556.1, SNB51281.1, and AGZ01283.1 that point in the same direction as PC1. PC2 has some moderately positive associations with AGs like BDQ10560.1
### QKE61192.1 - hypothetical protein [Vaccinia virus]
### QNP13375.1 - MPXV Viral membrane assembly proteins (VMAP) (Cop-A 30.5L)"

# Plot gene loadings for dim 3 and 4
png("Output/plot_loadings_pca_dim3and4.png", width=6,height=4,units="in",res=600)
fviz_pca_var(pca, axes = c(3, 4),
             col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,
             # select.var=list(contrib=50),   # modify the number of loadings to include
             labelsize=1)
             # + ggtitle("Plot of Gene Loadings for Dimensions 3 and 4")
dev.off()

# Biplot sequences and gene loadings
png("Output/biplot_pca_dim1and2.png", width=6,height=4,units="in",res=600)
fviz_pca_biplot(pca, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
                repel = TRUE,
                labelsize=1)
                # + ggtitle("Biplot of Sequences and Gene Loadings")
dev.off()

# Biplot top 20 influential scores and loadings
png("Output/biplot_pca_dim1and2_top20.png", width=6,height=4,units="in",res=600)
fviz_pca_biplot(pca, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, 
             labelsize=3,
             select.ind=list(contrib=20), select.var=list(contrib=20))
             # + ggtitle("Biplot of Top 20 Contributing Sequences and Gene Loadings")
dev.off()

# Clean environment
rm(list=setdiff(ls(), c("genes","pca")))

```

### *PCA Hierarchical Cluster Analysis*
Figures: *linegraph_optclusters_pca.png*, *clustree_pca.png*, *clustree_stability_pca.png*, *clustree_overpc1and2.png*, *cluster_dendogram.png*, *cluster_dendogram_rectangle.png*, *plot_scores_pca_bycluster.png*
Tables: *table_scores_pca_bycluster.csv*

```{r dim_cluster}

### Determine Optimal Number of Clusters ###

library(clustree)

# Extract coordinates for individual sequences
ind.coord <- pca$x
rownames(ind.coord) <- genes$VirusSpecies
ind.coord <- ind.coord[,1:10]

###Elbow method
# Calculate/graph the sum of squares at each number of clusters. Assess how the slope changes from steep to shallow (an elbow) to determine the optimal number of clusters. How does increasing the number of the clusters contribute to separating the clusters in a meaningful way based on intra-cluster variance?

# Set seed and execute
set.seed(31)
png("Output/linegraph_optclusters_pca.png", width=4,height=4,units="in",res=600)
fviz_nbclust(ind.coord, kmeans, method = "wss", k.max = 20) + theme_minimal() 
# + ggtitle("the Elbow Method")
dev.off()

#### Clustree method
# How do samples change groupings as the number of clusters increases? Clustree shows which clusters are distinct and which are unstable. It doesn’t explicitly tell you which choice of optimal clusters is but it is useful for exploring possible choices.

# Execution of k-means with 1 to 10 clusters
tmp <- NULL
for (k in 1:10){
  tmp[k] <- kmeans(ind.coord, k, nstart = 30) #generates 30 initial configs & avg all centroid results 
}

# Convert to dataframe
df <- data.frame(tmp)

# Add a prefix to the column names of df
colnames(df) <- seq(1:10)
colnames(df) <- paste0("k",colnames(df))

# Combine clustering data w/ PC loading values
df <- bind_cols(as.data.frame(df), as.data.frame(ind.coord))

# Execute clustree
png("Output/clustree_pca.png", width=6,height=8,units="in",res=600)
clustree(df, prefix = "k")
dev.off()
### note: nodes with multiple incoming edges indicate that we over-clustered the data

# Execute clustree, but display stability index by colour as opposed to count
png("Output/clustree_stability_pca.png", width=6,height=8,units="in",res=600)
clustree(df, prefix = "k", node_colour = "sc3_stability")
dev.off()
### note: k=6 appears to be the most stable number of clusters

# Execute clustree_overlay, overlaying PC1 on PC2 to assess quality of the clustering
df_subset <- df %>% dplyr::select(1:10,11:12)
png("Output/clustree_overpc1and2.png", width=9, height=12, units="in", res=600)
clustree_overlay(df_subset, prefix = "k", x_value = "PC1", y_value = "PC2")
dev.off()


# Execute clustree overlaying PC vs. k (resolution dimension)
overlay_list <- clustree_overlay(df_subset, prefix = "k", x_value = "PC1",
                                 y_value = "PC2", plot_sides = TRUE)
overlay_list$x_side  #PC1
overlay_list$y_side  #PC2

### Conduct Hierarchical Cluster Analysis ###
# Each object is assigned its own cluster iteratively, at each stage joining the 2 most similar clusters (bottom-up dendogram until only one cluster is left)

# Extract coordinates for individual sequences
ind.coord <- pca$x
rownames(ind.coord) <- genes$VirusSpecies
ind.coord <- ind.coord[,1:10]

# Calculate distance matrix
pc.dist <- dist(ind.coord, method="euclidean")

# Execute HCA
clusters <- hclust(pc.dist)

# Plot dendogram
png("Output/cluster_dendogram.png", width=8,height=5,units="in",res=600)
plot(clusters, cex=0.2)
dev.off()

# For k=6, add rectangular outline to each cluster in the dendrogram
png("Output/cluster_dendogram_rectangle.png", width=8,height=5,units="in",res=600)
plot(clusters, cex=0.2)
rect.hclust(clusters, k = 6, border = 2:8) # add rectangle
dev.off() 

# For k=6, view count of each cluster
clusterCut <- cutree(clusters, k = 6)
table(clusterCut)

# Prop tables by virus species
mytable<-table(clusterCut, genes$VirusSpecies)
mytable2 <- data.frame(prop.table(mytable,2))
ggplot(mytable2, aes(x = Var2, y = Freq, fill = clusterCut)) +
  geom_col() +
  labs(fill='Cluster') +
  theme(axis.title.x = element_blank(), axis.text.x = element_text(angle=45,hjust=1)) +
  ggtitle("Distribution by Virus Species")

# Re-run PCA to color by cluster  
  #add cluster to original db
  genes1<-data.frame(cbind(genes,clusterCut))
  genes1$clusterCut <- as.factor(genes1$clusterCut)

# Run PCA as before, but now grouping by cluster
pca_bycluster <- prcomp(genes1[,5:985])   

# color-blind friendly palette:
cbPalette1 <- c("#009292","#ff6db6","#ffb6db","#490092","#6db6ff","#db6d00")
cbPalette2 <- c("#E69F00", "#56B4E9", "#009E73", "#0072B2", "#D55E00", "#CC79A7")

# Plot of sequences by cluster
png("Output/plot_scores_pca_bycluster.png", width=8,height=5,units="in",res=600)
fviz_pca_ind(pca_bycluster, geom.ind = "point", pointshape = 21, 
             pointsize = 2, 
             fill.ind = genes1$clusterCut, 
             col.ind = "black", 
             addEllipses = TRUE,
             label = "var",
             col.var = "black",
             repel = TRUE,
             legend.title = "Cluster",
             palette = cbPalette1,
             alpha.ind = 0.5)
dev.off()
  # + ggtitle("PCA Plot of Sequences by Cluster")

# Biplot of sequences and gene loadings by cluster
fviz_pca_biplot(pca_bycluster, geom.ind = "point", pointshape = 21, 
             pointsize = 2, 
             fill.ind = genes1$clusterCut,
             col.ind = "black",
             label = "var",
             repel = TRUE,
             legend.title = "Cluster",
             addEllipses = TRUE,
             alpha.ind = 0,
             labelsize=1,
             col.var = "grey40")
     # + ggtitle("PCA Biplot of Sequences and Gene Loadings by Cluster")

# Create a table of sequences by cluster
db_cluster <- dplyr::select(genes1, Genome, VirusSpecies, HostGenus,clusterCut)
write.csv(db_cluster,"Output/table_scores_pca_bycluster.csv", row.names = F)

# Are the MPXV sequences in cluster 3 the same as the outliers in PCA4?
print(db_cluster[(db_cluster$VirusSpecies=="Monkeypox virus" & db_cluster$clusterCut==3),])
# print(outliers[,1:4])

# Clean environment
rm(list=setdiff(ls(), c("genes","genes1","mytable2", "pca")))

```

### *Visualize clustering on viral phylogentic tree*
Figures: *virustree_barplot_cluster_pca.png*

```{r dim_tree}

# Resources
#https://github.com/YuLab-SMU/ggtree/issues/295

# Load libraries
library(ggtree)
library(tidyverse)
library(clustree)
library(ape) 
library(phylogram)

# Load viral tree data
vtree <- ape::read.nexus("OPV_6Jan23.nexus")
print(vtree$tip.label)

# Reformat tip label by dropping everything before the underscore
vtree$tip.label=substring(vtree$tip.label, regexpr("_", vtree$tip.label) + 1, nchar(vtree$tip.label))

# Repeat this step for tip labels with two underscores
vtree$tip.label=substring(vtree$tip.label, regexpr("_", vtree$tip.label) + 1, nchar(vtree$tip.label))

# Drop single quote in tip label
vtree$tip.label=gsub("'","",vtree$tip.label)

# Rename tip label Abatino to Abatino macacapox
vtree$tip.label <- ifelse(vtree$tip.label=="Abatino", "Abatino macacapox", vtree$tip.label)

# Rename tip label Cetacean to Cetaceanpox
vtree$tip.label <- ifelse(vtree$tip.label=="Cetacean", "Cetaceanpox", vtree$tip.label)

# Add ' virus' to tip label
vtree$tip.label=paste0(vtree$tip.label," virus")

# Convert tree data from class "phylo" to "dendrogram"
dendrogram <- as.dendrogram(vtree)

# Copy dataframe of cluster data (freq table of virus species by cluster)
mytable3 = mytable2

# Rename/reformat variables
mytable3$tip.label = mytable2$Var2
mytable3$Cluster = as.factor(mytable2$clusterCut)
mytable3$freq = mytable2$Freq
mytable3 <- subset(mytable3, select=c(tip.label,Cluster,freq))

# Check that all virus species names in mytable3 are in vtree
mytable3$intree <- ifelse(mytable3$tip.label%in%setdiff(mytable3$tip.label, vtree$tip.label),'missing','tree')
which(mytable3$intree=="missing")
mytable3$intree=NULL

# Plot of tree with scale of substitution rate
p <- ggtree(vtree) + geom_tiplab(align=TRUE, size=0) +
     geom_treescale(x=0.1, y=12, width=0.2, label="substitution rate") +
     annotate(geom="text", x=0.2, y=12.3, label="0.2", size=4)
# p <- ggtree(dendrogram) + geom_tiplab(align=TRUE, size=0)

# Color-blind friendly palette:
cbPalette1 <- c("#009292","#ff6db6","#ffb6db","#490092","#6db6ff","#db6d00")
cbPalette2 <- c("#E69F00", "#56B4E9", "#009E73", "#0072B2", "#D55E00", "#CC79A7")

# Plot of tree combined with bar plot of clustering
p1 <- facet_plot(p, data = mytable3, geom = geom_bar, 
                 panel = "Barplot", colour = "black", 
                 mapping = aes(fill=Cluster,x=freq), stat = "identity", orientation="y") +
                 scale_fill_manual(values=cbPalette1)

# Plots of tree + clustering with x-axis scales
p2 <- p1 + theme_tree2()

# Plots of tree + clustering with x-axis scales, x-axis titles, and tiplabel names
p3 <- p2 + xlab(label = c("\n      Substitutions per site                                                     Relative Proportion of Clustering")) +  
      theme(axis.title.x = element_text(size = 12)) + 
      geom_tiplab(as_ylab=TRUE, size = 10)
p3

# Save
png("Output/virustree_barplot_cluster_pca.png", width=16,height=8,units="in",res=600)
p3
dev.off()

```

### *PCA2 (Alternative Analysis)*
What happens when we exclude accessory genes present in only one virus species?

```{r dim_pca2}

# Drop accessory genes that are present in only one virus species (all 0's except for one)
genes2 <- genes[c(1:4,4 + which(colSums(genes[-(1:4)])>1))]
### 985 variables to 686 variables

# Apply PCA using stats::prcomp 
pca2 <- prcomp(genes2[,5:686])

### Vizualize variance, scores and loadings

# Plot cumulative variance to show the proportion of variance explained with each add'l PC
cumpro <- cumsum(pca2$sdev^2 / sum(pca2$sdev^2))
plot(cumpro[0:15], xlab = "Dimension", ylab = "Proportion of explained variance", main = "Cumulative variance plot")
abline(v = 10, col="blue", lty=5)
abline(h = 0.7, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC10"), col=c("blue"), lty=5, cex=1)

# Biplot sequences and gene loadings
fviz_pca_biplot(pca2, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
               repel = TRUE) +
               ggtitle("Biplot of Sequences and Gene Loadings")

# Biplot top 20 influential scores and loadings
fviz_pca_biplot(pca2, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, select.ind=list(contrib=20), select.var=list(contrib=20), max.overlaps=Inf) +
             ggtitle("Biplot of Top 20 Contributing Sequences and Gene Loadings")

### Summary: Compared to the first PCA, there's an increase in the proportion of variance explained by the first 10 dimensions from 0.696 to 0.712. No noticeable difference in the spatial distribution of scores and vectors. 

```

### *PCA3 (Alternative Analysis)*
What happens when we drop duplicate observations within the same host-virus links (sequences with the same identical presence/absence of accessory genes as another sequence of the same host-virus link)?

```{r dim_pca3}

# Identify observations of the same host-virus links with identical presence/absence of accessory genes
genes3 <- genes
genes3$dup <- duplicated(genes3[,-c(1:2)])
table(genes3$dup)
### 42 dups

# Drop duplicate observations
genes3 <- genes3[genes3$dup==FALSE,]
genes3$dup=NULL
### 197 obs to 155 obs

# Apply PCA using stats::prcomp 
pca3 <- prcomp(genes3[,5:985])

### Vizualize variance, scores and loadings

# Plot cumulative variance to show the proportion of variance explained with each add'l PC
cumpro <- cumsum(pca3$sdev^2 / sum(pca3$sdev^2))
plot(cumpro[0:15], xlab = "Dimension", ylab = "Proportion of explained variance", main = "Cumulative variance plot")
abline(v = 10, col="blue", lty=5)
abline(h = 0.7, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC10"), col=c("blue"), lty=5, cex=1)

# Biplot sequences and gene loadings
fviz_pca_biplot(pca3, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
               repel = TRUE) +
               ggtitle("Biplot of Sequences and Gene Loadings")

# Biplot top 20 influential scores and loadings
fviz_pca_biplot(pca3, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, select.ind=list(contrib=20), select.var=list(contrib=20), max.overlaps=Inf) +
             ggtitle("Biplot of Top 20 Contributing Sequences and Gene Loadings")

### Summary: Compared to the first PCA, there is a decrease in the proportion of variance explained by the first ten PCs from 0.696 to 0.680. As in previous PCAs, biplot of top 20 contributing sequences and gene loadings show the most influential sequences in the third quadrant. 

```

### *PCA4 (Alternative Analysis )*
What happens if we exclude the potential outliers from PCA, and then predict their scores and loadings?

```{r dim_pca4}

# Create df excluding outliers identified in PCA3
genes4 <- genes[!grepl("MT724769_1|MN346703_1|MT724770_1|DQ011155_1", genes$Genome),]

# Create df of outliers
outliers <- genes[grepl("MT724769_1|MN346703_1|MT724770_1|DQ011155_1", genes$Genome),]

# Apply PCA using stats::prcomp
pca4 <- prcomp(genes4[,5:985])
relvar <- pca4$sdev^2 / sum(pca4$sdev^2)
relvar_per <- round(relvar*100,1)

# Prediction of PCs for outliers
pred <- predict(pca4, newdata=outliers)
pca4_pred <- pca4
pca4_pred$x <- rbind(pca4_pred$x, pred)

### Vizualize scores and loadings

# Plot of individuals by virus species w/ outliers in shaded bullets
COLOR <- c(1:length(unique(genes$VirusSpecies)))
pc <- c(1,2)
plot(pca4$x[,pc], cex=1, col=COLOR,
     xlab=paste0("PC 1", "(", relvar_per[pc[1]], "%)"), 
     ylab=paste0("PC 2", "(", relvar_per[pc[2]], "%)"))
points(pred[,pc], pch=16) + abline(h = 0, v=0, lty = 2) +
title("Plot of Sequences and Outliers") + theme(plot.title = element_text(hjust = 0.5))

# Biplot of individuals and variables
fviz_pca_biplot(pca4_pred, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE) +
             ggtitle("Biplot of Sequences and Gene Loadings")

# Biplot of top 20 contributing individuals and variables
fviz_pca_biplot(pca4_pred, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, select.ind=list(contrib=20), select.var=list(contrib=20)) +
             ggtitle("Biplot of Sequences and Gene Loadings")

# Clean environment
rm(list=setdiff(ls(), c("genes", "pca","outliers")))

### Summary: Predicted scores of outliers cluster in the fourth quadrant with other sequences. As in previous PCAs, biplot of top 20 contributing sequences and gene loadings show the most influential sequences in the third quadrant.

```

### *MCA of viral accessory genes*
Multiple Correspondence Analysis (MCA) for dimension reduction of categorical variables. MCA is different from PCA in that it's primarily used for categorical data, which in this example are the presence absence of the accessory genes. MCA also uses a dissimilarity measure as opposed to a covariance or correlation matrix to calculate the dissimilarities between categories, which are measured by the singular value decomposition (SVD) of the data matrix (as opposed to eigenvalues or eigenvectors).

```{r dim_mca}

# Subset data and reformat gene variables as factor
genes_cat <- subset(genes,select=-c(Genome,VirusSpecies,HostGenus))
genes_cat[] <- lapply(genes_cat, as.character)
rownames <- genes$Sequence
genes_cat[,-1] <- lapply(genes_cat[,-1], factor)
genes_cat$Sequence=NULL
rownames(genes_cat) <- rownames
#str(genes_cat)

# Apply MCA using FactoMineR::MCA
mca = MCA(genes_cat, graph = FALSE)
# pca_relvar <- pca$sdev^2 / sum(pca$sdev^2)
# pca_relvar_per <- round(pca_relvar*100,1)

# List and summarize MCA results
print(mca)
# summary(mca)
head(mca$ind$coord) #sequence (individuals)
head(mca$var$coord) #genes (variables)

# Screeplot - Variance (Eigenvalues)
#mca$eig
fviz_eig(mca, addlabels = TRUE, ylim = c(0, 25))

# Plots of individuals
fviz_mca_ind(mca, repel=TRUE)

#(6) Plots of MCA variables 1 and 2
fviz_mca_var(mca, repel = TRUE) ##

# Biplot
fviz_mca_biplot(mca, repel = TRUE)
fviz_mca_biplot(mca, repel = FALSE, select.ind=list(contrib=20), select.var=list(contrib=20))

# Clean environment
rm(list=ls())

```


2. Data Preparation
===================

### *Load packages and data for merging: i.e., Host-pox/viral traits (PC), taxonomy data, host traits, and host tree*

```{r prep_raw}

# Load treespace
## treespace dependencies include XQuartz v2.7.11 (https://www.xquartz.org/releases/XQuartz-2.7.11.html) and 'rgl' (https://stackoverflow.com/a/66127391/2554330)
## recommend installing and loading rgl including 'options(rgl.useNULL=TRUE)' below before loading treespace
library(rgl) # > install.packages("rgl"); > options(rgl.useNULL=TRUE)
library(treespace) 

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

# Load raw data
load("PoxHost_RawData.RData")

# Load genomic sequence data
load("Output/wgs_PCs.RData")

# Pox data: host-OPV interactions detected via PCR/isolation from Virion database *note additional interactions from pc_genes below
##virion <- vroom('https://github.com/viralemergence/virion/blob/main/Virion/Virion.csv.gz')
poxdata <- virion %>% filter(VirusGenus == "orthopoxvirus" & (DetectionMethod %in% c("PCR/Sequencing","Isolation/Observation"))) 

# Viral traits data (& Host-pox links): host-OPV linked interactions & principal components of OPV genes (viral traits) extracted from genome sequence data 
wgsdata <- wgs_PCs

# Taxa: mammal species taxonomy from vertlife
##vertlife <- read.csv(url('https://data.vertlife.org/mammaltree/taxonomy_mamPhy_5911species.csv'))
taxa <- vertlife

# Host traits: mammal traits from the COMBINE database <https://doi.org/10.1002/ecy.3344>
##path: ecy3344-sup-0001-datas1.zip > COMBINE_archives > trait_data_imputed.csv)
hostTraits <- combine

# Host tree: mammal phylogeny tree from Dryad, <https://doi.org/10.5061/dryad.tb03d03>
##path: Data_S8_finalFigureFiles > _DATA > MamPhy_fullPosterior_BDvr_Completed_5911sp_topoCons_NDexp_MCC_v2_target.tre)
hostTree <- dryad

# Clean environment
rm(virion, wgs_PCs, vertlife, dryad, combine)

```

### *Merge host-OPV interactions from Virion with host-OPV interactions from genome annotations (Stephanie)*

```{r prep_poxdata}

### Clean up Virion data ###

# Exclude if host genus or virus is NA; exclude variola (smallpox) virus
poxdata <- poxdata[!is.na(poxdata$HostGenus),]
poxdata <- poxdata[!is.na(poxdata$Virus),]
poxdata <- poxdata[!(poxdata$Virus=="variola virus"),]
#In this model, we keep vaccinia virus!

# Aggregate data at the host genus level
poxdata$link <- 1
poxdata <- aggregate(link~HostGenus+Virus, data=poxdata, mean)
poxdata$link=NULL

# Rename and reformat variables
poxdata <- plyr::rename(poxdata,c('HostGenus'='genus','Virus'='virus'))
poxdata$genus <- str_to_title(poxdata$genus)

# Add datasource variable
poxdata$virion <- 1

### Clean up genomic data ###

# Rename and reformat variables
wgsdata <- plyr::rename(wgsdata,c('HostGenus'='genus','Sequence'='sequence'))
wgsdata$virus <- tolower(wgsdata$VirusSpecies)
wgsdata$VirusSpecies=NULL

# Drop genome variable
wgsdata$Genome=NULL

# Add datasource variable
wgsdata$wgs <- 1

### Merge ###

# Are their virus in wgsdata that are not in poxdata and vice versa?
wgsdata$virus[!wgsdata$virus %in% poxdata$virus]
poxdata$virus[!poxdata$virus %in% wgsdata$virus]

# Correct 'cetaceanpox virus' to 'cetacean pox virus 1' in wgsdata
wgsdata$virus <- ifelse(wgsdata$virus=="cetaceanpox virus", "cetacean poxvirus 1", wgsdata$virus)

# Are their genera in wgsdata that are not in poxdata and vice versa?
wgsdata$genus[!wgsdata$genus %in% poxdata$genus]
poxdata$genus[!poxdata$genus %in% wgsdata$genus]

# Before merging, get count of unique host-virus associations in each dataset
poxdata_unique <- unique(poxdata[ , c("genus", "virus")])
length(unique(poxdata_unique$genus))
length(unique(poxdata_unique$virus))
wgsdata_unique <- unique(wgsdata[ , c("genus", "virus")])
length(unique(wgsdata_unique$genus))
length(unique(wgsdata_unique$virus))

# Merge poxdata w/ wgsdata
poxdata <- merge(poxdata,wgsdata,by=c('virus','genus'),all=TRUE)

# Create data source variable
poxdata$source <- ifelse(poxdata$wgs==1 & is.na(poxdata$virion),"wgs", ifelse(poxdata$virion==1 & is.na(poxdata$wgs),"virion","both"))

# Replace sequence==NA with "NA", as this var will be our unique identifier for WGS links
poxdata$sequence <- ifelse(is.na(poxdata$sequence),"NA",poxdata$sequence)

# Get count of unique host-virus associations in each dataset
poxdata_unique <- unique(poxdata[ , c("genus", "virus")])
length(unique(poxdata_unique$genus))
length(unique(poxdata_unique$virus))

# Remove virion and wgs vars; clean environment
poxdata$virion=NULL
poxdata$wgs=NULL
rm(wgsdata, wgsdata_unique, poxdata_unique)

```

### *Merge poxdata with broader mammal taxa to create pseudoabsences*

```{r prep_pseudo}

# Drop duplicate genera in taxa
gtaxa <- taxa[!duplicated(taxa$gen),]
gtaxa <- gtaxa[c('gen','fam','ord')]
gtaxa <- plyr::rename(gtaxa, c('gen'='genus'))

# Check for mismatched genus names between poxdata and taxa before merging poxdata with taxa
poxdata$genus[!poxdata$genus %in% gtaxa$genus]
poxdata <- merge(gtaxa,poxdata,by='genus',all.x=TRUE)

# To keep only genera from orders in which positive associations exist, first subset known host-virus associations
keep <- subset(poxdata, !is.na(poxdata$source))

# Next, create a new variable <keep> in poxdata denoting observations with the same host taxonomic order as that of known associations
poxdata$keep <- ifelse(poxdata$ord %in% keep$ord,TRUE,FALSE)

# View/evaluate which taxonomics orders will be kept and which orders will be discarded
uniq <- unique(poxdata[c("ord","keep")])

# Keep only observations with the same host taxonomic order as that of known associations
poxdata <- subset(poxdata,keep==TRUE)
poxdata$keep=NULL

# Create binary variable for known host-OPV associations/links
poxdata$link=ifelse(is.na(poxdata$source),0,1)

# Reorder variables
poxdata <- poxdata %>% select(link, virus, genus, fam, ord, source, everything())

# Clean environment
rm(taxa,gtaxa,keep,uniq)

```

### *Aggregate hostTraits to genus-level*

```{r prep_traits}

# Observe variable names
colnames(hostTraits)

# To aggregate continuous/integer variables, use the median as the summary measure
hostTraits_continuous=aggregate(cbind(adult_mass_g,brain_mass_g,adult_body_length_mm,adult_forearm_length_mm,
                                   max_longevity_d,maturity_d,female_maturity_d,male_maturity_d,
                                   age_first_reproduction_d,gestation_length_d,teat_number_n,
                                   litter_size_n,litters_per_year_n,interbirth_interval_d,
                                   neonate_mass_g,weaning_age_d,weaning_mass_g,generation_length_d,
                                   dispersal_km,density_n_km2,home_range_km2,social_group_n,
                                   dphy_invertebrate,dphy_vertebrate,dphy_plant,
                                   det_inv,det_vend,det_vect,det_vfish,det_vunk,det_scav,det_fruit,det_nect,det_seed,det_plantother,det_diet_breadth_n,
                                   upper_elevation_m,lower_elevation_m,altitude_breadth_m,habitat_breadth_n) 
                             ~ order+family+genus, data=hostTraits, FUN=median, na.action=na.pass, na.rm=TRUE)
##'na.action=na.pass, na.rm=TRUE' is specified such that if species w/in a genus has a combination of real values & NAs, the median of real values will be returned (as opposed to omitting the genus or returning NA)

# To aggregate binary variables, use the mean as the summary measure
hostTraits$fossoriality[hostTraits$fossoriality==2]<-0  #recode 0/1: 0=above ground, 1=fossorial dwelling
hostTraits_binary=aggregate(cbind(hibernation_torpor,fossoriality,freshwater,marine,terrestrial_non.volant,terrestrial_volant,island_dwelling,disected_by_mountains,glaciation) ~ order+family+genus, data=hostTraits, FUN=mean, na.action=na.pass, na.rm=TRUE)
hostTraits_binary_temp=aggregate(cbind(hibernation_torpor,fossoriality,freshwater,marine,terrestrial_non.volant,terrestrial_volant,island_dwelling,disected_by_mountains,glaciation) ~ order+family+genus, data=hostTraits, FUN=mean, na.action=na.pass, na.rm=TRUE)

# To aggregate categorical variables, first transform the variables to binary
hostTraits_cat <- hostTraits
hostTraits_cat$trophic_herbivores <- ifelse(hostTraits_cat$trophic_level==1,1,0)
hostTraits_cat$trophic_omnivores <- ifelse(hostTraits_cat$trophic_level==2,1,0)
hostTraits_cat$trophic_carnivores <- ifelse(hostTraits_cat$trophic_level==3,1,0)
hostTraits_cat$activity_nocturnal <- ifelse(hostTraits_cat$activity_cycle==1,1,0)
hostTraits_cat$activity_crepuscular <- ifelse(hostTraits_cat$activity_cycle==2,1,0) #nocturnal/crepuscular, cathemeral, crepuscular or diurnal/crepuscular
hostTraits_cat$activity_diurnal <- ifelse(hostTraits_cat$activity_cycle==3,1,0)
hostTraits_cat$forager_marine <- ifelse(hostTraits_cat$foraging_stratum=="M",1,0)
hostTraits_cat$forager_ground <- ifelse(hostTraits_cat$foraging_stratum=="G",1,0) 
hostTraits_cat$forager_scansorial <- ifelse(hostTraits_cat$foraging_stratum=="S",1,0)
hostTraits_cat$forager_arboreal <- ifelse(hostTraits_cat$foraging_stratum=="Ar",1,0)
hostTraits_cat$forager_aerial <- ifelse(hostTraits_cat$foraging_stratum=="A",1,0)
hostTraits_cat$island_end_marine <- ifelse(hostTraits_cat$island_endemicity=="Exclusively marine",1,0)
hostTraits_cat$island_end_mainland <- ifelse(hostTraits_cat$island_endemicity=="Occurs on mainland",1,0)
hostTraits_cat$island_end_lgbridge <- ifelse(hostTraits_cat$island_endemicity=="Occurs on large land bridge islands",1,0)
##hostTraits_cat$island_end_smbridge <- ifelse(hostTraits_cat$island_endemicity=="Occurs on small land bridge islands",1,0)
hostTraits_cat$island_end_isolated <- ifelse(hostTraits_cat$island_endemicity=="Occurs only on isolated islands",1,0)
hostTraits_cat$biogeo_afrotropical <- ifelse(grepl("Afrotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_antarctic <- ifelse(grepl("Antarctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_australasian <- ifelse(grepl("Australasian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_indomalayan <- ifelse(grepl("Indomalayan",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_nearctic <- ifelse(grepl("Nearctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_neotropical <- ifelse(grepl("Neotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_oceanian <- ifelse(grepl("Oceanian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_palearctic <- ifelse(grepl("Palearctic",hostTraits_cat$biogeographical_realm),1,0)

# To aggregate transformed categorical-to-binary variables, use the mean as the summary measure
hostTraits_cat=aggregate(cbind(trophic_herbivores,trophic_omnivores,trophic_carnivores,
                            activity_nocturnal,activity_crepuscular,activity_diurnal,
                            forager_marine,forager_ground,forager_scansorial,forager_arboreal,forager_aerial,
                            island_end_marine,island_end_mainland,island_end_lgbridge,island_end_isolated,
                            biogeo_afrotropical,biogeo_antarctic,biogeo_australasian,biogeo_indomalayan,biogeo_nearctic,biogeo_neotropical,biogeo_oceanian,biogeo_palearctic)
                       ~ order+family+genus, data=hostTraits_cat, FUN=mean, na.action=na.pass, na.rm=TRUE)

# Merge continuous variables with binary variables and simplify dataframe
hostTraits <- full_join(hostTraits_continuous, hostTraits_binary, by = c("order","family","genus"),keep=TRUE)
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits=subset(hostTraits, select=-c(order.y,family.y,genus.y))

# Merge transformed categorical variables and simplify dataframe
hostTraits <- full_join(hostTraits, hostTraits_cat, by = c("order","family","genus"),keep=TRUE)
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits <- subset(hostTraits, select=-c(order.y,family.y,genus.y))

# Clean environment
rm(hostTraits_binary,hostTraits_cat,hostTraits_continuous)

```

### *Trim hostTree to genus-level*

```{r prep_tree}

# Reformat
hostTree$tip.label[hostTree$tip.label=="_Anolis_carolinensis"] <- "Anolis_carolinensis"

# Create dataframe linking tip labels with their corresponding categories (genus and species)
tdata <- data.frame(matrix(NA,nrow=length(hostTree$tip.label),ncol=0))
tdata$genus <- sapply(strsplit(hostTree$tip.label,'_'),function(x) paste(x[1],sep='_'))
tdata$species <- hostTree$tip.label

# Collapse tree to genus level
hostTree <- makeCollapsedTree(tree=hostTree,df=tdata[c('genus','species')])

# Clean environment
rm(tdata)

```

### *Check for mismatched genera names in poxdata, hostTraits and hostTree*

```{r prep_names}

# Check if all poxdata genera are in hostTree
poxdata$gtip <- poxdata$genus
hostTree$gtip <- hostTree$tip.label
poxdata$intree <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTree$gtip),'missing','upham')

# Check if all poxdata genera are in hostTraits
hostTraits$gtip <- hostTraits$genus
poxdata$intraits <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTraits$gtip),'missing','traits')

# Create a dataframe of just the observations with mismatched names
fix <- poxdata[c('gtip','intree','intraits')]
fix <- fix[fix$intree=='missing'|fix$intraits=='missing',]
fix <- unique(fix)

# For those with mismatched names, identify homotypic synonyms or proxy species via IUCN (https://www.iucnredlist.org/) and NCBI (http://www.ncbi.nlm.nih.gov/taxonomy)
fix$treename <- NA
fix$traitname <- NA
fix$proxy <- NA
fix$proxy <- ifelse(fix$gtip=="Calassomys","Delomys",fix$proxy)
  ##source: https://academic.oup.com/jmammal/article/95/2/201/860032
fix$traitname <- ifelse(fix$gtip=="Liomys","Heteromys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Oreonax","Lagothrix",fix$traitname)
  ##source: https://www.iucnredlist.org/species/39924/192307818
fix$traitname <- ifelse(fix$gtip=="Paralomys","Phyllotis",fix$traitname)
  ##source: https://www.iucnredlist.org/species/17226/22333354
fix$traitname <- ifelse(fix$gtip=="Pearsonomys","Geoxus",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Pipanacoctomys","Tympanoctomys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/136557/78324400#taxonomy
fix$traitname <- ifelse(fix$gtip=="Pseudalopex","Lycalopex",fix$traitname)
  ##source: https://www.iucnredlist.org/species/6926/87695615
## hostTraits$genus[which(grepl('Tympanoctomys',hostTraits$genus))]

# Merge revised names with poxdata
fix <- subset(fix, select=-c(intree,intraits))
poxdata <- merge(poxdata,fix,by='gtip',all.x=T)

# If 'treename' is missing, first relabel as NA, then relabel with 'gtip'
poxdata$treename <- ifelse(poxdata$treename=='',NA,as.character(poxdata$treename))
poxdata$treename <- ifelse(is.na(poxdata$treename),as.character(poxdata$gtip),as.character(poxdata$treename))

# If 'traitname' is missing, first relabel as NA; If 'traitname' is NA and missing in 'intraits', then relabel with 'proxy'; If 'traitname' is not NA and missing in 'intraits', then relabel with 'traitname'
poxdata$traitname <- ifelse(poxdata$traitname=='',NA,as.character(poxdata$traitname))
poxdata$traitname <- ifelse(poxdata$intraits=='missing' & is.na(poxdata$traitname),as.character(poxdata$proxy),
                      ifelse(poxdata$intraits=='missing' & !is.na(poxdata$traitname),as.character(poxdata$traitname),
                             as.character(poxdata$gtip)))

# Simplify and clean environment
poxdata <- subset(poxdata, select=-c(intree,intraits,proxy))
rm(fix)

```

### *Merge poxdata with hostTraits and trim hostTree to mirror poxdata*

```{r prep_merge}

# Merge traits with poxdata
hostTraits$traitname <- hostTraits$gtip
poxdata <- merge(poxdata,hostTraits,by=c('traitname'),all.x=T)

# Clean up poxdata
poxdata <- plyr::rename(poxdata,c('gtip.x'='gtip','genus.x'='genus'))
poxdata <- subset(poxdata,select=-c(order, family, genus.y, gtip.y))

# Trim hostTree (remove species tip) to mirror poxdata
hostTree <- keep.tip(hostTree,hostTree$tip.label[hostTree$tip.label%in%poxdata$treename])
hostTree$gtip <- NULL
hostTree=makeLabel(hostTree)

# Clean environment
rm(hostTraits)

```

### *Add PubMed citations and evolutionary distinctiveness measure*

```{r prep_cited}

# Load library for PubMed citations
library(easyPubMed)

# Create function to count citations
counter=function(name){
  as.numeric(as.character(get_pubmed_ids(gsub('_','-',name))$Count))
}
citations=c()

# Extract unique genera from poxdata
treename <- unique(poxdata$treename)

# Apply counter function while looping through treenames
for(i in 1:length(treename)) {
  citations[i]=counter(treename[i])
  print(i)
}

# Compile citation numbers
cites <- data.frame(treename=treename,cites=citations)

# Merge cites with poxdata
poxdata <- merge(poxdata,cites,by='treename')

# Load library for evolutionary distinctiveness (ed) measure
library(picante)  #before loading picante, make sure latest version of nlme package is loaded
ed <- evol.distinct(hostTree,type='equal.splits') #calculates ed measures for a suite of species by equal splits and fair proportions; returns species score

# Rename variables in ed
ed <- plyr::rename(ed,c('Species'='treename','w'='ed_equal'))

# Merge ed with poxdata
poxdata <- merge(poxdata,ed,by='treename')

# Clean environment
rm(cites,ed,citations,i,treename,counter)

## Other potential viral traits to consider for future studies include: viral genome length, viral richness (number of virus detected in each genera), and host range (number of hosts from which each virus was detected)

```

### *Add all possible host-OPV combinations (i.e., pseudoabsences) for link prediction model and merge with PCA (viral genomic) data*

```{r prep_link}

# Create a dataframe of all possible host-OPV combinations (for mammal genera that exist in orders w/ known OPV predictions) by identifying all unique virus species and host genus of known associations and using the {expand.grid} function
uniq_virus <- unique(poxdata$virus[!is.na(poxdata$virus)])
uniq_genus <- unique(poxdata$genus[!is.na(poxdata$genus)])
combinations <- expand.grid(uniq_virus, uniq_genus)
combinations <- plyr::rename(combinations,c('Var1'='virus','Var2'='genus'))

# Create two dataframes: one subsetting host-OPV interaction/link data from poxdata (excluding host trait data), and the other subsetting unique host trait data (i.e., all other variables) which we will merge back in later
linkdata <- poxdata[,grepl("link|virus|genus|source|sequence|PC", names(poxdata))]
hostTraits <- poxdata[,!grepl("link|virus|source|sequence|PC", names(poxdata))] # include genus b/c we will merge on it later
hostTraits <- hostTraits[!duplicated(hostTraits$genus),]

# Merge linkdata with all possible combinations (drop observations if virus NA)
linkdata <- merge(linkdata, combinations, by=c("virus","genus"),all=TRUE)
linkdata <- linkdata[!is.na(linkdata$virus),]

# Merge linkdata with hostTraits
linkdata <- merge(linkdata, hostTraits, by=c("genus"))

# Reorder variables
linkdata <- linkdata %>% select(source, sequence, link, virus, genus, fam, ord, gtip, traitname, treename, PC1, PC2, PC3, PC4, PC5, PC6, PC7, PC8, PC9, PC10, everything())

# Reclassify NAs as pseudo-absences for viral detection
linkdata$link=ifelse(is.na(linkdata$link),0,linkdata$link)

### Next, we need to impute values of PC variables where data exist for that virus.

# First let's subset virus and PC variables, and drop rows w/ NA
pc <- linkdata[,grepl("virus|PC", names(linkdata))]
pc <- pc[!is.na(pc$PC1),]

# Let's take a quick look at which virus do not have PC data
setdiff(unique(linkdata$virus),unique(pc$virus))

# Next, we obtain the median value of each PC variable for each virus using aggregate function (dot notation), and rename PC variables
pc_median=aggregate(. ~virus, data=pc, FUN=median)
colnames(pc_median)[c(-1)] <- paste(colnames(pc_median)[c(-1)], "_med", sep="")

# Merge PC median variables w/ poxdata
linkdata <- merge(linkdata,pc_median,by=c("virus"),all.x=TRUE)

# Get PC colnames and replace NA values of PC vars w/ median PC values using for-loop
pc_names <- colnames(pc)[c(-1)]
for(i in pc_names) {
  linkdata[,i] <- ifelse(is.na(linkdata[,i]),linkdata[,paste(i,"_med",sep="")],linkdata[,i])
}

# Drop median PC variables
pc_med_names <- colnames(pc_median)[c(-1)]
for(i in pc_med_names) {
  linkdata[,i]=NULL
}

# Replace NA values for 'source' and 'sequence' with "NA"
linkdata$source <- ifelse(is.na(linkdata$source),"NA",linkdata$source)
linkdata$sequence <- ifelse(is.na(linkdata$sequence),"NA",linkdata$sequence)

# Clean environment
rm(combinations, hostTraits, uniq_virus, uniq_genus, pc, pc_median, pc_names, pc_med_names, i, poxdata)

```

### *Save cleaned data*

```{r prep_save}

#(1) Reorder variables
linkdata <- linkdata %>% select(source, sequence, link, virus, genus, fam, ord, gtip, traitname, treename, cites, ed_equal, everything())

#(2) Save dataframes for analysis **poxdata_temp.RData is for practice analysis**
save(linkdata, hostTree, file='Output/LinkPredictionModel_CleanData.RData')

```


3. BRT Model
============
This chapter builds boosted regression tree models to predict host-virus links. The following section is coded to run on your local computer and will likely take ~72+ hours (with parallel processing on 5 cores), outputting an RData file size of 2GB. For tips on running the code on an available HPC node, see 'Tseng2022/HPC Example' on the PoxHost GitHub repository: https://github.com/viralemergence/PoxHost/tree/0a1effef83dbd5f6f3d88c6d0c15c563eb499452/Tseng2022/HPC%20Example_01Jun2023.

### *Load required packages and set system*

```{r brt_load}

#(1) Libraries for BRT model
library(gbm)
library(fastDummies)
library(rsample)
library(ROCR)
library(sciplot)
library(ggplot2)
library(pdp)
library(PresenceAbsence)
library(tidyr)
library(viridis)
library(caper)
###to install ggtree, need to first install BiocManager:
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("ggtree")
library(phylofactor)
library(ggtree)
library(treeio)
library(caret) 
library(InformationValue)
library(mgcv) #for beta regression on performance metrics

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

### *Create variables of taxonomic family as predictors for the model*

```{r brt_taxo}

# Load data and clean environment
load("Output/LinkPredictionModel_CleanData.RData")
data <- linkdata
rm(linkdata)

# Calculate number of pseudoabsences
length(which(data$link==0))

# Ensure all accessory gene variables are numeric
PC_columns <- colnames(data[which(grepl("PC",names(data)))])
data[,c(PC_columns)] <- lapply(data[c(PC_columns)],as.numeric)
str(data)

# Make binary variables for each taxonomic family; remove any duplicates
dums=dummy_cols(data["fam"])
dums=dums[!duplicated(dums$fam),]

# Ensure all family vars are factor
for(i in 1:ncol(dums)){
  dums[,i]=factor(dums[,i])
}

# Merge family taxa variables with dataset as predictors
data=merge(data,dums,by="fam",all.x=T)

# Drop unnecessary columns and clean environment
data$traitname=NULL
rm(dums, i, PC_columns)

```

### *Assess variation and availability of data*
We explore the variation and availability of our data and drop variables if more than 40% of observations are missing/NA (vs. 30% for Host Trait Model; this is because of low coverage, ~60%, among PC/accessory gene variables). We also remove variables that are not needed for the BRT analysis and save the dataset as *data_LinkBRT.RData*.
Figure: *histogram_trait_coverage.png*
Table: *table_trait_coverage.csv*

```{r brt_var}

# Create mode function where for each variable, we extract the frequency of the most frequently occurring value for that variable and divide it by the number of non-NA elements in that variable
mode.prop <- function(x) {                
  ux <- unique(x[is.na(x)==FALSE])        # creates array of unique values
  tab <- tabulate(match(na.omit(x), ux))  # creates array of the frequency (number of times) a unique value appears in a column 
  max(tab)/length(x[is.na(x)==FALSE])     # max-frequency / number of elements in each column that are not NA
}

# Assess variation across columns (2 indicates columns)
vars=data.frame(apply(data,2,function(x) mode.prop(x)),
                apply(data,2,function(x) length(unique(x))))    # number of unique elements in each column

# Get names
vars$variables=rownames(vars)
names(vars)=c("var","uniq","column")

# # Round values
# vars$var=round(vars$var,2)

# Label variables "cut" if homogeneous (100%)
vars$keep=ifelse(vars$var<1,"keep","cut")
vars$keep=ifelse(vars$column%in%c('fam','source','sequence','link','virus','genus','ord','gtip','treename','cites','ed_equal'),'keep',vars$keep) # ensures we keep these columns
vars=vars[order(vars$keep),]

# Trim (creates array of column names to cut and removes from df)
keeps=vars[-which(vars$keep=="cut"),]$column

# Drop if no variation
data=data[keeps]
rm(keeps,vars)

# Assess missing values
mval=data.frame(apply(data,2,function(x) length(x[!is.na(x)])/nrow(data))) # proportion of values that are not NA

# Get names
mval$variables=rownames(mval)
names(mval)=c("comp","column")

# Plot frequency distribution of coverage among traits
png("Output/histogram_trait_coverage.png", width=4,height=4,units="in",res=600)
ggplot(mval[!mval$column%in%c("gen","treename","pcr","competence","tip.label","fam"),],
       aes(comp))+
  geom_histogram(bins=50)+
  geom_vline(xintercept=0.70,linetype=2,size=0.5)+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  labs(y="frequency",
       x="Trait coverage across mammal genera")+
  scale_x_continuous(labels = scales::percent)
dev.off()

# Label variables "cut" if >40% values are NA
mval$keep=ifelse(mval$comp>=0.60,"keep","cut")
table(mval$keep)
mval=mval[order(mval$keep),]

# Trim (creates array of column names to cut and removes from df)
keeps=mval[-which(mval$keep=="cut"),]$column

# Drop if not well represented
data=data[keeps]
rm(keeps,mval)

# Subset data to include only covariates
set <- subset(data,select=-c(fam, source, sequence, virus, genus, ord, gtip, treename))

#  Get trait coverage
trait_coverage=data.frame(apply(set,2,function(x) length(x[!is.na(x)])/nrow(set)))

# Rename and reorder columns
trait_coverage$variables=rownames(trait_coverage)
names(trait_coverage)=c("coverage","feature")
rownames(trait_coverage)=NULL
trait_coverage=trait_coverage[!trait_coverage$feature%in%c("pcr","competence"),]
trait_coverage <- subset(trait_coverage,select=c(feature,coverage))

# Save table
write.csv(trait_coverage, "Output/table_trait_coverage.csv")

# Check that binary variables are numeric and not factor (except for fam vars)
str(set)

# Remove vars not needed for BRT analysis
data$source=NULL
data$sequence=NULL
save(data, file='Output/data_LinkBRT.RData')

# Clean environment
rm(keeps, mval, trait_coverage)
```

### *Alternative dataset excluding vaccinia virus sequences*
We prepare an alternative dataset that excludes vaccinia virus sequences (host associations with vaccinia virus) from BRT analysis.

```{r brt_alt}

# Subset data to exclude host-vaccinia virus links
# data <- data[data$virus!="vaccinia virus",]
# set <- subset(data,select=-c(fam, virus, genus, ord, gtip, treename))

```

### *Tuning to asses model performance for each combination of tuning parameters*
We create a hyperparameter 'grid' that represents different combinations of parameter values to which we tune the model. We then save a table of the resulting model performance measures for 'Model 1', where we predict on all possible host-virus combinations. If model tuning on the alternative dataset (see above), {r brt_alt}, we recommend you modify the results table name to *par...Model2.csv*.
Table: *par_tuning_data_summary_Model1.csv*

```{r brt_tuning}

# Hyperparameter tuning ifelse
#hok="ok"
hok="notok"
if(hok!="ok"){
  
  ## hyperparameter grid
  hgrid=expand.grid(n.trees=5000,                              #creates df from all combinations of factor vars (1*3*3*1*10=90 obs & 5 vars)
                    interaction.depth=c(2,3,4),
                    shrinkage=c(0.01,0.001,0.0005),
                    n.minobsinnode=4,
                    seed=seq(1,10,by=1))
  # hgrid=expand.grid(n.trees=500,                              #creates df from all combinations of factor vars (1*3*3*1*10=90 obs & 5 vars)
  #                   interaction.depth=c(2,3,4),
  #                   shrinkage=c(0.1,0.01,0.005),
  #                   n.minobsinnode=4,
  #                   seed=seq(1,10,by=1))
  # fix trees
  hgrid$n.trees=ifelse(hgrid$shrinkage<0.001,hgrid$n.trees*3,hgrid$n.trees)
  
  ## trees, depth, shrink, min, prop 
  hgrid$id=with(hgrid,paste(n.trees,interaction.depth,shrinkage,n.minobsinnode))   #creates var 'id' concatenating values from each of the specified columns in hgrid
  
  ## sort by id then seed
  hgrid=hgrid[order(hgrid$id,hgrid$seed),]
  
  ## now add rows
  hgrid$row=1:nrow(hgrid)                                        #adds var 'row' based on row number in hgrid
  
  ## factor id
  hgrid$id2=factor(as.numeric(factor(hgrid$id)))                 #creates 9-level factor var 'id2' 
  
  
  ## function to assess each hyperpar combination
  hfit=function(row,response){
    
    ## make new data
    ndata=set
    
    ## correct response
    ndata$response=ndata[response][,1]                           #creates var 'response'
    
    ## remove raw
    # ndata$pcr=NULL
    # ndata$competence=NULL
    ndata$link=NULL
    
    ## use rsample to split
    set.seed(hgrid$seed[row])                                    #sets seed value of 1-10
    split=initial_split(ndata,prop=0.7,strata="response")        #creates single binary split of data into training set and testing set, where 70% of data is retained for modeling/analysis and resampling is created within the 'response' var
    
    ## test and train
    dataTrain=training(split)
    dataTest=testing(split)
    
    ## yTest and yTrain
    yTrain=dataTrain$response                                    #create array of just response values from training and testing set
    yTest=dataTest$response
    
    ## BRT
    set.seed(1)
    gbmOut=gbm(response ~ . ,data=dataTrain,                     #y~x; gbmOut contains list of 29 elements including train.error and valid.error referenced later in gbm.perf()
               n.trees=hgrid$n.trees[row],                       #total number of trees to fit (number of iterations; default is 100)
               distribution="bernoulli",
               shrinkage=hgrid$shrinkage[row],                   #equiv to learning rate or step-size reduction (smaller learning rate requires more trees, default is 0.1)
               interaction.depth=hgrid$interaction.depth[row],   #max depth of each tree (highest level of variable interactions allowed; default is 1)
               n.minobsinnode=hgrid$n.minobsinnode[row],         #min. number of obs in terminal nodes of trees
               cv.folds=5,class.stratify.cv=TRUE,                #no. of cross-val folds to perform; for cv.folds>1, returns estimate of generalization error in 'cv.error'
               bag.fraction=0.5,train.fraction=1,                #fraction of training set obs randomly selected to propose next tree in expansion - this is why we set.seed()
               n.cores=5,                                        #no. of CPU cores to use
               verbose=F)
               # par.details=(gbmParallel(num_threads=5)),
    
    ## performance
    par(mfrow=c(1,1),mar=c(4,4,1,1))                             #sets graphical parameters such that subsequent figure are drawn in a nr-by-nc array by mfrows respectively and gives the number of lines of margin to be specified on the four sides of the plot c(bottom, L, top, R) -> see 'best.iter' plot below 
    best.iter=gbm.perf(gbmOut,method="cv")                       #estimates optimal number of boosting iterations and plots 'training.error' performance measure; cv method extracts this optimal number using cross-validation
    
    ## predict with test data
    preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")  #number of trees based on the optimal number of boosting iterations as set above (5,352)
    
    ## known
    result=dataTest$response
    
    # ##estimate threshold value for classification of predicted probability
    # #library(pROC)
    # analysis <- roc(result,preds)  #roc([actual values],[predicted values])
    # e <- cbind(analysis$thresholds,analysis$sensitivities+analysis$specificities) #pulls each array and binds them into dataframe: 1st column are thresholds, 2nd column are sensitivities + specificities
    # 
    # ##optimum threshold value
    # opt_t <- subset(e,e[,2]==max(e[,2]))[,1] #subsets dataframe and returns the max (sens+spec) value of 2nd column of e 
    # #threshold<-opt_t #set as threshold value
    # #threshold = 0.2
    
    ## sensitivity and specificity                              #e.g., test run produced sensitivity of 0 b/c no predictedScores were > 0.5; and specificity of 1 b/c all predictedScores were <0.5
    sen=InformationValue::sensitivity(result,preds)              #calculates sensitivity (# of obs with event AND predicted to have event, divided by # of obs w/ event) for a given logit model where input is the actual binary flag (as numerica vector) for the response variable and the predicted probability scores for each observation; if predicted value is above the threshold (defaults to 0.5), it will be considered an event (1) or else a non-event (0)
    spec=InformationValue::specificity(result,preds)             #calculates specificity (# of obs w/o event AND predicted to not have event, divided by # of obs w/o event)  
    
    ## AUC on train
    auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))   #compute Information Retrieval measures for pairwise loss for a single group, where input is the observed value and the predicted value
    
    ## AUC on test
    auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
    
    ## print
    print(paste("hpar row ",row," done; test AUC is ",auc_test,sep=""))  #prints "hpar row [x] done; test AUC is []"
    
    ## save outputs
    return(list(best=best.iter,                    #saves optimal number of iterations, AUC on training set, AUC on testing set, specificity, sensitivity, and row number as a list
                trainAUC=auc_train,
                testAUC=auc_test,
                spec=spec,
                sen=sen,
                wrow=row))
  }
  
  ## run the function for link
  hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="link"))
  
  ## get results
  hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
                      sapply(hpars,function(x) x$testAUC),
                      sapply(hpars,function(x) x$spec),
                      sapply(hpars,function(x) x$sen),
                      sapply(hpars,function(x) x$wrow),
                      sapply(hpars,function(x) x$best))
  names(hresults)=c("trainAUC","testAUC",
                    "spec","sen","row","best")
  
  ## combine and save
  hsearch=merge(hresults,hgrid,by="row")
  
  # ## save
  # hsearch$type="PCR"
  
  # ## rerun the function for competence
  # hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="competence"))
  # 
  # ## get results
  # hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
  #                     sapply(hpars,function(x) x$testAUC),
  #                     sapply(hpars,function(x) x$spec),
  #                     sapply(hpars,function(x) x$sen),
  #                     sapply(hpars,function(x) x$wrow),
  #                     sapply(hpars,function(x) x$best))
  # names(hresults)=c("trainAUC","testAUC",
  #                   "spec","sen","row","best")
  # 
  # ## combine and save
  # csearch=merge(hresults,hgrid,by="row")
  # 
  # ## assign data type
  # csearch$type="competence"
  # 
  # ## combine
  # search=rbind.data.frame(csearch,hsearch)
  # search$type=factor(search$type,levels=c("PCR","competence"))

  search=hsearch
  
  ## export
  write.csv(search,"Output/par_tuning_data_summary_Model1.csv")
  # write.csv(search,"Output/par_tuning_data_summary_Model2.csv")

}else{
  
  ## 
  search=read.csv("Output/par_tuning_data_summary_Model1.csv")
  # search=read.csv("Output/par_tuning_data_summary_Model2.csv")

}

```

### *Assess model tuning results*
We fit a beta regression model using mgcv::gam to explore the main interaction effects of tuning parameters, interaction depth and shrinkage, on performance metrics (AUC, sensitivity, and specificity). This model is appropriate for analyzing continuous response variables bounded b/w 0-1 (i.e,, beta distribution). Using ANOVA, we determine whether the coefficients b/w the two interactions depths, the two shrinkage rates, and the four possible interactions b/w them are significantly different. We then plot the performance of BRTs based on various parameter combinations. Finally, we assess the distribution of best.iter (optimal # of iterations) to determine the max # of trees to use for model training.
Figure: *boxplot_brt_tuning.png*

```{r brt_tuning_results}

search=read.csv("/Users/katietseng/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model1/Output/par_tuning_data_summary_Model1.csv")
# search=read.csv("/Users/katietseng/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model1/Output/par_tuning_data_summary_Model2.csv")

# Convert parameters to factor and relabel values
search$shrinkage=factor(search$shrinkage)
lvl=rev(sort(unique(search$shrinkage)))  #sorts unique shrinkage par from large to small
search$shrinkage=factor(search$shrinkage,levels=lvl); rm(lvl)  #applies as factor
search$interaction.depth=factor(search$interaction.depth)

# Fit beta regression model to the test AUCs; ANOVA
mod=gam(testAUC~interaction.depth*shrinkage,  
        data=search,method="REML",family=betar)
anova(mod)

# Fit beta regression model to the sensitivities; ANOVA
mod=gam(sen~interaction.depth*shrinkage,
        data=search,method="REML",family=betar)
anova(mod)

# Fit beta regression model to the specificities; ANOVA
mod=gam(spec~interaction.depth*shrinkage,
        data=search,method="REML",family=betar)
anova(mod)

# To plot model tuning performance, transform dataframe from wide to long
search2=gather(search,measure,value,testAUC:sen)

# Relabel values and convert to factor 
search2$measure=plyr::revalue(search2$measure,
                              c("sen"="sensitivity",  
                                "spec"="specificity",
                                "testAUC"="test AUC"))
search2$measure=factor(search2$measure,
                       levels=c("test AUC","sensitivity","specificity"))

# Boxplot performance fo model tuning w/ various parameter combinations
png("Output/boxplot_brt_tuning.png",width=5,height=8,units="in",res=600)
set.seed(1)
ggplot(search2,aes(shrinkage,value,
                   colour=interaction.depth,fill=interaction.depth))+
  geom_boxplot(alpha=0.25)+
  geom_point(alpha=0.75,
             position = position_jitterdodge(dodge.width=0.75))+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  facet_grid(search2$measure,scales="free_y",switch="y")+
  theme(strip.placement="outside",
        strip.background=element_blank())+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        strip.text=element_text(size=12))+
  theme(legend.position="top")+
  scale_color_brewer(palette="Pastel2")+
  scale_fill_brewer(palette="Pastel2")+
  guides(colour=guide_legend(title="interaction depth"),
         fill=guide_legend(title="interaction depth"))+
  labs(y=NULL,
       x="learning rate")+
  scale_y_continuous(n.breaks=4)
dev.off()

# To determine optimal parameters for model training, subset tuning results by number of trees
search_nt5000 <- search[search$n.trees==5000,]
search_nt15000 <- search[search$n.trees==15000,]
search_nt5000_sh0.01 <- search_nt5000[search_nt5000$shrinkage==0.010,]  #subset models with shrinkage==0.010

# Plot best.iter to see max number of trees to include
p1 <- search_nt5000 %>%
  # ggplot( aes(x=best, fill=type)) +
  ggplot( aes(x=best)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) +
  ggtitle("(A) ntrees=5000 and shrinkage=0.001")
p2 <- search_nt15000 %>%
  # ggplot( aes(x=best, fill=type)) +
  ggplot( aes(x=best)) +  
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080"))  +
  ggtitle("(B) ntrees=15000 and shrinkage=0.001")
p3 <- search_nt5000_sh0.01 %>%
  # ggplot( aes(x=best, fill=type)) +
  ggplot( aes(x=best)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) +
  ggtitle("(C) ntrees=5000 and shrinkage=0.01")

# load library for combining plots
library(cowplot)

# Combine plots and save to output
png("Output/histogram_brt_tuning_bestiter.png",width=12,height=4,units="in",res=600)
plot_grid(p1,p2,p3) +
  ggtitle("Histogram of best iteration")
dev.off()

# Clean
rm(search,search2,hok,mod,search_nt5000,search_nt15000,search_nt5000_sh0.01,p1,p2,p3)

```

### *BRT function for applying across multiple data partitions*
We create our BRT function for model training, where we apply the function across multiple data partitions.

```{r brt_partition}

# BRT function to use different data partitions
brt_part=function(seed,response){
  
  ## Make new dataset
  ndata=set
  
  ## Correct response variable
  ndata$response=ndata[response][,1]
  
  ## Remove raw response variable
    ndata$link=NULL

  ## For BRT where cites is the response variable...
  if(response=="cites"){
    
    ## We add 1 to cites if cites equals 0
    ndata$cites=ifelse(ndata$cites==0,1,ndata$cites)
    
  }else{
    
    ndata=ndata
    
  }
  
  ## Use rsample package to split data
  set.seed(seed)
  split=initial_split(ndata,prop=0.7,strata="response")
  
  ## Create test and train datasets
  dataTrain=training(split)
  dataTest=testing(split)
  
  ## Get response variable for test dataset and train dataset
  yTrain=dataTrain$response
  yTest=dataTest$response
  
  ## Save distribution
  dist=ifelse(response=="cites","poisson","bernoulli")
  
  ## Save number of trees based on previous plots of optimal iterations
  nt=ifelse(response=="cites",10000,
     ifelse(response=="link",4500,5000)) #see plots of best.iter 
  
  ## Run BRTs using gbm package
  set.seed(1)
  gbmOut=gbm(response ~ . ,data=dataTrain,
             n.trees=nt,
             distribution=dist,
             shrinkage=0.01, #see plots of best.iter 
             interaction.depth=3,
             n.minobsinnode=4,
             cv.folds=5,class.stratify.cv=TRUE,
             bag.fraction=0.5,train.fraction=1,
             n.cores=5,
             verbose=F)
            # par.details=(gbmParallel(num_threads=5)),

  ## Get optimal number of iterations using gbm.perf & set plotting parameters for permance chart generated by gbm.perf
  par(mfrow=c(1,1),mar=c(4,4,1,1))                         
  best.iter=gbm.perf(gbmOut,method="cv")  #estimates optimal number of boosting iterations for a gbm object                 
  
  ## Predict with test data, applying the optimal number of iterations as n.trees
  preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")
  
  ## Save known associations
  result=dataTest$response
  
  ## Get sensitivity and specificity
  sen=InformationValue::sensitivity(result,preds)
  spec=InformationValue::specificity(result,preds)
  
  ## Get AUC from model training
  auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))
  
  ## Get AUC from model test
  auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
  
  ## Skip if poisson
  if(response=="cites"){
    
    perf=NA
    
  }else{
    
    ## Inner loop if yTest is all 0
    if(var(yTest)==0){
      
      perf=NA
    }else{
      
      ## To construct an ROC curve, create a prediction object using the predicted probabilities and the true class labels (known responses)
      pr=prediction(preds,dataTest$response)   
      
      ## Next, calculate the desired performance measures specified by the 'measures' argument
      perf=performance(pr,measure="tpr",x.measure="fpr")         #pr=prediction object; measure=performance measure for evaluation; x.measure=second perf measure (2-D)
      
      ## Create a dataframe of those performance values
      perf=data.frame(perf@x.values,perf@y.values)
      
      
      ## Rename columns
      names(perf)=c("fpr","tpr")
      
      ## Add seed
      perf$seed=seed
      
    }
  }
  
  ## Get relative importance
  bars=summary(gbmOut,n.trees=best.iter,plotit=F)
  bars$rel.inf=round(bars$rel.inf,2)

  ## Predict with cites
  preds=predict(gbmOut,data,n.trees=best.iter,type="response")
  #pred_data=data[c("gtip",'treename',"fam","ord","pcr","competence")]
  pred_data=data[c("virus","gtip",'treename',"fam","ord","link")]
  pred_data$pred=preds
  pred_data$type=response
  
  ## Predict with mean cites
  pdata=data
  pdata$cites=mean(pdata$cites)
  pred_data$cpred=predict(gbmOut,pdata,n.trees=best.iter,type="response")
  
  ## Sort by decreasing predicted probability
  pred_data=pred_data[order(pred_data$pred,decreasing=T),]
  
  ## Print
  print(paste("BRT ",seed," done; test AUC = ",auc_test,sep=""))
  
  ## Save outputs
  return(list(mod=gbmOut,
              best=best.iter,
              trainAUC=auc_train,
              testAUC=auc_test,
              spec=spec,
              sen=sen,
              roc=perf,
              rinf=bars,
              predict=pred_data,
              traindata=dataTrain,
              testdata=dataTest,
              seed=seed))
}

```

### *Apply BRT function across 100 partitions to generate ensemble*

```{r brt_ensemble}

# Apply across 100 splits each
# smax=101
smax=100
brts=lapply(1:smax,function(x) brt_part(seed=x,response="link"))

# Run wos brts
pm_brts=lapply(1:(smax-1),function(x) brt_part(seed=x,response="cites"))

# Save results to working directory
save(brts,pm_brts,file="Output/brts_Model1.RData")
# save(brts,pm_brts,file="Output/brts_Model2.RData")

```

4. Model Performance
====================
Note: Model tuning and model predictions were run twice on HPC. Once with vaccinia virus links included (Model 1) and a second time excluding vaccinia virus links (Model 2).

### Load required packages and set system

```{r perf_load, echo=FALSE}

#(1) Libraries for BRT figures
library(tidyr)
library(ggplot2)
library(sciplot)
library(fastDummies)
library(caper)
library(ape)
library(treeio)
library(ggtree)
library(plotrix)
library(rstatix)
library(ggrepel)
library(ggpubr)
library(plyr)
library(pROC)

#(2) Clean environment
rm(list=ls()) 
graphics.off()

#(3) Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

### *Evaluate distribution of MPXV sequences in train and test datasets from Model 1 results using 'cites' variable as proxy*
To ensure that MPXV sequences were well distributed between train and test dataset, we plot 'cites' for each train and test datasets for each iteration. 
Figures: *plot_perf_mpxv_train.png*, *plot_perf_mpxv_test.png*, *plot_perf_mpxv_train_iter3.png*, *plot_perf_mpxv_test_iter3.png*

```{r perf_mpxv}

#### If needed, increase vector memory in R environment and reboot R before proceeding (https://stackoverflow.com/questions/51295402/r-on-macos-error-vector-memory-exhausted-limit-reached)

# Get data from Model 1
load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model1/Output/brts_Model1.RData")
brts1=brts
rm(brts)

# Extract cites from brts1 train data
ctrain=lapply(brts1,function(x) x$traindata$cites)
ctrain=do.call(rbind, ctrain)

# Convert to matrix
cmat_train = as.matrix(ctrain)
cmat_train = t(cmat_train)

# Change colnames
colnames(cmat_train) = paste("iter", seq(ncol(cmat_train)), sep="")

# Convert to dataframe
dat_train = as.data.frame(cmat_train)
dat_train$obs = rownames(dat_train)

# Reshape wide to long
mdat_train = reshape2::melt(dat_train, id.vars="obs")
# mdat_train$obs = as.numeric(gsub("obs", "", mdat_train$variable))
mdat_train$iter = as.factor(mdat_train$variable)
mdat_train$log10_cites = as.numeric(log10(mdat_train$value))
mdat_train$obs = as.numeric(mdat_train$obs)

# Plot as line graph by iteration
p_train = ggplot(mdat_train, aes(x=obs, y=log10_cites, color=iter)) +
    theme_bw() + theme(panel.grid=element_blank()) +
    theme(legend.position="none") +
    geom_line(linewidth=0.2, alpha=0.1) +
    stat_summary(aes(y = log10_cites), fun=mean, color="black", geom="line", linewidth=0.2, alpha=0.4)

# Save plot
png("Output/plot_perf_mpxv_train.png",width=20,height=15,units="in",res=300)
p_train
dev.off()

# Extract cites from brts1 train data
ctest=lapply(brts1,function(x) x$testdata$cites)
ctest=do.call(rbind, ctest)

# Convert to matrix
cmat_test = as.matrix(ctest)
cmat_test = t(cmat_test)

# Change colnames
colnames(cmat_test) = paste("iter", seq(ncol(cmat_test)), sep="")

# Convert to dataframe
dat_test = as.data.frame(cmat_test)
dat_test$obs = rownames(dat_test)

# Reshape wide to long
mdat_test = reshape2::melt(dat_test, id.vars="obs")
# mdat_train$obs = as.numeric(gsub("obs", "", mdat_train$variable))
mdat_test$iter = as.factor(mdat_test$variable)
mdat_test$log10_cites = as.numeric(log10(mdat_test$value))
mdat_test$obs = as.numeric(mdat_test$obs)

# Plot as line graph by iteration
p_test = ggplot(mdat_test, aes(x=obs, y=log10_cites, color=iter)) +
    theme_bw() + theme(panel.grid=element_blank()) +
    theme(legend.position="none") +
    geom_line(linewidth=0.2, alpha=0.1) +
    stat_summary(aes(y = log10_cites), fun=mean, colour="black", geom="line", linewidth=0.2, alpha=0.4)

# Save plot
png("Output/plot_perf_mpxv_test.png",width=20,height=15,units="in",res=300)
p_test
dev.off()

# Replot for iter 3 for train and test data
png("Output/plot_perf_mpxv_train_iter3.png",width=20,height=15,units="in",res=300)
ggplot(mdat_train[mdat_train$iter=="iter1" | mdat_train$iter=="iter2" | mdat_train$iter=="iter3" | mdat_train$iter=="iter4" | mdat_train$iter=="iter5",], aes(x=obs, y=log10_cites, color=iter)) +
    theme_bw() + theme(panel.grid=element_blank()) +
    geom_line(linewidth=0.2, alpha=1) 
dev.off()
png("Output/plot_perf_mpxv_test_iter3.png",width=20,height=15,units="in",res=300)
ggplot(mdat_test[mdat_test$iter=="iter1" | mdat_test$iter=="iter2" | mdat_test$iter=="iter3" | mdat_test$iter=="iter4" | mdat_test$iter=="iter5",], aes(x=obs, y=log10_cites, color=iter)) +
    theme_bw() + theme(panel.grid=element_blank()) +
    geom_line(linewidth=0.2, alpha=1)
dev.off()

# Clean environment
rm(cmat_test, cmat_train, ctest,ctrain, dat_test, dat_train, mdat_test, mdat_train, p_test, p_train)

```

### *Evaluate performance measures for Model 1 (all links) and Model 2 (excluding Vaccinia)*
How accurately did Model 1 and Model 2 distinguish host-virus links vs. non-links (assuming a threshold value of 0.5)? We evaluate the mean AUC, sensitivity, and specificity of our models.

```{r perf_auc}

# Get data from Model 1
load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model1/Output/brts_Model1.RData")
brts1=brts
rm(brts)

# Get data from Model 2
load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model2/Output/brts_Model2.RData")
brts2=brts
rm(brts)

# Index non-missing
keep1=which(!is.na(sapply(brts1,function(x) x$testAUC)))
keep2=which(!is.na(sapply(brts2,function(x) x$testAUC)))

# Trim, keeping only those that are non-missing
brts1=brts1[keep1]
brts2=brts2[keep2]

# Check number of iterations
length(keep1)
length(keep2)

### MODEL 1 (INCL. VACCINIA LINKS): Get model performance measures assuming 0.5 threshold ###

# Get predicted probabilities for each iteration
m1_cpreds=lapply(brts1,function(x) x$predict)
m1_cpreds=lapply(m1_cpreds,function(x) select(x,c("link","cpred")))

# Get AUC for each iteration and calculate mean AUC and standard error across iterations
m1_auc = lapply(m1_cpreds, function(x) auc(x$link, x$cpred))
mean = mean(sapply(m1_auc,function(x) x))
se = std.error(sapply(m1_auc,function(x) x))
m1_auc_mean <- paste0(sprintf("%.2f",mean), " \u00b1 ", sprintf("%.3f",se))

# Get sensitivity for each iteration and calculate mean sensitivity and standard error across iterations
m1_sens = lapply(m1_cpreds, function(x) InformationValue::sensitivity(x$link, x$cpred, threshold=0.5))
mean = mean(sapply(m1_sens,function(x) x))
se = std.error(sapply(m1_sens,function(x) x))
m1_sens_mean <- paste0(sprintf("%.2f",mean), " \u00b1 ", sprintf("%.3f",se))

# Get specificity for each iteration and calculate mean specificity and standard error across iterations
m1_spec = lapply(m1_cpreds, function(x) InformationValue::specificity(x$link, x$cpred, threshold=0.5))
mean = mean(sapply(m1_spec,function(x) x))
se = std.error(sapply(m1_spec,function(x) x))
m1_spec_mean <- paste0(sprintf("%.2f",mean), " \u00b1 ", sprintf("%.3f",se))

### MODEL 2 (EXCL. VACCINIA LINKS): Get model performance measures assuming 0.5 threshold ###

# Get predicted probabilities for each iteration
m2_cpreds=lapply(brts2,function(x) x$predict)
m2_cpreds=lapply(m2_cpreds,function(x) select(x,c("link","cpred")))

# Get AUC for each iteration and calculate mean AUC and standard error across iterations
m2_auc = lapply(m2_cpreds, function(x) auc(x$link, x$cpred))
mean = mean(sapply(m2_auc,function(x) x))
se = std.error(sapply(m2_auc,function(x) x))
m2_auc_mean <- paste0(sprintf("%.2f",mean), " \u00b1 ", sprintf("%.3f",se))

# Get sensitivity for each iteration and calculate mean sensitivity and standard error across iterations
m2_sens = lapply(m2_cpreds, function(x) InformationValue::sensitivity(x$link, x$cpred, threshold=0.5))
mean = mean(sapply(m2_sens,function(x) x))
se = std.error(sapply(m2_sens,function(x) x))
m2_sens_mean <- paste0(sprintf("%.2f",mean), " \u00b1 ", sprintf("%.3f",se))

# Get specificity for each iteration and calculate mean specificity and standard error across iterations
m2_spec = lapply(m2_cpreds, function(x) InformationValue::specificity(x$link, x$cpred, threshold=0.5))
mean = mean(sapply(m2_spec,function(x) x))
se = std.error(sapply(m2_spec,function(x) x))
m2_spec_mean <- paste0(sprintf("%.2f",mean), " \u00b1 ", sprintf("%.3f",se))

# Clean environment; save performance metrics to create a table in the next section
rm(m1_cpreds, m2_cpreds, keep1, keep2, mean, se)

```

### *Compare performance between BRTs trained on host-virus associations including and excluding vaccinia virus*
Is model performance significantly different when trained on all links (Model 1) vs. links excluding Vaccinia virus (Model 2)? We create a function to perform an unpaired T-test on the AUC, sensitivity and specificity of the two models and determine the effect size (mean difference) via Cohen's d.

```{r perf_compare}

### T-test for AUC ###

# Get auc values for model 1
adata_m1=data.frame(y=c(sapply(m1_auc, function(x) x)))
adata_m1$seed = 1:nrow(adata_m1)
adata_m1$response = "model1"

# Get auc values for model 2
adata_m2=data.frame(y=c(sapply(m2_auc, function(x) x)))
adata_m2$seed = 1:nrow(adata_m2)
adata_m2$response = "model2"
adata_auc=rbind(adata_m1, adata_m2)

# Transform 'response' to factor
adata_auc$response=factor(adata_auc$response,levels=c('model1','model2'))
 
# T-test
tsum_auc=t.test(y~response,data=adata_auc,
            alternative='two.sided',
            var.equal=F,paired=F)  
  
# Effect size
csum_auc=cohens_d(y~response,data=adata_auc,paired=F,var.equal=F)

### T-test for sensitivity ###

# Get sensitivity values for model 1 
adata_m1=data.frame(y=c(sapply(m1_sens, function(x) x)))
adata_m1$seed = 1:nrow(adata_m1)
adata_m1$response = "model1"

# Get sensitivity values for model 2
adata_m2=data.frame(y=c(sapply(m2_sens, function(x) x)))
adata_m2$seed = 1:nrow(adata_m2)
adata_m2$response = "model2"
adata_sens=rbind(adata_m1, adata_m2)

# Transform 'response' to factor
adata_sens$response=factor(adata_sens$response,levels=c('model1','model2'))
 
# T-test
tsum_sens=t.test(y~response,data=adata_sens,
            alternative='two.sided',
            var.equal=F,paired=F)  
  
# Effect size
csum_sens=cohens_d(y~response,data=adata_sens,paired=F,var.equal=F)

### T-test for specificity ###

# Get sensitivity values for model 1 
adata_m1=data.frame(y=c(sapply(m1_spec, function(x) x)))
adata_m1$seed = 1:nrow(adata_m1)
adata_m1$response = "model1"

# Get sensitivity values for model 2
adata_m2=data.frame(y=c(sapply(m2_spec, function(x) x)))
adata_m2$seed = 1:nrow(adata_m2)
adata_m2$response = "model2"
adata_spec=rbind(adata_m1, adata_m2)

# Transform 'response' to factor
adata_spec$response=factor(adata_spec$response,levels=c('model1','model2'))
 
# T-test
tsum_spec=t.test(y~response,data=adata_spec,
            alternative='two.sided',
            var.equal=F,paired=F)  
  
# Effect size
csum_spec=cohens_d(y~response,data=adata_spec,paired=F,var.equal=F)

# Adjust p-values w/ Benjamini Hochberg correction method
ps=c(tsum_auc$p.value,
     tsum_sens$p.value,
     tsum_spec$p.value)
ps_adjust <- sprintf("%.4f",p.adjust(ps,method="BH"))    #"BH" (aka "fdr") = Benjamini & Hochberg (1995) method control the false discovery rate, the expected proportion of false discoveries amongst the rejected hypotheses (false discovery rate is less stringent condition than family-wise error rate)

# Create and save table of performance measures 
table_perf_metrics <- data.frame(matrix(c(m1_auc_mean, m1_sens_mean, m1_spec_mean, 
                                          m2_auc_mean, m2_sens_mean, m2_spec_mean,
                                          sprintf("%.2f", tsum_auc$statistic), 
                                          sprintf("%.2f", tsum_sens$statistic), 
                                          sprintf("%.2f", tsum_spec$statistic), 
                                          ps_adjust, 
                                          sprintf("%.2f", csum_auc$effsize), 
                                          sprintf("%.2f", csum_sens$effsize), 
                                          sprintf("%.2f", csum_spec$effsize)), 
                                  ncol=3, byrow=TRUE))

# Rename columns and rownames
colnames(table_perf_metrics) <- c('AUC (mean \u00b1 SE)', 'Sensitivity (mean \u00b1 SE)', 'Specificity (mean \u00b1 SE)')
rownames(table_perf_metrics) <- c('Link prediction model', 'Link prediction model excluding VACV associations', 't-test', 'p-val', "Cohen's d")

# Save table
write.csv(table_perf_metrics, "Output/table_perf_metrics.csv")

# Clean environment
rm(list=setdiff(ls(), c("brts1", "brts2", 
                        "adata_auc", "adata_sens", "adata_spec")))

```

<!-- ### *Evaluate performance measures for Model 1 (all links) and Model 2 (excluding Vaccinia)* -->
<!-- How accurately did Model 1 and Model 2 distinguish host-virus links vs. non-links (assuming a threshold value of 0.5)? We evaluate the mean AUC, sensitivity, and specificity of our models. -->

<!-- ```{r perf_auc} -->

<!-- # Get data from Model 1 -->
<!-- load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model1/Output/brts_Model1.RData") -->
<!-- brts1=brts -->
<!-- rm(brts) -->

<!-- # Get data from Model 2 -->
<!-- load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model2/Output/brts_Model2.RData") -->
<!-- brts2=brts -->
<!-- rm(brts) -->

<!-- # Index non-missing -->
<!-- keep1=which(!is.na(sapply(brts1,function(x) x$testAUC))) -->
<!-- keep2=which(!is.na(sapply(brts2,function(x) x$testAUC))) -->

<!-- # Trim, keeping only those that are non-missing -->
<!-- brts1=brts1[keep1] -->
<!-- brts2=brts2[keep2] -->

<!-- # Get AUC for Model 1 -->
<!-- auc1 <- paste0(round(mean(sapply(brts1,function(x) x$testAUC)),3), " (", round(std.error(sapply(brts1,function(x) x$testAUC)),4), ")") -->

<!-- # Get sensitivity for Model 1 -->
<!-- sens1 <- paste0(round(mean(sapply(brts1,function(x) x$sen)),3)," (", round(std.error(sapply(brts1,function(x) x$sen)),4), ")") -->

<!-- # Get specificity for Model 1 -->
<!-- spec1 <- paste0(round(mean(sapply(brts1,function(x) x$spec)),3), " (", round(std.error(sapply(brts1,function(x) x$spec)),4), ")") -->

<!-- # Get AUC for Model 2 -->
<!-- auc2 <- paste0(round(mean(sapply(brts2,function(x) x$testAUC)),3), " (", round(std.error(sapply(brts2,function(x) x$testAUC)),4), ")") -->

<!-- # Get sensitivity for Model 2 -->
<!-- sens2 <- paste0(round(mean(sapply(brts2,function(x) x$sen)),3), " (", round(std.error(sapply(brts2,function(x) x$sen)),4), ")") -->

<!-- # Get specificity for Model 2 -->
<!-- spec2 <- paste0(round(mean(sapply(brts2,function(x) x$spec)),3), " (", round(std.error(sapply(brts2,function(x) x$spec)),4), ")") -->

<!-- # # Get AUC for Cites Model 1 -->
<!-- # paste0(round(mean(sapply(pm_brts1,function(x) x$testAUC)),3), " (", round(std.error(sapply(pm_brts1,function(x) x$testAUC)),4), ")") -->

<!-- # # Get AUC for Cites Model 2 -->
<!-- # paste0(round(mean(sapply(pm_brts2,function(x) x$testAUC)),3), " (", round(std.error(sapply(pm_brts2,function(x) x$testAUC)),4), ")") -->

<!-- # Clean environment -->
<!-- rm(keep1, keep2)  -->

<!-- ``` -->

<!-- ### *Compare performance between BRTs trained on infection vs. competence* -->
<!-- Is model performance significantly different when trained on all links (Model 1) vs. links excluding Vaccinia virus (Model 2)? We create a function to perform an unpaired T-test on the AUC, sensitivity and specificity of the two models and determine the effect size (mean difference) via Cohen's d. -->

<!-- ```{r perf_compare} -->

<!-- # Function for extracting data, performing unpaired t-test and determining effect size via Cohen's d -->
<!-- tfun=function(measure){ -->

<!--   ## format data -->
<!--   n=length(sapply(brts1,function(x) x$measure)) -->
<!--   adata=data.frame(y=c(sapply(brts1,function(x) x[measure][[1]]), -->
<!--                        sapply(brts2,function(x) x[measure][[1]])), -->
<!--                    response=c(rep('model1',n),rep('model2',n)), -->
<!--                    seed=c(sapply(brts1,function(x) x$seed), -->
<!--                           sapply(brts2,function(x) x$seed))) -->
<!--   rm(n) -->

<!--   ## factor -->
<!--   adata$model=factor(adata$response,levels=c('model1','model2')) -->

<!--   ## make jitter position -->
<!--   adata$x=as.numeric(factor(adata$response)) -->
<!--   set.seed(1) -->
<!--   adata$xj=jitter(adata$x,0.5) -->

<!--   ## fix response -->
<!--   adata$response1=plyr::revalue(adata$response,c("model1"="Full Model", -->
<!--                                            "model2"="Partial Model")) -->

<!--   ## t-test -->
<!--   tsum=t.test(y~response,data=adata, -->
<!--               alternative='two.sided', -->
<!--               var.equal=F,paired=F)   -->

<!--   ## effect size -->
<!--   csum=cohens_d(y~response,data=adata,paired=F,var.equal=F) -->

<!--   ## return -->
<!--   return(list(adata=adata,tsum=tsum,csum=csum)) -->
<!-- } -->

<!-- # Compare AUC between models; extract t-stat and Cohen's d -->
<!-- adata=tfun("testAUC") -->
<!-- adata$tsum$statistic -->
<!-- adata$csum$effsize -->

<!-- # Compare sensitivity between models; extract t-stat and Cohen's d -->
<!-- sedata=tfun("sen") -->
<!-- sedata$tsum$statistic -->
<!-- sedata$csum$effsize -->

<!-- # Compare specificity between models; extract t-stat and Cohen's d -->
<!-- spdata=tfun("spec") -->
<!-- spdata$tsum$statistic -->
<!-- spdata$csum$effsize -->

<!-- # Adjust p values w/ Benjamini Hochberg correction method -->
<!-- ps=c(adata$tsum$p.value, sedata$tsum$p.value, spdata$tsum$p.value) -->
<!-- ps_adjust <- round(p.adjust(ps,method="BH"),4)     -->
<!-- ###"BH" (aka "fdr") = Benjamini & Hochberg (1995) method controls the false discovery rate, the expected proportion of false discoveries among the rejected hypotheses (false discovery rate is less stringent condition than family-wise error rate) -->

<!-- # Create and save table of performance measures  -->
<!-- ts4 <- data.frame(matrix(c(auc1, sens1, spec1,  -->
<!--                 auc2, sens2, spec2,  -->
<!--                 round(adata$tsum$statistic,2), round(sedata$tsum$statistic,2), round(spdata$tsum$statistic,2),  -->
<!--                 ps_adjust,  -->
<!--                 round(adata$csum$effsize,2), round(sedata$csum$effsize,2), round(spdata$csum$effsize,2)),  -->
<!--             ncol=3, byrow=TRUE)) -->
<!-- colnames(ts4) <- c('mean_AUC (SE)', 'mean_sens (SE)', 'mean_spec (SE)') -->
<!-- rownames(ts4) <- c('Model 1', 'Model 2', 't-test', 'p-val', "Cohen's d") -->
<!-- write.csv(ts4, "Output/table_perf_metrics.csv") -->

<!-- # Clean environment -->
<!-- rm(tfun, ts4, auc1, sens1, spec1, auc2, sens2, spec2, ps, ps_adjust) -->

<!-- ``` -->

### How do performance measures change when we apply different optimal threshold values (e.g., based on maximizing sensitivity + specificity)?

```{r perf_thv}

### OPTION 1 ### Get optimized THV from the predicted probabilities of all 100 iterations

# Row-bind predicted values of all iterations for Model 1
model1=lapply(brts1,function(x) x$predict)
model1=do.call(rbind,model1)

# Row-bind predicted values of all iterations for Model 2
model2=lapply(brts2,function(x) x$predict)
model2=do.call(rbind,model2)

# Build an ROC curve from the predicted probabilities of all iterations (and known links) for Model 1 and Model 2
roc1 <- roc(model1$link,model1$cpred, auc=TRUE, ci=TRUE)
roc2 <- roc(model2$link,model2$cpred, auc=TRUE, ci=TRUE)

# Plot ROC curve for Model 1
png("Output/ROCcurve_thv0.5_model1.png",width=8,height=6,units="in",res=300)
plot(roc1, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
  grid.col=c("gray", "gray"), max.auc.polygon=TRUE,
  auc.polygon.col="lightblue", print.thres=TRUE) #print.thres based on max(sens+spec)
dev.off()

# Plot ROC curve for Model 2
plot(roc2, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
  grid.col=c("gray", "gray"), max.auc.polygon=TRUE,
  auc.polygon.col="lightblue", print.thres=TRUE)

# Get optimum THV by finding THV when sens+spec are maximized for Model 1
tss <- cbind(roc1$thresholds, roc1$sensitivities + roc1$specificities)
thv1_mss <- subset(tss, tss[,2]==max(tss[,2]))[,1]

# Get optimum THV by finding THV when sens+spec are maximized for Model 2
tss <- cbind(roc2$thresholds, roc2$sensitivities + roc2$specificities)
thv2_mss <- subset(tss, tss[,2]==max(tss[,2]))[,1] 

### OPTION 2 ### Get optimized THV averaged across all 100 model iterations based on predicted probs

# Model 1: Build individual ROCs for each iteration; compile as a list
roc1=lapply(brts1,function(x) roc(x$predict$link,x$predict$cpred, auc=TRUE,ci=TRUE))

# Model 1: Calculate mean AUC from roc (thv=0.5)
auc=unlist(lapply(roc1, function(x) x$auc))
mean(auc)
std.error(auc)

# Model 1: Plot ROC curves
png("Output/ROCcurve_thv0.5_model1_eachiter.png",width=8,height=6,units="in",res=300)
plot(roc1[[1]])
for (i in 2:length(roc1)) {
   plot(roc1[[i]], add=TRUE, grid=c(0.1, 0.2),
  grid.col=c("gray", "gray"))
}
dev.off()

# Model 1: For each iteration's ROC, extract the threshold value and the sum of sensitivity + specificity
tss1=lapply(roc1, function(x) cbind(x$thresholds, x$sensitivities + x$specificities))

# Model 1: For each iteration, extract the threshold value where sens+spec were maximized
thv1_mss = lapply(tss1, function(x) subset(x, x[,2]==max(x[,2]))[,1])

# Model 1: Get the mean and standard error of those threshold values; this is our calculated optimal threshold value
thv1_mss_mean = mean(sapply(thv1_mss, function(x) x))
thv1_mss_se =se(sapply(thv1_mss, function(x) x))

# Model 1: For each iteration, get the coordinates (sensitivity & specificity) of the ROC curve applying the mean threshold value
coords1 = lapply(roc1, function(x) coords(x, thv1_mss_mean, input="threshold"))

# Model 1: Extract sens and spec values from coordinate points
coords1_sens = unlist(lapply(coords1, function(x) x$sensitivity))
coords1_spec = unlist(lapply(coords1, function(x) x$specificity))

# Model 1: Calculate corresponding mean sens and spec
mean(coords1_sens)
std.error(coords1_sens)

# Model 1: Get optimized AUC
AUC_optimized <- unlist(lapply(roc1, function(x) auc(x, thresholds=thv1_mss_mean)))
AUC_optimized_mean <- mean(AUC_optimized)
print(AUC_optimized_mean)

# Model 2: Build individual ROCs for each iteration; compile as a list
roc2=lapply(brts2,function(x) roc(x$predict$link,x$predict$cpred, auc=TRUE,ci=TRUE))

# Model 2: Calculate mean AUC from roc (thv=0.5)
auc=unlist(lapply(roc2, function(x) x$auc))
mean(auc)
std.error(auc)

# Model 2: Plot ROC curves
plot(roc2[[1]])
for (i in 2:length(roc1)) {
   plot(roc2[[i]], add=TRUE, grid=c(0.1, 0.2),
  grid.col=c("gray", "gray"))
}  

# Model 2: For each iteration's ROC, extract the threshold value and the sum of sensitivity + specificity
tss2=lapply(roc2, function(x) cbind(x$thresholds, x$sensitivities + x$specificities))

# Model 2: For each iteration, extract the threshold value where sens+spec were maximized
thv2_mss = lapply(tss2, function(x) subset(x, x[,2]==max(x[,2]))[,1])

# Model 2: Get the mean and standard error of those threshold values
thv2_mss_mean = mean(sapply(thv2_mss, function(x) x))
thv2_mss_se =se(sapply(thv2_mss, function(x) x))

# Model 2: For each iteration, get the coordinates of the ROC curve applying the mean threshold value and extract sens and spec values
coords2 = lapply(roc2, function(x) coords(x, thv2_mss_mean, input="threshold"))
coords2_sens = unlist(lapply(coords2, function(x) x$sensitivity))
coords2_spec = unlist(lapply(coords2, function(x) x$specificity))

# Model 2: Calculate corresponding mean sens and spec
mean(coords2_spec)
std.error(coords2_spec)

### OPTION 2 ### Get optimum THV based on the ROC curve: maximize TRP and FPR (true/false positive rate) by minimizing |FPR + TPR - 1|, which is equal to minimizing |sensitivity - specificity|.

# Model 1: Unlist and extract sensitivity, specificity and threshold values
sensitivities <- unlist(lapply(roc1, function(x) x$sensitivities))
specificities <- unlist(lapply(roc1, function(x) x$specificities))
thresholds <- unlist(lapply(roc1, function(x) x$thresholds))

# Model 1: Combine values into df
df <- as.data.frame(cbind(sensitivities, specificities, thresholds))
colnames(df) <- c("sens", "spec", "thresh")
df <- subset(df, is.finite(df$thresh))

# Model 1: Create variable = |sensitivity - specificity|
df$sens_spec <- abs(df$sens - df$spec)

# Model 1: Plot sens_spec to see threshold level at minimum 
ggplot(df, aes(thresh, sens_spec)) + geom_line()

# Model 1: Get values
df[which.min(df$sens_spec),]
thv1_minss <- df[which.min(df$sens_spec),3]

# Model 1: Get optimized AUC
roc1 <- roc(model1$link,model1$cpred)
AUC_optimized <- auc(roc1, thresholds = thv1_minss)
print(AUC_optimized)

# Clean environment
rm(list=setdiff(ls(), c("adata","brts1","brts2","sedata","spdata")))

```

### *Generate boxplot of model performance*
Figures: *boxplot_model_senspec.png*, *boxplot_model_auc.png*

```{r perf_boxplot}

# Create list of dataframes
list_dfs <- list(adata_auc, adata_sens, adata_spec)

# Generate additional variables needed for plotting model performance
for (i in 1:length(list_dfs)){
  
  ## make jitter position to spread out points along the x-coordinate
  list_dfs[[i]]$x=as.numeric(factor(list_dfs[[i]]$response))
  set.seed(1)
  list_dfs[[i]]$xj=jitter(list_dfs[[i]]$x,0.5)
  
  # ## fix response
  # list_dfs[[i]]$respond2=plyr::revalue(list_dfs[[i]]$response,c("model1"="Host-virus links","model2"="Host-virus links excludin VACV"))
}

# Unlist
df_auc <- as.data.frame(list_dfs[[1]])
df_sens <- as.data.frame(list_dfs[[2]])
df_spec <- as.data.frame(list_dfs[[3]])

# Add type variable
df_auc$type="auc"
df_sens$type="sensitivity"
df_spec$type="specificity"

# Aggregate sens and spec datasets
sdata=rbind.data.frame(df_sens, df_spec)


# Extract sensitivity and specificity data; save as new dataframes
data1=sedata$adata
data2=spdata$adata

# Group observations by type for plotting
data1$type="sensitivity"
data2$type="specificity"

# Aggregate datasets
sdata=rbind.data.frame(data1,data2)
rm(data1,data2,sedata,spdata)

# Boxplot of AUC
png("Output/boxplot_model_auc.png",width=4,height=5,units="in",res=300)
set.seed(1)
ggplot(df_auc)+
  geom_boxplot(aes(x=x,y=y,group=x),width=0.25,alpha=0.25,outlier.alpha=0)+
  geom_point(aes(x=xj,y=y),size=1.5,alpha=0.5)+
  scale_x_continuous(breaks=c(1,2),
                     labels=c("Host-virus links","Host-virus links \n excluding VACV"),
                     limits=c(0.5,2.5))+
  theme_bw()+
  labs(x="Response variable",
       y="Area under the curve (AUC)")+
  theme(axis.text=element_text(size=10),
        axis.text.x=element_text(size=8),
        axis.title=element_text(size=12))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  guides(colour="none")
dev.off()

# Boxplot of sensitivity and specificity
png("Output/boxplot_model_senspec.png",width=4,height=5,units="in",res=300)
set.seed(1)
ggplot(sdata) +
  geom_boxplot(aes(x=x,y=y,group=x),width=0.25,alpha=0.25,outlier.alpha=0)+
  geom_point(aes(x=xj,y=y),size=1.5,alpha=0.5)+
  scale_x_continuous(breaks=c(1,2),
                     labels=c("Host-virus links","Host-virus links \n excluding VACV"),
                     limits=c(0.5,2.5))+
  theme_bw()+
  facet_wrap(~type,scales="free_y",strip.position="left",ncol=1)+
  theme(strip.placement="outside",
        strip.background=element_blank())+
  labs(x="Response variable",
       y=NULL)+
  theme(axis.text.y=element_text(size=10),
        axis.text.x=element_text(size=8),
        axis.title=element_text(size=12),
        strip.text=element_text(size=12))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  guides(colour="none")
dev.off()

```


5. Model Predictions
====================
In this chapter, we examine predictions from our BRT models assessing the predicted probabilities of OPV positivity. 

### *Load required packages and set system*

```{r pred_load}

# Libraries for BRT figures
library(tidyr)
library(ggplot2)
library(sciplot)
library(fastDummies)
library(caper)
library(ape)
library(phylofactor)
library(plotrix) #std.error
library(rstatix)
library(ggrepel)
library(ggpubr) #ggarrange
library(plyr)
library(dplyr)

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

### *Extract and save predicted probabilities*
Table: *table_LinkPredictionModel1_predictions.csv*, *table_LinkPredictionModel2_predictions.csv*

```{r pred_save}

# Load Model 1 predictions
load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model1/Output/brts_Model1.RData")
brts1=brts
rm(brts)

# load Model 2 predictions
load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model2/Output/brts_Model2.RData")
brts2=brts
rm(brts)

# Load cleaned data file
library(fastDummies)
load("Output/LinkPredictionModel_CleanData.RData")
data <- linkdata

# Make binary columns for each taxonomic family in our dataset
dums=dummy_cols(data["fam"])

# Get only unique observations
dums=dums[!duplicated(dums$fam),]

# Ensure all are factor
for(i in 1:ncol(dums)){
  ## column as factor
  dums[,i]=factor(dums[,i])
}

# Merge family variables with poxdata
data=merge(data,dums,by="fam",all.x=T)
rm(dums)

# Get predicted probabilities from Model 1
model1_apreds=lapply(brts1,function(x) x$predict)
model1_apreds=do.call(rbind,model1_apreds)

# Collapse to mean of predicted probabilities for each unique treename/tip
model1_apreds=data.frame(aggregate(pred~treename+virus,data=model1_apreds,mean), 
                         aggregate(cpred~treename+virus,data=model1_apreds,mean)['cpred'], ## holding wos constant
                      aggregate(link~treename+virus,data=model1_apreds,prod)['link'])

# Generate variable of model type/number
model1_apreds$type='Model1'

# Get predicted probabilities from Model 2
model2_apreds=lapply(brts2,function(x) x$predict)
model2_apreds=do.call(rbind,model2_apreds)

# Collapse to mean of predicted probabilities for each unique treename/tip
model2_apreds=data.frame(aggregate(pred~treename+virus,data=model2_apreds,mean),
                       aggregate(cpred~treename+virus,data=model2_apreds,mean)['cpred'], ## holding wos constant
                       aggregate(link~treename+virus,data=model2_apreds,prod)['link'])

# Generate variable of model type/number
model2_apreds$type='Model2'

# Combine predictions from Model 1 and 2
apreds=rbind.data.frame(model1_apreds,model2_apreds)

# Transform type variable to factor and generate new type variable and revalue
library(plyr)
apreds$type=factor(apreds$type,levels=c("Model1","Model2"))
apreds$type2=revalue(apreds$type,c("Model1"="FullModel","Model2"="PartialModel"))

# Transform apreds long to wide, keeping cpred b/c these are our predicted probabilities after holding citations at their average (isolating their effect on prediction; we control for the confounding effects of citations)
apreds2=spread(apreds[c('virus','treename','type','cpred')],type,cpred)
model1_apreds$link1=model1_apreds$link
model2_apreds$link2=model2_apreds$link

# Merge with apreds2
apreds2=merge(apreds2,model1_apreds[c("virus","treename","link1")],by=c("virus","treename"),all=TRUE)
apreds2=merge(apreds2,model2_apreds[c("virus","treename","link2")],by=c("virus","treename"),all=TRUE)

# Check that datasets merged correctly, links for vaccinia virus should be NA for 'Model2' and 'link2'
View(apreds2[apreds2$virus=="vaccinia virus",])

# Fix variable names
names(apreds2)=c("virus","treename","pred_Model1","pred_Model2","link1","link2")

# Merge with data
apreds2=merge(apreds2,data[c("virus","treename","source","ord","fam","genus")],by=c('virus','treename'),all.x=TRUE)

# View(apreds2[duplicated(apreds2),]) #check 
apreds2 <- apreds2[!duplicated(apreds2),]
apreds=merge(apreds,data[c("virus","treename","source")],by=c('virus','treename'),all.x=TRUE)
# View(apreds[duplicated(apreds),]) #check 
apreds <- apreds[!duplicated(apreds),]

# Fix source labels
apreds2$cat=ifelse(apreds2$source=="NA","Pseudoabsence",apreds2$source)
apreds2$cat=ifelse(apreds2$source=="both","Virion & WGS",apreds2$cat)
apreds2$cat=ifelse(apreds2$source=="virion","Virion", apreds2$cat)
apreds2$cat=ifelse(apreds2$source=="wgs","WGS", apreds2$cat)

apreds$cat=ifelse(apreds$source=="NA","Pseudoabsence",apreds$source)
apreds$cat=ifelse(apreds$source=="both","Virion & WGS",apreds$cat)
apreds$cat=ifelse(apreds$source=="virion","Virion", apreds$cat)
apreds$cat=ifelse(apreds$source=="wgs","WGS", apreds$cat)

# Fix source type
apreds2$cat=factor(apreds2$cat,c("Pseudoabsence","Virion","Virion & WGS", "WGS"))
apreds$cat=factor(apreds$cat,levels=levels(apreds2$cat))

# Fix type2
apreds$type2=revalue(apreds$type2,
                     c("FullModel"="Full Model",
                       "PartialModel"="Partial Model"))

# Reformat for saving
preds=apreds2
preds$source=preds$cat
library(stringr)
preds$fam=str_to_title(preds$fam)
preds$ord=str_to_title(preds$ord)

# Subset predictions for each model and save
preds1=preds[c("source","virus","treename","fam","ord","pred_Model1","link1")]
preds2=preds[c("source","virus","treename","fam","ord","pred_Model2","link2")]
write.csv(preds1,"Output/table_LinkPredictionModel1_predictions.csv")
write.csv(preds2,"Output/table_LinkPredictionModel2_predictions.csv")

#(22) Print predicted links organized by virus and source for discussion
preds1=preds1[order(preds1$virus,preds1$source,-preds1$pred_Model1),]
paste0("Predicted links for Model 1 by virus and source")
preds1[preds1$pred_Model1>0.5,]
length(which(preds1$pred_Model1>0.5))
length(which(preds1$pred_Model1>thv1_mss_mean))
length(which(preds1$pred_Model1>thv1_minss))

preds2=preds2[order(preds2$virus,preds2$source,-preds2$pred_Model2),]
paste0("Predicted links for Model 2 by virus and source")
preds2[preds2$pred_Model2>0.5,]
length(which(preds2$pred_Model2>0.5))
length(which(preds2$pred_Model2>thv2_mss_mean))

# Clean environment
rm(preds1, preds2)

```

### *Visualize how predicted probabilities are distributed*
Figures: *plot_pp.png*

```{r pred_figure}

# Load library for color palette; select and re-order colors
remotes::install_github("awhstin/awtools")
library(awtools)
cc=mpalette[2:5] 
cc=rev(cc)

# Density plot of predicted probabilities
densityplot_pp=ggplot(apreds,aes(cpred))+
  geom_density(aes(fill=cat,colour=cat),alpha=0.5)+
  facet_wrap(~type2,ncol=1,strip.position='top',scales="free_y")+
  theme_bw()+
  theme(legend.position="top")+
  labs(x=expression(paste("Predicted probability (",italic(P),") of link")))+
  xlim(0,0.1)+
  # xlim(thv1_mss_mean,1)+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        legend.title=element_text(size=12),
        legend.text=element_text(size=11),
        strip.text=element_text(size=11),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(20,20,20,20))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  scale_colour_manual(values=cc)+
  scale_fill_manual(values=cc)+
  guides(colour=guide_legend(title="(a) Host-OPV positivity"),
         fill=guide_legend(title="(a) Host-OPV positivity"))

# Scatterplot of predicted probabilities
scatterplot_pp=ggplot(apreds2,aes(pred_Model1,pred_Model2))+
  geom_point(alpha=0.5,size=2,aes(colour=cat,fill=cat))+
  geom_smooth(method='gam',colour="grey")+
  labs(x=expression(paste(italic(P),' from Full Model 1')),
       y=expression(paste(italic(P),' from Partial Model 2')))+
  theme_bw()+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        legend.title=element_text(size=12),
        legend.text=element_text(size=11),
        strip.text=element_text(size=11),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(20,20,20,20))+
  theme(legend.position="top")+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  scale_colour_manual(values=cc)+
  scale_fill_manual(values=cc)+
  guides(colour=guide_legend(title="(a) Host-OPV positivity"),
         fill=guide_legend(title="(a) Host-OPV positivity"))

# Combine density plot with scatterplot of predicted probabilities; save
png("Output/plot_pp.png",width=6.5,height=4,units="in",res=300)
ggarrange(densityplot_pp,scatterplot_pp,common.legend=T)
dev.off()

# Clean environment
rm(densityplot_pp,scatterplot_pp, cc)

```

### *Explore the effects of threshold moving on binary classification*
We calculate various optimal threshold values and evaluate how threshold moving changes classification of OPV links vs. non-links.
Table: *table_thresholdvalues_model1.csv*,
*table_LinkPredictionModel1_PredictedLinks.xlsx*, 
*table_LinkPredictionModel1_virusratio.xlsx*, *table_thresholdvalues_model2.csv*,
*table_LinkPredictionModel2_PredictedLinks.xlsx*, 
*table_LinkPredictionModel2_virusratio.xlsx*

```{r pred_threshold}

# Load libraries
library(openxlsx)
library(PresenceAbsence) #for thresholding results

# Set seed
set.seed(12345)

###########################################################################
### Extract Binary Predictions for Model 1 ###
###########################################################################

### CALCULATE THRESHOLD VALUES ###

# Load predictions for Model 1
pred1 <- read.csv("Output/table_LinkPredictionModel1_predictions.csv")
pred1$virus_treename=paste0(pred1$virus, "%",pred1$treename)

### Predictions with 'feline poxvirus ita2_bc' as known associations (i.e., with Homo) should have been classified as 'cowpox virus', but b/c cowpox virus already had a known association with Homo, we drop it out of these prediction instead.

# Drop out 'feline poxvirus ita2_bc'
pred1 <- pred1[!(pred1$virus=="feline poxvirus ita2_bc"),]

# Create table of optimal threshold values for 5 different methods
ts1 <- optimal.thresholds(data.frame(pred1[,c('virus_treename','link1','pred_Model1')]),
                           threshold = 10001,
                           opt.methods = c(2,3,4,5,10), 
                           req.sens = 0.80,
                           na.rm = TRUE)
  #opt.methods=2: Sens=Spec = 0.0385000
  #opt.methods=3: MaxSens+Spec = 0.0597000
  #opt.methods=4: MaxKappa = 0.4949000 (Th that gives max value of Kappa - assess improvement over chance prediction)
  #opt.methods=5: MaxPCC = 0.5670222 (Th that maximizes total accuracy or Percent Correctly Classified)
  #opt.methods=10: ReqSens = 0.0365000 (set required sensitivity - req.sens)

# Add method applying 85% required sensitivity
ts1[nrow(ts1) + 1,] <- optimal.thresholds(data.frame(pred1[,c('virus_treename','link1','pred_Model1')]),
                           threshold = 10001,
                           opt.methods = c(10), 
                           req.sens = 0.85,
                           na.rm = TRUE)

# Add method applying 90% required sensitivity
ts1[nrow(ts1) + 1,] <- optimal.thresholds(data.frame(pred1[,c('virus_treename','link1','pred_Model1')]),
                           threshold = 10001,
                           opt.methods = c(10), 
                           req.sens = 0.9,
                           na.rm = TRUE)

# Add method applying 95% required sensitivity
ts1[nrow(ts1) + 1,] <- optimal.thresholds(data.frame(pred1[,c('virus_treename','link1','pred_Model1')]),
                           threshold = 10001,
                           opt.methods = c(10), 
                           req.sens = 0.95,
                           na.rm = TRUE)

# Create function that sums the number of predicted obs (known and unknown) and just unknown obs predicted as links based on calculated THVs for Model 1; use sapply to view counts
cut.1 <- function(x) {sum(pred1$pred_Model1 > x)}  #all predicted links
cut.2 <- function(x) {sum(pred1$pred_Model1[pred1$link1==0] > x)}  #unknown predicted links only
sapply(unlist(ts1[2]), cut.1) #number of predicted links
sapply(unlist(ts1[2]), cut.2) #number of unknown predicted links
sum(pred1$link1)

### CREAT TABLE OF OPTIMAL THRESHOLDING METHODS, VALUES, AND NUMBER OF PREDICTED HOSTS ###

# Save threshold values as new tables
table_ts1 <- ts1

# Correct method labels
table_ts1[5,1] <- "ReqSens 80%"
table_ts1[6,1] <- "ReqSens 85%"
table_ts1[7,1] <- "ReqSens 90%"
table_ts1[8,1] <- "ReqSens 95%"

# Add new columns for sensitivity, specificity, number of predicted hosts, and number of unknown predicted hosts
table_ts1$threshold <- table_ts1$pred_pcr
table_ts1$pred_pcr <- NULL
table_ts1$sensitivity <- NA
table_ts1$specificity <- NA
table_ts1$n_predicted <- NA
table_ts1$n_predicted_unknown <- NA

# For infection model, get sensitivity, specificity, and number of predicted hosts based on various threshold values
for (i in 1:nrow(table_ts1)) {
  table_ts1[i,3] <-  InformationValue::sensitivity(pred1$link1, pred1$pred_Model1, threshold = table_ts1[i,2])
  table_ts1[i,4] <-  InformationValue::specificity(pred1$link1, pred1$pred_Model1, threshold = table_ts1[i,2])
  table_ts1[i,5] <- cut.1(table_ts1[i,2])
  table_ts1[i,6] <- cut.2(table_ts1[i,2])
}

# Save table of the effects of threshold moving
write.csv(table_ts1, file='Output/table_thresholdmoving_linkmodel1.csv')

### APPLY THRESHOLDS TO PREDICTIONS ###

# Extract selected optimum threshold values from ts.1
ts1_rs0.8 <- as.data.frame(ts1[5,])
ts1_rs0.85 <- as.data.frame(ts1[6,])
ts1_rs0.9 <- as.data.frame(ts1[7,])
ts1_rs0.95 <- as.data.frame(ts1[8,])
ts1_mss3 <- as.data.frame(ts1[2,])

# Extract lists of known and unknown predicted hosts applying different thresholds
  pred1$virus_treename=paste0(pred1$virus, "%",pred1$treename)
  
# Threshold the results to binary outputs
  pred1 %>%
    mutate(bin_rs0.8 = ifelse(pred_Model1 > ts1_rs0.8$pred_Model1, 1, 0),
           bin_rs0.85 = ifelse(pred_Model1 > ts1_rs0.85$pred_Model1, 1, 0),
           bin_rs0.9 = ifelse(pred_Model1 > ts1_rs0.9$pred_Model1, 1, 0),
           bin_mss3 = ifelse(pred_Model1 > ts1_mss3$pred_Model1,1,0)) -> pred1
  
# Pull out the relevant lists 
pred1 %>% filter(link1==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> known
pred1 %>% filter(bin_rs0.8==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_rs0.8
pred1 %>% filter(bin_rs0.85==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_rs0.85
pred1 %>% filter(bin_rs0.9==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_rs0.9
pred1 %>% filter(bin_mss3==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_mss3

# Sort and create table of known and unknown hosts (hosts that do not overlap)
pred_kn <- as.data.frame(sort(known))
pred_unk_rs0.8 <- as.data.frame(sort(pred_rs0.8[!(pred_rs0.8 %in% known)])) #n=421
pred_unk_rs0.85 <- as.data.frame(sort(pred_rs0.8[!(pred_rs0.85 %in% known)])) #n=421
pred_unk_rs0.9 <- as.data.frame(sort(pred_rs0.9[!(pred_rs0.9 %in% known)])) #n=2174
pred_unk_mss3 <- as.data.frame(sort(pred_mss3[!(pred_mss3 %in% known)])) #n=1309

  # How many predicted hosts are undiscovered by Model 1?
  nrow(pred_unk_rs0.8) 
  nrow(pred_unk_rs0.85)
  nrow(pred_unk_rs0.9) 
  nrow(pred_unk_mss3) 

# Rename variables
colnames(pred_kn) <- c("V1")
colnames(pred_unk_rs0.8) <- c("V1")
colnames(pred_unk_rs0.85) <- c("V1")
colnames(pred_unk_rs0.9) <- c("V1")
colnames(pred_unk_mss3) <- c("V1")

# Create list of dataframes/tables
list_df <- list(pred_kn, pred_unk_rs0.8, pred_unk_rs0.85, pred_unk_rs0.9, pred_unk_mss3)

# Extract virus as a separate column
list_df <- lapply(list_df, function(x) {x$virus <- sapply(strsplit(x$V1,'%'),function(x) paste(x[1],sep=' ')); x})

# Extract genus as a separate column
list_df <- lapply(list_df, function(x) {x$genus <- sapply(strsplit(x$V1,'%'),function(x) paste(x[2],sep=' ')); x})

# Clean up
list_df <- lapply(list_df, function(x) {x$V1=NULL; x})

# Incorporate taxonomic family & order for each model
taxa <- apreds2[,c("genus","fam","ord")] 
taxa <- unique(taxa)
list_df <- lapply(list_df, function(x) {x <- merge(x, taxa, by = "genus", all=FALSE); x})

# Sort by virus, order, family, and genus
list_df <- lapply(list_df, function(x) {x <- x[order(x$virus, x$ord, x$fam, x$genus),]; x})

# Reorder columns
list_df <- lapply(list_df, function(x) {x <- x[,c("virus","ord","fam","genus")]; x})

# Reformat to proper
list_df <- lapply(list_df, function(x) {x$fam <- str_to_title(x$fam); x})
list_df <- lapply(list_df, function(x) {x$ord <- str_to_title(x$ord); x})

# Unlist
pred_kn <- as.data.frame(list_df[[1]])
pred_unk_rs0.8 <- as.data.frame(list_df[[2]])
pred_unk_rs0.85 <- as.data.frame(list_df[[3]])
pred_unk_rs0.9 <- as.data.frame(list_df[[4]])
pred_unk_mss3 <- as.data.frame(list_df[[5]])

# Save for known hosts and unknown hosts where req.sens=0.8, req.sens=0.85, req.sens=0.9, and opt.methods=3 (MaxSensSpec)
pred_model1 <- list('known'=pred_kn, 
                    'unknown_rs0.8'=pred_unk_rs0.8, 
                    'unknown_rs0.85'=pred_unk_rs0.85, 
                    'unknown_rs0.9'=pred_unk_rs0.9, 
                    'unknown_mss3'=pred_unk_mss3)
write.xlsx(pred_model1, file='Output/table_LinkPredictionModel1_PredictedLinks.xlsx')

# Let's analyze the ratio of unknown predicted hosts to known hosts
list_virus <- list_df
list_virus <- lapply(list_virus, function(x) {x$link <- 1; x})
list_virus <- lapply(list_virus, function(x) {x <- aggregate(link ~ virus, data=x, FUN=sum); x})
known <- list_virus[[1]]$link
list_virus <- lapply(list_virus, function(x) {x <- cbind(x, known); x})
list_virus <- lapply(list_virus, function(x) {x$sum <- x$link+x$known; x})
list_virus <- lapply(list_virus, function(x) {x$ratio_sum_to_known <- x$sum/x$known; x})
list_virus <- lapply(list_virus, function(x) {x$opv_ratio <- sum(x$sum)/sum(x$known); x})

virus_ratio_rs0.8 <- as.data.frame(list_virus[[2]])
virus_ratio_rs0.85 <- as.data.frame(list_virus[[3]])
virus_ratio_rs0.9 <- as.data.frame(list_virus[[4]])
virus_ratio_mss0.3 <- as.data.frame(list_virus[[5]])

# Save as excel sheets
library(openxlsx)
virus_ratio_model1 <- list('rs0.8'=virus_ratio_rs0.8, 
                           'rs0.85'=virus_ratio_rs0.85,
                           'rs0.9'=virus_ratio_rs0.9, 
                           'mss0.3' = virus_ratio_mss0.3)
write.xlsx(virus_ratio_model1, file = 'Output/table_LinkPredictionModel1_virusratio.xlsx')

###########################################################################
### Extract Binary Predictions for Model 2 ###
###########################################################################

### CALCULATE THRESHOLD VALUES ###

# Load file
pred2 <- read.csv("Output/table_LinkPredictionModel2_predictions.csv")
pred2$virus_treename=paste0(pred2$virus, "%",pred2$treename)

# Remove NA vaccinia values
pred2 <- pred2[which(!is.na(pred2$link2)),]

# Drop out 'feline poxvirus ita2_bc'
pred2 <- pred2[!(pred2$virus=="feline poxvirus ita2_bc"),]

# Create table of optimal threshold values for 5 different methods
ts2 <- optimal.thresholds(data.frame(pred2[,c('virus_treename','link2','pred_Model2')]),
                           threshold = 10001,
                           opt.methods = c(2,3,4,5,10),
                           req.sens = 0.90,
                           na.rm = TRUE)

# Add method applying 85% required sensitivity
ts2[nrow(ts2) + 1,] <- optimal.thresholds(data.frame(pred2[,c('virus_treename','link2','pred_Model2')]),
                           threshold = 10001,
                           opt.methods = c(10), 
                           req.sens = 0.85,
                           na.rm = TRUE)

# Add method applying 90% required sensitivity
ts2[nrow(ts2) + 1,] <- optimal.thresholds(data.frame(pred2[,c('virus_treename','link2','pred_Model2')]),
                           threshold = 10001,
                           opt.methods = c(10), 
                           req.sens = 0.9,
                           na.rm = TRUE)

# Add method applying 95% required sensitivity
ts2[nrow(ts2) + 1,] <- optimal.thresholds(data.frame(pred2[,c('virus_treename','link2','pred_Model2')]),
                           threshold = 10001,
                           opt.methods = c(10), 
                           req.sens = 0.95,
                           na.rm = TRUE)

# Create function that sums the number of unknown obs predicted as links based on calculated THVs for Model 2
cut.2 <- function(x) {sum(pred2$pred_Model2[pred2$link2==0] > x)}

# Apply cut function using THVs from ts.2 and from prior calculated THVs for Model 2 to view number of number of obs with previously undetected links having predicted probabilities greater than the optimum threshold value
sapply(unlist(ts2[2]), cut.2)

# save threshold values 
write.csv(ts2, file='Output/table_thresholdvalues_model2.csv')

### APPLY THRESHOLDS TO PREDICTIONS ###

# Extract selected optimum threshold values from ts.2
ts2_rs0.8 <- as.data.frame(ts2[5,])
ts2_rs0.85 <- as.data.frame(ts2[6,])
ts2_rs0.9 <- as.data.frame(ts2[7,])
ts2_rs0.95 <- as.data.frame(ts2)
ts2_ses2 <- as.data.frame(ts2[1,])
ts2_mss3 <- as.data.frame(ts2[2,])

# Extract lists of known and unknown predicted hosts applying different thresholds
pred2$virus_treename=paste0(pred2$virus, "%",pred2$treename)
  
  # Threshold the results to binary outputs
  pred2 %>%
    mutate(bin_rs0.8 = ifelse(pred_Model2 > ts2_rs0.8$pred_Model2, 1, 0),
           bin_rs0.85 = ifelse(pred_Model2 > ts2_rs0.85$pred_Model2, 1, 0),
           bin_rs0.9 = ifelse(pred_Model2 > ts2_rs0.9$pred_Model2, 1, 0),
           bin_mss3 = ifelse(pred_Model2 > ts2_mss3$pred_Model2,1,0)) -> pred2

# Pull out the relevant lists 
pred2 %>% filter(link2==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> known
pred2 %>% filter(bin_rs0.8==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_rs0.8
pred2 %>% filter(bin_rs0.85==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_rs0.85
pred2 %>% filter(bin_rs0.9==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_rs0.9
pred2 %>% filter(bin_mss3==1) %>% dplyr::pull(virus_treename) %>% gsub("_"," ",.) -> pred_mss3

# Sort and create table of known and unknown hosts (hosts that do not overlap)
pred_kn <- as.data.frame(sort(known))
pred_unk_rs0.8 <- as.data.frame(sort(pred_rs0.8[!(pred_rs0.8 %in% known)])) #n=421
pred_unk_rs0.85 <- as.data.frame(sort(pred_rs0.85[!(pred_rs0.8 %in% known)])) #n=421
pred_unk_rs0.9 <- as.data.frame(sort(pred_rs0.9[!(pred_rs0.9 %in% known)])) #n=2174
pred_unk_mss3 <- as.data.frame(sort(pred_mss3[!(pred_mss3 %in% known)])) #n=1309

  # How many predicted hosts are undiscovered by Model 2?
  nrow(pred_unk_rs0.8) 
  nrow(pred_unk_rs0.85)
  nrow(pred_unk_rs0.9) 
  nrow(pred_unk_mss3) 

# Rename variables
colnames(pred_kn) <- c("V1")
colnames(pred_unk_rs0.8) <- c("V1")
colnames(pred_unk_rs0.85) <- c("V1")
colnames(pred_unk_rs0.9) <- c("V1")
colnames(pred_unk_mss3) <- c("V1")

# Create list of dataframes/tables
list_df <- list(pred_kn, pred_unk_rs0.8, pred_unk_rs0.85, pred_unk_rs0.9, pred_unk_mss3)

# Extract virus as a separate column
list_df <- lapply(list_df, function(x) {x$virus <- sapply(strsplit(x$V1,'%'),function(x) paste(x[1],sep=' ')); x})

# Extract genus as a separate column
list_df <- lapply(list_df, function(x) {x$genus <- sapply(strsplit(x$V1,'%'),function(x) paste(x[2],sep=' ')); x})

# Clean up
list_df <- lapply(list_df, function(x) {x$V1=NULL; x})

# Incorporate taxonomic family & order for each model
taxa <- apreds2[,c("genus","fam","ord")] 
taxa <- unique(taxa)
list_df <- lapply(list_df, function(x) {x <- merge(x, taxa, by = "genus", all=FALSE); x})

# Sort by virus, order, family, and genus
list_df <- lapply(list_df, function(x) {x <- x[order(x$virus, x$ord, x$fam, x$genus),]; x})

# Reorder columns
list_df <- lapply(list_df, function(x) {x <- x[,c("virus","ord","fam","genus")]; x})

# Reformat to proper
list_df <- lapply(list_df, function(x) {x$fam <- str_to_title(x$fam); x})
list_df <- lapply(list_df, function(x) {x$ord <- str_to_title(x$ord); x})

# Unlist
pred_kn <- as.data.frame(list_df[[1]])
pred_unk_rs0.8 <- as.data.frame(list_df[[2]])
pred_unk_rs0.85 <- as.data.frame(list_df[[3]])
pred_unk_rs0.9 <- as.data.frame(list_df[[4]])
pred_unk_mss3 <- as.data.frame(list_df[[5]])

# Save for known hosts and unknown hosts where req.sens=0.8, req.sens=0.85, req.sens=0.9, and opt.methods=3 (MaxSensSpec)
pred_model2 <- list('known'=pred_kn, 
                    'unknown_rs0.8'=pred_unk_rs0.8, 
                    'unknown_rs0.85'=pred_unk_rs0.85, 
                    'unknown_rs0.9'=pred_unk_rs0.9, 
                    'unknown_mss3'=pred_unk_mss3)
write.xlsx(pred_model2, file='Output/table_LinkPredictionModel2_PredictedLinks.xlsx')

# Let's analyze the ratio of unknown predicted hosts to known hosts
list_virus <- list_df
list_virus <- lapply(list_virus, function(x) {x$link <- 1; x})
list_virus <- lapply(list_virus, function(x) {x <- aggregate(link ~ virus, data=x, FUN=sum); x})
known <- list_virus[[1]]$link
list_virus <- lapply(list_virus, function(x) {x <- cbind(x, known); x})
list_virus <- lapply(list_virus, function(x) {x$sum <- x$link+x$known; x})
list_virus <- lapply(list_virus, function(x) {x$ratio_sum_to_known <- x$sum/x$known; x})
list_virus <- lapply(list_virus, function(x) {x$opv_ratio <- sum(x$sum)/sum(x$known); x})

virus_ratio_rs0.8 <- as.data.frame(list_virus[[2]])
virus_ratio_rs0.85 <- as.data.frame(list_virus[[3]])
virus_ratio_rs0.9 <- as.data.frame(list_virus[[4]])
virus_ratio_mss0.3 <- as.data.frame(list_virus[[5]])

# Save as excel sheets
virus_ratio_model2 <- list('rs0.8' = virus_ratio_rs0.8,
                           'rs0.85' = virus_ratio_rs0.85,
                           'rs0.9' = virus_ratio_rs0.9, 
                           'mss0.3' = virus_ratio_mss0.3)
write.xlsx(virus_ratio_model2, file = 'Output/table_LinkPredictionModel2_virusratio.xlsx')

```

### *Explore model correlation and phylogenetic signal*

```{r pred_phylo}

# Test correlation between the predicted probabilities of the two models
cor(apreds2$pred_Model1,apreds2$pred_Model2,method='spearman') #computes Spearman correlation coefficient
cor.test(apreds2$pred_Model1,apreds2$pred_Model2,method='spearman') #tests for correlation b/w paired samples based on Spearman corr test
## The predicted probabilities of the BRT models including vs. excluding vaccinia virus links (Model 1 vs. Model 2) were significantly correlated.

#Load phylogeny
load("Output/LinkPredictionModel_CleanData.RData")
mtree=hostTree

# Label observations in apreds2 that are non-existent in mtree
apreds2$tree=ifelse(apreds2$treename%in%setdiff(apreds2$treename,mtree$tip.label),'cut','keep')
table(apreds2$tree)    
## keep: 945

# Trim and match
bdata=subset(apreds2,tree=='keep')

#Save new vars
bdata$label=bdata$treename
bdata$Species=bdata$treename

#Drop 'feline poxvirus ita2_bc': this species has a single known link to the genus 'homo' and can be reclassified as CPXV; however, CPXV already has a known link to 'homo', so we drop it instead
bdata <- bdata[!(bdata$virus=="feline poxvirus ita2_bc"),]

#Generate variable of whether a link was predicted based on threshold value
bdata$link1_rs0.8 <- ifelse(bdata$pred_Model1 > ts1_rs0.8$pred_Model1, 1, 0)
bdata$link1_rs0.85 <- ifelse(bdata$pred_Model1 > ts1_rs0.85$pred_Model1, 1, 0)
bdata$link1_rs0.9 <- ifelse(bdata$pred_Model1 > ts1_rs0.9$pred_Model1, 1, 0)
bdata$link1_mss3 <- ifelse(bdata$pred_Model1 > ts1_mss3$pred_Model1, 1, 0)

#Aggregate at the host genera level across virus species; assume the mean b/c pgls() takes only one value per tip; aggregate separately for Model 1 and 2 predictions due to NA value for vaccinia virus in Model 2
bdata_mean_model1 <- aggregate(pred_Model1 ~ treename + ord + fam + genus + label + Species, data=bdata, mean)
bdata_mean_model2 <- aggregate(pred_Model2 ~ treename + ord + fam + genus + label + Species, data=bdata, mean)

# For visualizing binary classification of links on a phylogenetic tree (where only one tip value is allowed), we regroup as 'unclassified orthopoxvirus' the following virus species:
  # 'cetacean poxvirus 1'
  # 'cetacean poxvirus 2'
  # 'orthopoxvirus gcp2010'
  # 'orthopoxvirus gcp2013'
  # 'orthopoxvirus sp.'
  # 'orthopoxvirus tena dona'
  # 'steller sea lion poxvirus'

# Combine all rows of data for unclassified virus species into a single dataset
bdata_unclassified <- bdata[bdata$virus=="cetacean poxvirus 1",]
bdata_unclassified <- rbind(bdata_unclassified, bdata[bdata$virus=="cetacean poxvirus 2",])
bdata_unclassified <- rbind(bdata_unclassified, bdata[bdata$virus=="orthopoxvirus gcp2010",])
bdata_unclassified <- rbind(bdata_unclassified, bdata[bdata$virus=="orthopoxvirus gcp2013",])
bdata_unclassified <- rbind(bdata_unclassified, bdata[bdata$virus=="orthopoxvirus sp.",])
bdata_unclassified <- rbind(bdata_unclassified, bdata[bdata$virus=="orthopoxvirus tena dona",])
bdata_unclassified <- rbind(bdata_unclassified, bdata[bdata$virus=="steller sea lion poxvirus",])

# Aggregate unclassified virus species at host genera level and take max value of link
bdata_unclassified <- aggregate(cbind(link1,link2,link1_rs0.8,link1_rs0.85,link1_rs0.9,link1_mss3) ~ treename + ord + fam + genus + label + Species, data=bdata, max)

# Add virus column for "unclassified orthopoxvirus"
bdata_unclassified$virus <- "unclassified orthopoxvirus"

# Create new df bdata_sum from bdata to which we will append bdata_unclassified: match column names to those of bdata_unclassified, and drop virus species that were regrouped in unclassified
bdata_sum <- subset(bdata, select=c(colnames(bdata_unclassified)))
bdata_sum <- bdata_sum[!(bdata_sum$virus=="cetacean poxvirus 1"),]
bdata_sum <- bdata_sum[!(bdata_sum$virus=="cetacean poxvirus 2"),]
bdata_sum <- bdata_sum[!(bdata_sum$virus=="orthopoxvirus gcp2010"),]
bdata_sum <- bdata_sum[!(bdata_sum$virus=="orthopoxvirus gcp2013"),]
bdata_sum <- bdata_sum[!(bdata_sum$virus=="orthopoxvirus sp."),]
bdata_sum <- bdata_sum[!(bdata_sum$virus=="orthopoxvirus tena dona"),]
bdata_sum <- bdata_sum[!(bdata_sum$virus=="steller sea lion poxvirus"),]

# Append to bdata_sum new virus group of unclassified
bdata_sum <- rbind(bdata_sum, bdata_unclassified)

# Aggregate at the host genera level assuming the sum
bdata_sum <- aggregate(cbind(link1,link2,link1_rs0.8,link1_rs0.85,link1_rs0.9,link1_mss3) ~ treename + ord + fam + genus + label + Species, data=bdata_sum, sum)

# Combine bdata_mean and bdata_sum
bdata_agg <- merge(bdata_mean_model1, bdata_mean_model2, by=c("treename", "ord", "fam", "genus", "label", "Species"))
bdata_agg <- merge(bdata_agg, bdata_sum, by=c("treename", "ord", "fam", "genus", "label", "Species"))


### We take the mean of the predictions for visualizing the phylotree later b/c if the mean is >1 that means at least one host-virus link was positive within that host genera
### link1 and link2 represent known hosts; unknown_link1_ and unknown_link2_ represent unknown predicted hosts

# Merge tree data with predictions ensuring consistent structure
cdata=comparative.data(phy=mtree,data=bdata_agg,names.col=treename,vcv=T,na.omit=F,warn.dropped=T)  #vcv=T indicates to include variance covariance array representing phylogeny w/in the comparative dataset

# Fix
cdata$data$tree=NULL

# Measure phylogenetic signal (Pagel's lambda) of model predictions using caper::pgls
Model1_lmod=pgls(pred_Model1~1,data=cdata,lambda="ML")   #pgls fits a linear model while taking into account phylogenetic non-independence between data points
Model2_lmod=pgls(pred_Model2~1,data=cdata,lambda="ML")   #lambda = value for lambda transformation; 'ML' uses maximum likelihood to optimize branch length transformations
###for more info: https://static1.squarespace.com/static/5459da8ae4b042d9849b7a7b/t/57ea64eae58c62718aa34769/1474979059782/Nesin_Winternitz_Practical_1and2.pdf

# Get Pagel's lambda (phylogenetic signal) 
summary(Model1_lmod)
summary(Model2_lmod)


```

### *Identify taxonomic patterns via phylofactorization*
Table: *table_pf_clades.csv*

```{r pred_pf}

# Extract taxonomy
cdata$data$taxonomy=paste(cdata$data$ord,cdata$data$fam,cdata$data$Species,sep='; ') #We refer to genus as "Species" as this is required in later functions

# Set taxonomy
taxonomy=data.frame(cdata$data$taxonomy)
names(taxonomy)="taxonomy"
taxonomy$Species=rownames(cdata$data)
taxonomy=taxonomy[c("Species","taxonomy")]
taxonomy$taxonomy=as.character(taxonomy$taxonomy)

# Holm rejection procedure (counteract the problem of multiple comparisons and controls for family-wise error rate)
HolmProcedure <- function(pf,FWER=0.05){
  
  ## get split variable
  cs=names(coef(pf$models[[1]]))[-1]
  split=ifelse(length(cs)>1,cs[3],cs[1])
  
  ## obtain p values
  if (pf$models[[1]]$family$family%in%c('gaussian',"Gamma","quasipoisson")){
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|t|)'])
  } else {
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|z|)'])
  }
  D <- length(pf$tree$tip.label)
  
  ## this is the line for Holm's sequentially rejective cutoff
  keepers <- pvals<=(FWER/(2*D-3 - 2*(0:(pf$nfactors-1))))
  
  
  if (!all(keepers)){
    nfactors <- min(which(!keepers))-1
  } else {
    nfactors <- pf$nfactors
  }
  return(nfactors)
}

# Get species in a clade
cladeget=function(pf,factor){
  spp=pf$tree$tip.label[pf$groups[[factor]][[1]]]
  return(spp)
}

# Summarize pf object 
pfsum=function(pf){
  
  ## get formula
  chars=as.character(pf$frmla.phylo)[-1]
  
  ## response
  resp=chars[1]
  
  ## fix
  resp=ifelse(resp=='cbind(pos, neg)','prevalence',resp)
  
  ## holm
  hp=HolmProcedure(pf)
  
  ## save model
  model=chars[2]
  
  ## set key
  setkey(pf$Data,'Species')
  
  ## make data
  dat=data.frame(pf$Data)
  
  ## make clade columns in data
  for(i in 1:hp){
    
    dat[,paste0(resp,'_pf',i)]=ifelse(dat$Species%in%cladeget(pf,i),'factor','other')
    
  }
  
  ## make data frame to store taxa name, response, mean, and other
  results=data.frame(matrix(ncol=6, nrow = hp))
  colnames(results)=c('factor','taxa','tips','node',"clade",'other')
  
  ## set taxonomy
  taxonomy=dat[c('Species','taxonomy')]
  taxonomy$taxonomy=as.character(taxonomy$taxonomy)
  
  ## loop
  for(i in 1:hp){
    
    ## get taxa
    tx=pf.taxa(pf,taxonomy,factor=i)$group1
    
    ## get tail
    tx=sapply(strsplit(tx,'; '),function(x) tail(x,1))
    
    ## combine
    tx=paste(tx,collapse=', ')
    
    # save
    results[i,'factor']=i
    results[i,'taxa']=tx
    
    ## get node
    tips=cladeget(pf,i)
    node=ggtree::MRCA(pf$tree,tips)
    results[i,'tips']=length(tips)
    results[i,'node']=ifelse(is.null(node) & length(tips)==1,'species',
                             ifelse(is.null(node) & length(tips)!=1,NA,node))
    
    ## get means
    ms=(tapply(dat[,resp],dat[,paste0(resp,'_pf',i)],mean))
    
    ## add in
    results[i,'clade']=ms['factor']
    results[i,'other']=ms['other']
    
  }
  
  ## return
  return(list(set=dat,results=results))
}

# Fix palette
AlberPalettes <- c("YlGnBu","Reds","BuPu", "PiYG")
AlberColours <- sapply(AlberPalettes, function(a) RColorBrewer::brewer.pal(5, a)[4])
afun=function(x){
  a=AlberColours[1:x]
  return(a)
}

# Make low and high
pcols=afun(2)

# Generalized phylofactorization on Model 1 predictions
set.seed(1)
Model1pred_pf=gpf(Data=cdata$data,tree=cdata$phy,
               frmla.phylo=pred_Model1~phylo,
               family=gaussian,algorithm='phylo',nfactors=20,min.group.size=5)

# Generalized phylofactorization on Model 2 predictions
set.seed(1)
Model2pred_pf=gpf(Data=cdata$data,tree=cdata$phy,
                frmla.phylo=pred_Model2~phylo,
                family=gaussian,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize results of phylofactorization
Model1pred_pf_results=pfsum(Model1pred_pf)$results
Model2pred_pf_results=pfsum(Model2pred_pf)$results

# Add model variable
Model1pred_pf_results$model="Model 1 (Full)"
Model2pred_pf_results$model="Model 2 (Partial)"

# Combine results of both models
predpfs=rbind.data.frame(Model1pred_pf_results,Model2pred_pf_results)

# Round probabilities to the 2nd decimal place
predpfs$clade=round(predpfs$clade,2)
predpfs$other=round(predpfs$other,2)

# Save to output folder
write.csv(predpfs,"Output/table_pf_clades.csv")

```

### *Plot predictions on phylogenetic tree*
Figures: *tree_pp_model1.png*

```{r pred_tree1}

#load libraries
library(treeio)
library(ggtree)
library(plotrix)
library(viridis) #library for color palette

# Combine tree and data
dtree=treeio::full_join(as.treedata(cdata$phy),cdata$data,by="label")

# Plot base tree
pbase=ggtree(dtree,layout="fan",branch.length="none",size=0.25)

# Get tree data
tdata=pbase$data

# Get tips only
tdata=tdata[which(tdata$isTip==T),]

# Set x max
xmax=max(tdata$x)+10

### VERSION 1 ###
# For each model, we plot the predicted probabilities of mammal genera as geom segments corresponding to the tips of a circular mammal tree; colored segments correspond to predicted links

# View the distribution of predicted probabilities 
hist(cdata$data$pred_Model1)
summary(cdata$data$pred_Model1)
 
# Cap outliers at 0.15, 0.1, and 95% percentile
cdata$data$cap0.15_pred_Model1 = ifelse(cdata$data$pred_Model1 > 0.15, 0.15, cdata$data$pred_Model1)
cdata$data$cap0.1_pred_Model1 = ifelse(cdata$data$pred_Model1 > 0.1, 0.1, cdata$data$pred_Model1)
cdata$data$quant0.95_pred_Model1 = ifelse(cdata$data$pred_Model1 > quantile(cdata$data$pred_Model1,0.95), quantile(cdata$data$pred_Model1,0.95),cdata$data$pred_Model1)

# Make data frame for Model 1
samp=data.frame(x=tdata$x,
                y=tdata$y,
                yend=tdata$y,
                # xend_Model1=rescale(cdata$data$pred_Model1,c(max(tdata$x),xmax)),
                xend_Model1=rescale(cdata$data$cap0.15_pred_Model1,c(max(tdata$x),xmax)), #rescale(x, newrange) where x is numeric object and newrange is the new min and max
                # xend_Model1=rescale(cdata$data$quant0.95_pred_Model1,c(max(tdata$x),xmax)),
                # xend_Model1_circle=rescale(cdata$data$circle0.1,c(max(tdata$x),xmax)),
                link1_rs0.8=cdata$data$link1_rs0.8,
                link1_rs0.85=cdata$data$link1_rs0.85,
                link1_rs0.9=cdata$data$link1_rs0.9,
                link1_mss3=cdata$data$link1_mss3,
                factor_link1_rs0.8=as.factor((cdata$data$link1_rs0.8)),
                factor_link1_rs0.85=as.factor((cdata$data$link1_rs0.85)),
                factor_link1_rs0.9=as.factor((cdata$data$link1_rs0.9)),
                factor_link1_mss3=as.factor((cdata$data$link1_mss3)),
                treename=tdata$label)

# For plotting, separate df into predicted host genera and non-predicted host genera for different thresholds
samp_nopred_rs0.8 <- samp[samp$link1_rs0.8==0,]
samp_pred_rs0.8 <- samp[samp$link1_rs0.8>0,]
samp_nopred_rs0.85 <- samp[samp$link1_rs0.85==0,]
samp_pred_rs0.85 <- samp[samp$link1_rs0.85>0,]
samp_nopred_rs0.9 <- samp[samp$link1_rs0.9==0,]
samp_pred_rs0.9 <- samp[samp$link1_rs0.9>0,]
samp_nopred_mss3 <- samp[samp$link1_mss3==0,]
samp_pred_mss3 <- samp[samp$link1_mss3>0,]

# Plot circular tree base and the significant clades identified by phylofactorization on Model 1 results
gg=pbase
for(i in 1:nrow(Model1pred_pf_results)){
  gg=gg+
    geom_hilight(node=Model1pred_pf_results$node[i],
                 alpha=ifelse(Model1pred_pf_results$tips[i]/Ntip(cdata$phy)<0.5,0.5,0.25), #alpha=0.5 is less transparent opacity); 0.25 is more transparent opacity
                 fill="black")
}

# Add predicted probabilities as bars colored based on whether host genera had any predicted links (binary)
p1_rs0.8=gg+
  geom_segment(
    data=samp_nopred_rs0.8,
    mapping=aes(x=x,y=y,xend=xend_Model1,yend=yend,
                alpha=factor_link1_rs0.8),
    # color="gray60",linewidth=0.75)+
    color="tomato2",linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(
    data=samp_pred_rs0.8,
    mapping=aes(x=x,y=y,xend=xend_Model1,yend=yend,
                colour=factor(link1_rs0.8)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1,
                      guide=guide_legend(reverse=TRUE),
                      limits=seq(from=1,to=12),
                      name="Number of predicted links\nwith OPV species") +
 theme(legend.position=c(1.1,.5))

p1_rs0.85=gg+
  geom_segment(
    data=samp_nopred_rs0.85,
    mapping=aes(x=x,y=y,xend=xend_Model1,yend=yend,
                alpha=factor_link1_rs0.85),
    # color="gray60",linewidth=0.75)+
    color="tomato2",linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(data=samp_pred_rs0.85,aes(x=x,y=y,xend=xend_Model1,yend=yend,
                                  colour=factor(link1_rs0.85)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1, 
                      guide=guide_legend(reverse=TRUE), 
                      limits=seq(from=1,to=12),
                      name="Number of predicted links\nwith OPV species") +
 theme(legend.position=c(1.1,.5))

p1_rs0.9=gg+
  geom_segment(
    data=samp_nopred_rs0.9,
    mapping=aes(x=x,y=y,xend=xend_Model1,yend=yend,
                alpha=factor_link1_rs0.9),
    # color="gray60",linewidth=0.75)+
    color="tomato2",linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(data=samp_pred_rs0.9,aes(x=x,y=y,xend=xend_Model1,yend=yend,
                                  colour=factor(link1_rs0.9)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1, 
                      guide=guide_legend(reverse=TRUE), 
                      limits=seq(from=1,to=12),
                      name="Number of predicted links\nwith OPV species") +
 theme(legend.position=c(1.1,.5))

p1_mss3=gg+
  geom_segment(
    data=samp_nopred_mss3,
    mapping=aes(x=x,y=y,xend=xend_Model1,yend=yend,
                alpha=factor_link1_mss3),
    # color="gray60",linewidth=0.75)+
    color="tomato2",linewidth=0.75)+
  scale_alpha_discrete(range=c(1,1),name="No predicted links")+
  geom_segment(data=samp_pred_mss3,aes(x=x,y=y,xend=xend_Model1,yend=yend,
                                  colour=factor(link1_mss3)),linewidth=0.75,)+
  scale_color_viridis(discrete=TRUE,option="D", direction=-1, 
                      guide=guide_legend(reverse=TRUE),
                      limits=seq(from=1,to=12),
                      name="Number of predicted links\nwith OPV species") +
 theme(legend.position=c(1.1,.5))

# Combine figures for different threshold values
tree_pp_model1=ggarrange(p1_rs0.8,p1_rs0.85, p1_rs0.9,p1_mss3,
              labels=c("(a) ReqSens0.8; Th=0.14","(b) ReqSens0.85; Th=0.08","(c) ReqSens0.9; Th=0.05","(d) MaxSensSpec; Th=0.06"),
              label.x=c(-0.25,-0.25,-0.25,-0.25),
              label.y=0.2,
              font.label=list(face="plain",size=13),
              ncol=2,nrow=2,
              common.legend = TRUE, legend="right")

# Visualize and select threshold to apply binary classification
tree_pp_model1

# Let's use ReqSens0.8 and MaxSensSpec to demonstrate the impact of threshold moving on binary classification
tree_pp_model1_select=ggarrange(p1_rs0.8,p1_mss3,
              labels=c("(C) ReqSens0.8; Th=0.14","(D) MaxSensSpec; Th=0.06"),
              label.x=c(0.27,0.27),
              label.y=c(1,1),
              font.label=list(face="plain",size=13),
              ncol=1,nrow=2,
              common.legend = TRUE, legend="left")

# Save tree plot
# png("Output/tree_pp_model1_gray.png",width=12,height=8,units="in",res=300)
png("Output/tree_pp_model1_red.png",width=12,height=8,units="in",res=600)
# pdf("Output/tree_pp_model1_gray.pdf",width=12,height=8)
# pdf("Output/tree_pp_model1_red.pdf",width=12,height=8)
tree_pp_model1_select
dev.off()

# Export tip labels of mammal orders for Steph
tiplabels <- ggtree(dtree,layout="fan",branch.length="none",size=0.25) + geom_tiplab(aes(label = dtree@extraInfo$ord))
png("Output/tiplabels_forSteph(1).png",width=24,height=24,units="in", res=300)
tiplabels
dev.off()

# Export tip labels again for mammal orders for Steph but dropping duplicate labels
temp_tree <- dtree
temp_tree@extraInfo$ord[duplicated(temp_tree@extraInfo$ord)] <- NA 

tiplabels <- ggtree(dtree,layout="fan",branch.length="none",size=0.25) + geom_tiplab(aes(label = temp_tree@extraInfo$ord))
png("Output/tiplabels_forSteph(2).png",width=24,height=24,units="in", res=300)
tiplabels
dev.off()

### INTERMISSION: TRYING TO ADD SCALE/CONCENTRIC CIRCLES ########

# Install package ggtreeExtra
#https://github.com/YuLab-SMU/plotting-tree-with-data-using-ggtreeExtra
BiocManager::install("ggtreeExtra")
library(ggrteeExtra)

# Add concentric circles
#https://yulab-smu.top/treedata-book/chapter10.html
BiocManager::install("phyloseq")
data("GlobalPatterns")

plot <- p1_rs0.8 + 
  geom_segment(data=samp,aes(x=x,y=y,xend=xend_Model1_circle,yend=yend,
                                  colour=factor(link1_rs0.8)),linewidth=0.75,)
gg +
     geom_fruit(
         data=samp,
         geom=geom_segment,
         mapping = aes(
                     y=0.5,
                     x=x,
                     xend=xend_Model1,
                     yend=yend,
                     colour=factor(samp$link1_rs0.8)),
         # axis.params=list(
         #                 axis       = "x",
         #                 text.size  = 1.8,
         #                 hjust      = 1,
         #                 vjust      = 0.5,
         #                 nbreak     = 3,
         #             ),
         grid.params=list()
     ) 

# Sample silhouette image code for the outermost ring
install.packages("ggtreeExtra")
library(ggtreeExtra)
library(ggimage)
phylopicda <- read.csv("https://raw.githubusercontent.com/YuLab-SMU/plotting-tree-with-data-using-ggtreeExtra/master/data/VertebrateGutMicrobiomes/data_phylopic_uid.csv")

p1_rs0.8+geom_nodelab(aes(image=phylopicda), geom="phylopic", alpha=.5, color='steelblue')

fig4 <- fig3 +
      new_scale_colour() +
      geom_fruit(
          data=phylopicda,
          geom=geom_phylopic,
          mapping=aes(y=taxa, image=uid, color=class),
          size=0.035,
          offset=0.16,
          alpha=0.8,
          position=position_identityx()
      ) +
      scale_colour_manual(
          values=c("#b2df8a","#33a02c","#fb9a99",
                   "#EACB47","#6a3d9a"),
          guide="none"
      ) +
      theme(
          legend.background=element_rect(fill=NA),
          legend.title=element_text(size=7),
          legend.text=element_text(size=5),
          legend.spacing.y = unit(0.02, "cm")
      )  

# Annotate tree with Phylopic (deprecated?): https://yulab-smu.top/treedata-book/chapter8.html

### END INTERMISSION ###

```


6. Mapping Host Distribution
============================

### *Load required packages and set system*

```{r map_load}

# Libraries for generating maps
library(classInt)
library(tidyverse)
library(raster)
library(rgdal)  # switches to sf in 2023
library(dismo)
library(XML)
library(maps)
library(sp)
library(dplyr)
library(devtools)
#install_github("hunzikp/velox")
library(velox)
library(fasterize)
library(sf)
library(openxlsx)
library(PresenceAbsence) #for thresholding results

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

### *Explore threshold moving on the mapping of host distribution*
Figures: *map_model1_kn_unrs0.8_unrs0.85_unmss.png*, *map_model1_kn_unrs0.8_unrs0.9_unmss.png*,
*map_model1_kn_unrs0.9.png*

```{r map_threshold}

## Before proceeding, make sure you have downloaded "MAMMALS.shp" to your working directory. This shape file of mammal geographic range can be obtained from IUCN Red List Spatial Database: <https://www.iucnredlist.org/resources/spatial-data-download>. This file (>1GB) is only required for this section of the code ("5. Mapping host distribution").

# Load shape file of mammal geographic range
iucn <- sf::st_read(dsn = "/Users/katietseng/Fernandez Lab Dropbox/Katie Tseng/Mac/Desktop/PoxHost(copy)/data/raw/MAMMALS/MAMMALS.shp", layer='MAMMALS')

# Make a blank raster
r <- disaggregate(getData("worldclim",var="alt",res=2.5)*0,2)

# Create four layers
iucn$treename=sapply(strsplit(iucn$binomial,' '),function(x) paste(x[1],sep=' '))

# Pull out the relevant lists of known hosts and predicted hosts for all OPVs
pred1 %>% filter(link1==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known.1 #n=102
pred1 %>% filter(bin_rs0.8==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred.1_rs0.8 #n=503
pred1 %>% filter(bin_rs0.85==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred.1_rs0.85 #n=503
pred1 %>% filter(bin_rs0.9==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred.1_rs0.9 #n=2266
pred1 %>% filter(bin_mss3==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred.1_mss3 #n=1399

# Pull out the relevant lists of predicted unknown hosts for all OPVs
pred.1_unk_rs0.8 <- pred.1_rs0.8[!(pred.1_rs0.8 %in% known.1)] #n=311
pred.1_unk_rs0.85 <- pred.1_rs0.85[!(pred.1_rs0.85 %in% known.1)] #n=311
pred.1_unk_rs0.9 <- pred.1_rs0.9[!(pred.1_rs0.9 %in% known.1)] #n=1844
pred.1_unk_mss3 <- pred.1_mss3[!(pred.1_mss3 %in% known.1)] #n=1097

###iucn$treename is the genus of the iucn species
iucn.1_kn <- iucn[iucn$treename %in% known.1,] #n=1699
iucn.2_rs0.8 <- iucn[iucn$treename %in% pred.1_unk_rs0.8,] #n=1586
iucn.3_rs0.85 <- iucn[iucn$treename %in% pred.1_unk_rs0.85,] #n=1586
iucn.3_rs0.9 <- iucn[iucn$treename %in% pred.1_unk_rs0.9,] #n=5155 
iucn.4_mss3 <- iucn[iucn$treename %in% pred.1_unk_mss3,] #n=4838

library(fasterize)
map.kn1 <- (fasterize(iucn.1_kn, r, fun="sum"))
map.pr1_rs0.8 <- (fasterize(iucn.2_rs0.8, r, fun="sum"))
map.pr1_rs0.85 <- (fasterize(iucn.3_rs0.85, r, fun="sum"))
map.pr1_rs0.9 <- (fasterize(iucn.3_rs0.9, r, fun="sum"))
map.pr1_mss3 <- (fasterize(iucn.4_mss3, r, fun="sum"))

# Add zeros for the continental area 
fix <- function(x) {sum(x,r,na.rm=TRUE)+r}

map.kn1 <- fix(map.kn1)
map.pr1_rs0.8 <- fix(map.pr1_rs0.8)
map.pr1_rs0.85 <- fix(map.pr1_rs0.85)
map.pr1_rs0.9 <- fix(map.pr1_rs0.9)
map.pr1_mss3 <- fix(map.pr1_mss3)

#Maps 1 includes req.sens 85%
raster::stack(map.kn1, map.pr1_rs0.8, map.pr1_rs0.85, map.pr1_mss3) %>% raster::trim() -> maps1 #alternatively, can use tera package

#Maps 2 includes req.sens 90%
raster::stack(map.kn1, map.pr1_rs0.8, map.pr1_rs0.9, map.pr1_mss3) %>% raster::trim() -> maps2 #alternatively, can use tera package

names(maps1) <- c('KnownModel1', 'PredModel1_ReqSens0.8', 'PredModel1_ReqSens0.85', 'PredModel1_MaxSensSpec')
names(maps2) <- c('KnownModel1', 'PredModel1_Unk_ReqSens0.8', 'PredModel1_Unk_ReqSens0.9', 'PredModel1_Unk_MaxSensSpec')

# Generate the actual visualization
library(rasterVis)
library(RColorBrewer)

mycolors <- colorRampPalette(rev(brewer.pal(10,"Spectral")))(21)
mycolors[1] <- "#C0C0C0"

png("Output/map_model1_kn_unrs0.8_unrs0.85_unmss.png",width=10,height=10,units="in",res=300)
rasterVis::levelplot(maps1,  
                     col.regions = mycolors,
                     #at = seq(0, 15, 1),
                     alpha = 0.5, 
                     scales=list(alternating=FALSE),
                     par.strip.text=list(cex=0),
                     xlab = NULL, ylab = NULL,
                     #labels = labels,
                     maxpixels = 5e6)
dev.off()

png("Output/map_model1_kn_unrs0.8_unrs0.9_unmss.png",width=10,height=10,units="in",res=300)
rasterVis::levelplot(maps2,  
                     col.regions = mycolors,
                     #at = seq(0, 15, 1),
                     alpha = 0.5, 
                     scales=list(alternating=FALSE),
                     par.strip.text=list(cex=0),
                     xlab = NULL, ylab = NULL,
                     #labels = labels,
                     maxpixels = 5e6)
dev.off()

### Selected map using 90% sensitivity threshold

# Final selected map using rs0.9
raster::stack(map.kn1, map.pr1_rs0.9) %>% raster::trim() -> maps_rs0.9
names(maps_rs0.9) <- c('KnownModel1', 'PredModel1_Unk_ReqSens0.9')

# Generate the actual visualization
png("Output/map_model1_kn_unrs0.9.png",width=10,height=10,units="in",res=300)
rasterVis::levelplot(maps_rs0.9,  
                     col.regions = mycolors,
                     #at = seq(0, 15, 1),
                     alpha = 0.5, 
                     scales=list(alternating=FALSE),
                     par.strip.text=list(cex=0),
                     xlab = NULL, ylab = NULL,
                     #labels = labels,
                     maxpixels = 5e6)
dev.off()

```

### *Generate maps of host distribution for manuscript*
Figures: 

```{r map_manuscript}

#Threshold the results
library(PresenceAbsence)

set.seed(12345)

#### Host only model ####

# Load file
pred <- read.csv("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Host Trait Model/Output/table_HostTraitModel_predictions.csv")

# Optimal thresholds for PCR
t.pcr <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
                            threshold = 10001,
                            opt.methods = 10,
                            req.sens = 0.90,
                            na.rm = TRUE)

# Optimal threshold for competence
t.comp <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
                             threshold = 10001,
                             opt.methods = 10,
                             req.sens = 0.90,
                             na.rm = TRUE)

# Threshold the results to binary outputs
pred %>%
  mutate(bin_comp = (pred_comp > t.comp$pred_comp),
         bin_pcr = (pred_pcr > t.pcr$pred_pcr)) -> pred

####Let's get the relevant lists of known and predicted hosts for all OPVs keeping pcr and competence predictions separate 
pred %>% filter(PCR==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known_pcr
pred %>% filter(competence==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known_comp
pred %>% filter(bin_pcr==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_pcr
pred %>% filter(bin_comp==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred_comp

#Pull out the relevant lists of predicted unknown hosts for all OPVs keeping pcr and competence predictions separate
unk_pcr <- pred_pcr[!(pred_pcr %in% known_pcr)] #n=197
unk_comp <- pred_comp[!(pred_comp %in% known_comp)] #n=118

####Let's get the relevant lists of known and predicted hosts for all OPVs combining comp and pcr predictions for manuscript
pred %>% filter(competence==1|PCR==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known #71
pred %>% filter(bin_comp==1|bin_pcr==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred.pcrcomp #n=299
sort(pred.pcrcomp[!(pred.pcrcomp %in% known)]) -> unknown #235

#### Link prediction model ####

#load link prediction file
pred1 <- read.csv("Output/table_LinkPredictionModel1_predictions.csv")
pred1$virus_treename=paste0(pred1$virus, "%",pred1$treename)

#drop out 'feline poxvirus ita2_bc'
pred1 <- pred1[!(pred1$virus=="feline poxvirus ita2_bc"),]

#() Add method applying 90% required sensitivity
ts1_rs0.9 <- optimal.thresholds(data.frame(pred1[,c('virus_treename','link1','pred_Model1')]),
                           threshold = 10001,
                           opt.methods = c(10), 
                           req.sens = 0.9,
                           na.rm = TRUE)

pred1$virus_treename=paste0(pred1$virus, "%",pred1$treename)
  
#(2) Threshold the results to binary outputs
pred1 %>%
  mutate(bin_rs0.9 = ifelse(pred_Model1 > ts1_rs0.9$pred_Model1, 1, 0)) -> pred1
  
#(7) Pull out the relevant lists of known hosts and predicted hosts for all OPVs
pred1 %>% filter(link1==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> known.1 #n=102
pred1 %>% filter(bin_rs0.9==1) %>% dplyr::pull(treename) %>% gsub("_"," ",.) -> pred.1_rs0.9 #n=2266

#() Pull out the relevant lists of predicted unknown hosts for all OPVs
pred.1_unk_rs0.9 <- pred.1_rs0.9[!(pred.1_rs0.9 %in% known.1)] #n=1844

#### CREATE MAP ####

# Load shape file of mammal geographic range
iucn <- sf::st_read(dsn = "/Users/katietseng/Fernandez Lab Dropbox/Katie Tseng/Mac/Desktop/PoxHost(copy)/data/raw/MAMMALS/MAMMALS.shp", layer='MAMMALS')

# Make a blank raster (must be connected to wifi for the disaggregate function)
r <- raster::disaggregate(getData("worldclim",var="alt",res=2.5)*0,2)

# Create four layers
iucn$treename=sapply(strsplit(iucn$binomial,' '),function(x) paste(x[1],sep=' '))

iucn_known <- iucn[iucn$treename %in% known,] #n=1676
iucn_pcrcomp <- iucn[iucn$treename %in% pred.pcrcomp,] #n=1908
iucn_link <- iucn[iucn$treename %in% pred.1_rs0.9,] #n=1699

map_known <- (fasterize(iucn_known, r, fun="sum"))
map_pcrcomp <- (fasterize(iucn_pcrcomp, r, fun="sum"))
map_link <- (fasterize(iucn_link, r, fun="sum"))

# Add zeros for the continental area 
fix <- function(x) {sum(x,r,na.rm=TRUE)+r}

map_known <- fix(map_known)
map_pcrcomp <- fix(map_pcrcomp)
map_link <- fix(map_link)

raster::stack(map_known, map_pcrcomp, map_link) %>% raster::trim() -> maps_hostlink #alternatively, can use tera package

names(maps_hostlink) <- c('Host traits model - known', 'Host traits model - pred', 'Link prediction model - pred')

# Generate the actual visualization
library(rasterVis)
library(RColorBrewer)

mycolors <- colorRampPalette(rev(brewer.pal(10,"Spectral")))(21)
mycolors[1] <- "#C0C0C0"

# png("Output/map_hostlink_rs0.9_manuscript.png",width=10,height=12,units="in",res=300)
pdf("Output/map_hostlink_rs0.9_manuscript.pdf",width=10,height=12)
rasterVis::levelplot(maps_hostlink,  
                     col.regions = mycolors,
                     #at = seq(0, 15, 1),
                     alpha = 0.5, 
                     scales=list(alternating=FALSE),
                     par.strip.text=list(cex=0),
                     xlab = NULL, ylab = NULL,
                     labels = labels,
                     maxpixels = 5e6)
dev.off()

```


7. Feature Importance
=====================

In this chapter, we examine predictions from our BRT model identifying and ranking the importance of model features.

### *Load required packages and set system*

```{r feat_load}

# Libraries for BRT figures
library(tidyr)
library(ggplot2)
library(fastDummies)
library(caper)
library(phylofactor)
library(plotrix) #std.error
library(rstatix) 
library(ggrepel)
library(ggpubr) #ggarrange
library(dplyr)

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

### *Identify and rank relative feature importance*
We compare and contrast the relative feature importance of the predictors in our models includnig and excluding vaccinia virus links (Model 1 and Model 2), determining the mean, variance, and standard error for each model. We then rank features by their relative importance, focusing on the top 10 predictive features. 
Figures: *boxplot_trait_ranking.png*
Tables: *table_ranks_model1*, *table_ranks_model2*

```{r feat_rank}

# Load Model 1 predictions
load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model1/Output/brts_Model1.RData")
brts1=brts
rm(brts)

load("~/Fernandez Lab Dropbox/Katie Tseng/Mac/Downloads/HPC_24Nov2022_Model2/Output/brts_Model2.RData")
brts2=brts
rm(brts)

# What was the relative importance/influence of each feature in Model 1? Get values.
vinf=lapply(brts1,function(x) x$rinf)
vinf1=do.call(rbind,vinf)

# What was the relative importance/influence of each feature in Model 2? Get values.
vinf=lapply(brts2,function(x) x$rinf)
vinf2=do.call(rbind,vinf)

# What was the mean, standard error, and variance of feature relative influence in Model 1?
vdata1=data.frame(aggregate(rel.inf~var,data=vinf1,mean),
                 aggregate(rel.inf~var,data=vinf1,std.error)["rel.inf"],
                 aggregate(rel.inf~var,data=vinf1,var)["rel.inf"])
names(vdata1)=c("var","rel.inf","rse","rvar")
vdata1=vdata1[order(vdata1$rel.inf,decreasing=T),]

# What was the mean, standard error, and variance of feature relative influence in Model 2?
vdata2=data.frame(aggregate(rel.inf~var,data=vinf2,mean),
                      aggregate(rel.inf~var,data=vinf2,std.error)["rel.inf"],
                      aggregate(rel.inf~var,data=vinf2,var)["rel.inf"])
names(vdata2)=c("var","rel.inf","rse","rvar")
vdata2=vdata2[order(vdata2$rel.inf,decreasing=T),]

# How does the average variance compare between Model 1 and 2?
paste0("mean Relative Importance for Model 1: ", mean(vdata1$rvar))
paste0("mean Relative Importance for Model 2: ", mean(vdata2$rvar))

# How does the variance of relative influence compare between Model 1 and 2?
paste0("variance in mean Relative Importance for Model 1: ", var(vdata1$rel.inf))
paste0("variance in mean Relative Importance for Model 2: ", var(vdata2$rel.inf))

# Can we rank features by their relative influence?
vdata1$rank1=1:nrow(vdata1)
vdata2$rank2=1:nrow(vdata2)

# What is their relative influence/importance as a proportion?
vdata1$imp1=vdata1$rel.inf/100
vdata2$imp2=vdata2$rel.inf/100

# Combine the rankings
ranks=merge(vdata1[c("var","rank1","imp1")],
            vdata2[c("var","rank2","imp2")],
            by="var")

# Create a table of ranked features and their relative importance for Model 1
table_ranks=ranks
table_ranks$feature=table_ranks$var
table_ranks_model1=table_ranks[c("feature","imp1","rank1")]
table_ranks_model1=table_ranks_model1[order(table_ranks_model1$rank1),]
write.csv(table_ranks_model1,"Output/table_ranks_model1.csv")

# Create a table of ranked features and their relative importance for Model 2
table_ranks_model2=table_ranks[c("feature","imp2","rank2")]
table_ranks_model2=table_ranks_model2[order(table_ranks_model2$rank2),]
write.csv(table_ranks_model2,"Output/table_ranks_model2.csv")

# Create a list of the top 10 variables
keep1 <- ranks$var[which(ranks$rank1<=10)]
keep2 <- ranks$var[which(ranks$rank2<=10)]

# Get the relative importance values for the top 10 features of Model 1
vinf1 <- vinf1[which(vinf1$var%in%keep1),]
vinf1$rel.inf <- vinf1$rel.inf/100

# Get the relative importance values for the top 10 features of Model 2
vinf2 <- vinf2[which(vinf2$var%in%keep2),]
vinf2$rel.inf <- vinf2$rel.inf/100

# Relabel 'cites' for boxplots
vinf1$var <- ifelse(vinf1$var=="cites", "Citations", vinf1$var)
vinf2$var <- ifelse(vinf2$var=="cites", "Citations", vinf2$var)

# Relabel 'island_dwelling' for boxplots
vinf1$var <- ifelse(vinf1$var=="island_dwelling", "Island dwelling", vinf1$var)
vinf2$var <- ifelse(vinf2$var=="island_dwelling", "Island dwelling", vinf2$var)

# Relabel 'dispersal_km' for boxplots
vinf1$var <- ifelse(vinf1$var=="dispersal_km", "Dispersal (km)", vinf1$var)
vinf2$var <- ifelse(vinf2$var=="dispersal_km", "Dispersal (km)", vinf2$var)

# Create grouping variable for Model 1
vinf1$type <- NA
vinf1$type <- ifelse(vinf1$var=="Citations", "Sampling effort", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="Island dwelling", "Life history", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="Dispersal (km)", "Life history", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="PC4", "Viral genomic", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="PC1", "Viral genomic", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="PC3", "Viral genomic", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="PC9", "Viral genomic", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="PC10", "Viral genomic", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="PC7", "Viral genomic", vinf1$type)
vinf1$type <- ifelse(vinf1$var=="PC8", "Viral genomic", vinf1$type)

# Create grouping variable for Model 2
vinf2$type <- NA
vinf2$type <- ifelse(vinf2$var=="Citations", "Sampling effort", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="Island dwelling", "Life history", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="Dispersal (km)", "Life history", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="PC4", "Viral genomic", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="PC1", "Viral genomic", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="PC3", "Viral genomic", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="PC9", "Viral genomic", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="PC10", "Viral genomic", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="PC7", "Viral genomic", vinf2$type)
vinf2$type <- ifelse(vinf2$var=="PC2", "Viral genomic", vinf2$type)

# Boxplot relative feature importance for Model 1
boxplot_trait_Model1 <- ggplot(vinf1) + ggtitle("(C) Link prediction model") +
        geom_boxplot(aes(x=rel.inf, y=reorder(var,rel.inf), group=var, fill=type), width=0.7, alpha=0.85, linewidth=0.2) +
        theme_bw() +
        labs(x="Relative influence",
             y="Features") + 
        theme(axis.text.y=element_text(size=14),
              axis.text.x=element_text(size=14),
              axis.title.x=element_text(size=20, margin=margin(t=10,r=0,b=0,l=0)),
              axis.title.y=element_text(size=20, margin=margin(t=0,r=10,b=0,l=0)),
              strip.text=element_text(size=20)) +
        scale_fill_manual(values=c("#482677FF","#238A8DFF","#FDE725FF")) +
        scale_y_discrete(labels = function(x) str_wrap(x, width = 16))

#For viridis palette c("#482677FF","#238A8DFF", "#55C667FF","#FDE725FF"): https://www.thinkingondata.com/something-about-viridis-library/

# Boxplot relative feature importance for Model 2
boxplot_trait_Model2 <- ggplot(vinf2) + ggtitle("(D) Link prediction model (no vaccinia virus)") +
        geom_boxplot(aes(x=rel.inf, y=reorder(var,rel.inf), group=var, fill=type), width=0.7, alpha=0.85, linewidth=0.2) +
        theme_bw() +
        labs(x="Relative influence",
             y="Features") + 
        theme(axis.text.y=element_text(size=14),
              axis.text.x=element_text(size=14),
              axis.title.x=element_text(size=20, margin=margin(t=10,r=0,b=0,l=0)),
              axis.title.y=element_text(size=20, margin=margin(t=0,r=10,b=0,l=0)),
              strip.text=element_text(size=20)) +
        scale_fill_manual(values=c("#482677FF","#238A8DFF","#FDE725FF")) +
        scale_y_discrete(labels = function(x) str_wrap(x, width = 16)) 

# Combine boxplots of relative feature importance
png("Output/boxplot_trait_ranking.png",width=12,height=10,units="in",res=600)
ggarrange(boxplot_trait_Model1,boxplot_trait_Model2,ncol=2,nrow=1,
          font.label=list(face="plain",size=12))
dev.off()

#Note: Island dwelling = 20% or more of the breeding range occurs on an island
# https://stats.stackexchange.com/questions/422458/gbm-how-to-interpret-relative-variable-influence

rm(vinf, vinf1, vinf2, keep1, keep2, vdata1, vdata2, boxplot_trait_Model1, boxplot_trait_Model2, table_ranks, table_ranks_model1, table_ranks_model2)

```

### *Identify consistently important and unimportant host traits*
Figure: *scatterplot_trait_ranking.png*

```{r feat_consistent}

# Were the rankings of relative feature importance significantly correlated?
cor.test(ranks$rank1,ranks$rank2,method="spearman")

# What if we remove traits with zero/no relative importance and rerank?
ranks2=ranks[-which(ranks$imp1==0 & ranks$imp2==0),]
ranks2=ranks2[order(ranks2$imp1,decreasing=T),]
ranks2$rank1=1:nrow(ranks2)
ranks2=ranks2[order(ranks2$imp2,decreasing=T),]
ranks2$rank2=1:nrow(ranks2)

# Are rankings still correlated after removing traits with zero/no relative importance?
cor.test(ranks2$rank1,ranks2$rank2,method="spearman")

# Can we identify features with high residuals?
ranks2$resid=abs(resid(lm(rank2~rank1,data=ranks2)))  # extract residuals from linear regression as absolute values

# Plot residuals
plot(ranks2$rank1,ranks2$resid,
     ylab="Residuals",xlab="Traits by ranking for Model 1", 
     main="Model 1 with variables with zero/no relative importance removed")

# Were any  residual values greater than 10 or greater than 20? Flag residuals.
#ranks2$select=ifelse(ranks2$resid>10,"yes","no")
ranks2$select=ifelse(ranks2$resid>20,"yes","no")
ranks2[ranks2$resid>20,] # returns 5 values

# Were any features consistenly high or low ranking across both infection and competence models? Flag.
n=7
ranks2$select=ifelse(ranks2$rank2<n & ranks2$rank1<n,"yes",ranks2$select)
ranks2$select=ifelse(ranks2$rank2%in%tail(1:nrow(ranks2),n) & ranks2$rank1%in%tail(1:nrow(ranks2),n),"yes",ranks2$select)

# Flag if high or low ranks
# rnk=c(head(ranks2$comp_rank,n),tail(ranks2$comp_rank,n))
# ranks2$select=ifelse(ranks2$comp_rank%in%rnk,"yes",ranks2$select)

# # Just yes
# rset=ranks2[ranks2$select=="yes",]

# Get the names of consistently high or low ranking features
rset=ranks2
rset$var=ifelse(rset$select=="yes",rset$var,"")

# Plot feature ranking of infection model against competence model and label traits that were consistently important and unimportant
set.seed(1)
png("Output/scatterplot_trait_ranking.png",width=7,height=7,units="in",res=300)
ggplot(ranks2,aes(rank1,rank2))+
  #geom_label(data=rset,aes(label=var),size=2,fill=col,alpha=0.2)+
  geom_text_repel(data=rset,aes(label=var),
                  size=2,
                  force=4,
                  #nudge_y=-2,
                  #nudge_x=1,
                  direction="both",
                  segment.size=0.5,
                  segment.color="grey")+
  geom_point()+
  #scale_y_reverse(limits=c(max(c(ranks$comp_rank,ranks$pcr_rank))+3,0))+
  #scale_x_reverse(limits=c(max(c(ranks$comp_rank,ranks$pcr_rank))+3,0))+
  scale_y_reverse(limits=c(max(c(ranks2$rank2,ranks2$rank1))+4,0))+
  scale_x_reverse(limits=c(max(c(ranks2$rank2,ranks2$rank1))+4,0))+
  #geom_abline(slope=1,linetype=2,size=0.5)+
  theme_bw()+
  labs(x="Feature rank for Model 1 (Full) ",
       y="Feature rank for Model 2 (Partial)")+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12))+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))
dev.off()

# Clean environment

```

### *Determine effect directions of each feature on the predicted outcome*
We determine the effect directions of each feature on link prediction using partial dependence plots. These plots allow us to visualize the relationship between a subset of features and the response variable (OPV positivity) while accounting for the average effect of the other predictors in the model.
Figures: *pdplot_trait_effect.png*

```{r feat_Effect}


# Download library for partial dependence plots
# detach("package:purrr", unload=TRUE)
library(pdp) #partial dependence plots help visualize the relationship b/w a subset of features and the response while accounting for the avg effect of the other predictors in the model
library(gbm)# detach("package:purrr", unload=TRUE)

# Create a function for compiling across BRTs for a given predictor, all else equal
pdp_agg=function(mod,feature){
  
  ## just the plot function
  pdep=plot(mod$mod,feature,
            return.grid=T,
            n.trees=mod$best,
            plot=F,
            continuous.resolution=200,
            type="response")
  
  ## add seed
  pdep$seed=unique(mod$roc$seed)
  
  ## save predictor
  pdep$predictor=pdep[feature][,1]
  
  ## order
  pdep=pdep[order(pdep$predictor),]
  
  ## get rank
  pdep$rank=1:nrow(pdep)
  
  ## save yhat
  pdep$yhat=pdep$y
  
  ## return
  return(pdep)
  
}

# Create a function to plot the PDPs
pdp_plot=function(bmods,feature){
  
  ## pdp_agg
  agg=do.call(rbind,lapply(bmods,function(x) pdp_agg(x,feature)))
  
  ## get class of the feature
  cl=class(data[feature][,1])
  
  ## if else based on type
  if(cl%in%c("numeric","integer")){
    
    ## get element-wise means
    x=with(agg,tapply(predictor,rank,mean))
    y=with(agg,tapply(yhat,rank,mean))
    
    ## save as mean
    pmean=data.frame(predictor=x,yhat=y)
    
    ## get yrange
    yrange=range(agg$yhat,pmean$yhat,na.rm=T)
    
    ## get histogram
    hi=hist(data[feature][,1],breaks=30,plot=F)
    hi=with(hi,data.frame(breaks[1:(length(breaks)-1)],counts))
    names(hi)=c("mids","counts")
    
    ## ggplot it
    ggplot(agg,aes(predictor,yhat,group=seed))+
      
      ## add histogram
      geom_segment(data=hi,inherit.aes=F,
                   aes(x=mids,xend=mids,
                       y=yrange[1],yend=plotrix::rescale(counts,yrange)),
                   size=1,colour="grey",alpha=0.25)+
      
      ## add lines
      geom_line(linewidth=1,alpha=0.25,colour="grey")+
      
      ## add mean
      geom_line(data=pmean,linewidth=2,inherit.aes=F,
                aes(predictor,yhat))+
      
      ## theme
      theme_bw()+
      theme(axis.text=element_text(size=6),
            axis.title=element_text(size=7))+
      theme(axis.title.x=element_text(margin=margin(t=5,r=0,b=0,l=0)))+
      theme(axis.title.y=element_text(margin=margin(t=0,r=5,b=0,l=0)))+
      theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
      labs(x=feature,y="marginal effect")+
      scale_y_continuous(labels=scales::number_format(accuracy=0.01))
    
    ## end numeric
  }else{ ## factor-based plot
    
    ## get element-wise means
    y=with(agg,tapply(yhat,predictor,mean))
    
    ## save as mean
    #pmean=data.frame(predictor=x,yhat=y)
    pmean=data.frame(y)
    names(pmean)="yhat"
    pmean$predictor=rownames(pmean)
    rownames(pmean)=NULL
    
    ## make temp data
    temp=data
    temp$predictor=temp[feature][,1]
    
    ## do nothing
    agg=agg
    pmean=pmean
    temp=temp
    
    ## get yrange
    yrange=range(agg$yhat,pmean$yhat,na.rm=T)
    
    ## fix temp to yrange
    temp$yhat=ifelse(temp$pcr==1,max(yrange),min(yrange))
    
    ## ggplot with rug
    set.seed(1)
    ggplot(agg,aes(predictor,yhat,group=seed))+
      
      ## add individual BRTs
      geom_jitter(size=1,alpha=0.25,colour="grey",width=0.1)+
      
      ## add mean
      geom_point(data=pmean,size=2,inherit.aes=F,shape=15,
                 aes(predictor,yhat))+
      
      ## add rug
      geom_rug(data=temp,inherit.aes=F,
               aes(predictor,yhat),
               sides="b",position="jitter",
               colour="grey",alpha=0.25,
               na.rm=T)+
      
      ## theme
      theme_bw()+
      theme(axis.text=element_text(size=6),
            axis.title=element_text(size=7))+
      theme(axis.title.x=element_text(margin=margin(t=5,r=0,b=0,l=0)))+
      theme(axis.title.y=element_text(margin=margin(t=0,r=5,b=0,l=0)))+
      theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
      labs(x=feature,y="marginal effect")+
      scale_y_continuous(limits=c(yrange[1]-0.01,yrange[2]+0.01),
                         labels=scales::number_format(accuracy=0.01))
    
  }
  
}

# Load cleaned data file
library(fastDummies)
load("Output/LinkPredictionModel_CleanData.RData")
data <- linkdata

# Make binary columns for each taxonomic family in our dataset
dums=dummy_cols(data["fam"])

# Get only unique observations
dums=dums[!duplicated(dums$fam),]

# Ensure all are factor
for(i in 1:ncol(dums)){
  ## column as factor
  dums[,i]=factor(dums[,i])
}

# Merge family variables with poxdata
data=merge(data,dums,by="fam",all.x=T)
rm(dums)

# PDPs for top ranking features of Model 1
ranks2=ranks2[order(ranks2$rank1),]
a1=pdp_plot(brts1,ranks2$var[1]) #118
a2=pdp_plot(brts1,ranks2$var[2])
a3=pdp_plot(brts1,ranks2$var[3])
a4=pdp_plot(brts1,ranks2$var[4])
a5=pdp_plot(brts1,ranks2$var[5])
a6=pdp_plot(brts1,ranks2$var[6])
a7=pdp_plot(brts1,ranks2$var[7])
a8=pdp_plot(brts1,ranks2$var[8])
a9=pdp_plot(brts1,ranks2$var[9])
a10=pdp_plot(brts1,ranks2$var[10])

# PDPs for top ranking features of Model 2
ranks2=ranks2[order(ranks2$rank2),]
b1=pdp_plot(brts2,ranks2$var[1])
b2=pdp_plot(brts2,ranks2$var[2])
b3=pdp_plot(brts2,ranks2$var[3])
b4=pdp_plot(brts2,ranks2$var[4])
b5=pdp_plot(brts2,ranks2$var[5])
b6=pdp_plot(brts2,ranks2$var[6])
b7=pdp_plot(brts2,ranks2$var[7])
b8=pdp_plot(brts2,ranks2$var[8])
b9=pdp_plot(brts2,ranks2$var[9])
b10=pdp_plot(brts2,ranks2$var[10])

# Plot compiled PDPs of the top ranked features for both Model 1 and 2
library(patchwork)
m1_pdp_plots <- a1+a2+a3+a4+a5+a6+a7+a8+a9+a10+plot_layout(nrow=10,ncol=1,byrow=F)
m2_pdp_plots <- b1+b2+b3+b4+b5+b6+b7+b8+b9+b10+plot_layout(nrow=10,ncol=1,byrow=F)
png("Output/pdpplot_trait_effect.png",width=4,height=10,units="in",res=300)
ggarrange(m1_pdp_plots,m2_pdp_plots,ncol=2,nrow=2,widths=c(4,4),heights=c(22,1),
          labels=c("(A) Full Model","(B) Partial Model"),
          label.x=c(0,-0.1), label.y=0.001,
          font.label=list(face="plain",size=12))
dev.off()

# Clean environment
rm(pdp_agg, pdp_plot, a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,
   b1,b2,b3,b4,b5,b6,b7,b8,b9,b10,
   m1_pdp_plots, m2_pdp_plots)

```
