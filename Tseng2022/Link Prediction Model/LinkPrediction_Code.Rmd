---
title: "Orthopoxvirus Link Prediction Model Code"
author: "Katie Tseng, Dan Becker, Colin Carlson, Pilar Fernandez, and Stephanie Seifert"
output:
  pdf_document:
  latex_engine: xelatex
  toc: yes
html_document:
  fig_height: 6
  fig_width: 6
  highlight: tango
  theme: journal
editor_options: 
  chunk_output_type: console
---

# Table of Contents

Introduction
1. Dimension Reduction 
2. Data Preparation
3. Boosted Regression Trees (BRTs)
4. BRT Figures
5. Mapping Host Distributions

# Introduction

The following code reproduces the analyses from <...>, pertaining to the link prediction model. The code is subdivided into five parts: "1. Dimension Reduction", "2. Data Preparation", "3. Boosted Regression Trees", "4. BRT Figures", "5. Mapping Host Distributions".

To reproduce the analyses pertaining to the host prediction model, please see the markdown file HostPrediction_Code.Rmd located in the PoxHost repository on GitHub: https://github.com/viralemergence/PoxHost.

To run the following script, four files are required in your working directory:
(1) Data_raw.RData, the raw data file;
(2) OPVnew_nowwithVirus.xlsx, the excel file of OPV genome annotations
(3) "Output" folder, where all output will be saved - e.g., cleaned datasets, model results, figures, and tables; 
(4) MAMMALS.shp, the shape file of mammal geographical range obtained from IUCN Red List Spatial Database <https://www.iucnredlist.org/resources/spatial-data-download>. This file (>1GB) is only required in the last section of the code ("5. Mapping host distribution") and should be downloaded to your working directory before proceeding with part five.

### Before proceeding, we recommend setting knit options and your working directory

```{r, echo=F, message=F}
knitr::opts_chunk$set(eval=F)

# Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

# Dimension Reduction

In this section, we draw from our dataset of annotated OPV genomes (n=197 unique sequences; see genome annotation pipeline in methods section for more information), which compose our known host-OPV associations for incorporation in the link prediction model. Each sequence is classified by its source or virus species and its host, as well as the presence (1) or absence (0) of a suite of OPV accessory genes. Because our data consists of over 981 OPV accessory genes, the goal of this section is to reduce the number of viral predictors for incorporation in the link prediction model, while maintaining maximal variance. Using principal components analysis (PCA), a method of dimension reduction, we distill the variables down to their most important features. We also explore which sequences have the most similar values (aka, how do they group?) in the principal components using k-means clustering. Because we are analyzing presence/absence data (binary variables), we use multiple correspondence analysis (MCA) to further validate our results. MCA is a dimension reduction method similar to PCA but is used to analyze datasets with multiple categorical variables. 

### Load packages, clean environment, and set working directory

```{r prep_load, message=FALSE, warning=FALSE}

# Libraries for preparing data for analysis
library(ape)
library(dplyr)
library(nlme)
library(tidyverse)
library(vroom) 
library(readxl)
library(ggplot2)

# Libraries for PCA (principal components analysis)
library(vegan)
library(factoextra) #fviz_eig

#libraries for MCA
library(FactoMineR)
library(dplyr)
library(factoextra) #fviz_eig

#Clean environment
rm(list=ls()) 
graphics.off()

#Set working directory
setwd("~/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost/Tseng2022/Link Prediction Model")

```

### Prepare genomic data for dimension reduction
Let's clean our sequence data and explore the variability in the data!

```{r prep_genes}

#Load genome annotations and trim
genes <- read_xlsx("OPVnew_nowwithVirus.xlsx", sheet="PoxHost")

#Rename variables and exclude unnecessary variables
genes <- plyr::rename(genes, c("Virus"="VirusSpecies","Host Genus"="HostGenus","Host Species"="HostSpecies"))
genes <- subset(genes, select=-c(HostSpecies))

#Correct sequence MT903347_1 - 'HostGenus' var lists Family name instead of Genus
genes$HostGenus <- ifelse(genes$HostGenus=="Gliridae","Graphiurus",genes$HostGenus)

#Add unique identifier
genes$rownames <- rownames(genes)
genes$Sequence <- paste(genes$Genome,genes$VirusSpecies,genes$HostGenus,sep="_",genes$rownames)
genes$rownames=NULL
genes <- genes %>% dplyr::select(Sequence, everything())

#View frequency of various virus species
prop_table <- subset(genes, select=-c(Sequence,Genome))
prop_table$Frequency = 1 
prop_table <- aggregate(Frequency ~ VirusSpecies + HostGenus, data=prop_table, FUN=sum)
prop_table <- prop_table[order(prop_table[,c("VirusSpecies")],prop_table[,c("HostGenus")]) ,]
prop_table$Perc <- prop_table$Frequency/sum(prop_table$Frequency)*100
print(prop_table)

#Save frequency table to Output folder
# write.csv(table, "Output/gene_freq_table.csv")

#Create function (mode.prop) to assess variation in the presence/absence of OPV genes
mode.prop <- function(x) {                
  ux <- unique(x[is.na(x)==FALSE])        # creates array of unique values
  tab <- tabulate(match(na.omit(x), ux))  # creates array of the frequency a unique value appears in a column 
  max(tab)/length(x[is.na(x)==FALSE])     # max-frequency / number of elements in each column that are not NA
}

#Assess variation across columns (2 indicates columns)
vars=data.frame(apply(genes,2,function(x) mode.prop(x)),
                apply(genes,2,function(x) length(unique(x)))) # number of unique elements in each column
vars$variables=rownames(vars)
colnames(vars) <- c("var","uniq","column")

#Trim
vars <- vars[-c(1,2), ]

#Any variables with no variation? If so drop
which(vars$var==1)
# vars <- subset(vars,vars$var<1)

#Visualize distribution of variation
#png("Output/gene_variation.png", width=4,height=4,units="in",res=600)
gene_var <- ggplot(vars,
       aes(var))+
  geom_histogram(bins=50)+
  geom_vline(xintercept=0.70,linetype=2,size=0.5)+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  labs(y="frequency",
       x="variation in the presence/absence of genes across genome sequences")+
  scale_x_continuous(labels=scales::percent)
#dev.off()
gene_var

# Clean environment
rm(list=setdiff(ls(), c("genes")))

```

### PCA(1) of viral accessory genes
Using principal components analysis, can we distill the variables down to their most important features? Which genes contribute the most to each feature?

```{r pca1_sum}

# Subset data and reformat as numeric matrix
# genes_mat <- subset(genes,select=-c(Genome,VirusSpecies,HostGenus))
# mat <- as.matrix(genes_mat[,-1])
# rownames(mat) <- genes_mat[,1] %>% pull()
# class(mat) <- "numeric"

#Apply PCA using stats::prcomp 
pca1 <- prcomp(genes[,5:985])      #scaling/centering not appropriate
relvar <- pca1$sdev^2 / sum(pca1$sdev^2)
relvar_per <- round(relvar*100,1)

#View summary results
# summary(pca1)
# View(pca1$x) #sequence (individuals)
# View(pca1$rotation) #genes (variables)

#Table of importance of components: Eigenvalue, SD, Proportion of Variance, Cumulative Prop
importance <- as.data.frame(t(summary(pca1)$importance))
importance$Eigenvalue <- importance$`Standard deviation`^2
importance <- importance %>% dplyr::relocate(Eigenvalue) 
importance <- importance[c(1:10),]
### Eigenvalue: the variance explained by each PC

#Table of loadings: $rotation is the matrix of variable loadings where columns are eigenvectors
loadings <- as.data.frame(pca1$rotation)
loadings <- loadings[,c(1:10)]
loadings <- abs(loadings) #get absolute values
### Why are some loadings > |1|? Loading is the covariances/correlations b/w original vars and unit-scaled components)

#For each dimension, create df of accessory genes 
for(i in 1:ncol(loadings)){
  assign(colnames(loadings)[i], data.frame(loadings[,i]))
}

#Create list of dataframes of PC loadings
list <- colnames(loadings)       
list_df = lapply(list, get)

#To each dataframe in that list, add corresponding gene name and sort in descending order (genes with highest load value to smallest load value)
for (i in 1:length(list)) {
  colnames(list_df[[i]]) <- "Loadings"
  list_df[[i]]$Gene <- rownames(loadings)
  list_df[[i]]=list_df[[i]][order(-list_df[[i]]$Loadings),]
}

#Create df of just ranked genes (drop loadings)
genes_df <- list_df
for(i in 1:length(list)) {
  genes_df[[i]]$Loadings=NULL
}
rank_genes <- data.frame(matrix(ncol=ncol(loadings), nrow=nrow(loadings)))
colnames(rank_genes) <- colnames(loadings)
for(i in 1:length(list)) {
  rank_genes[,i] = genes_df[[i]]
}
rank_genes <- setNames(rank_genes, paste0(names(loadings), '_', 'Gene'))

#Create df of just ranked loadings
loadings_df <- list_df
for(i in 1:length(list)) {
  loadings_df[[i]]$Gene=NULL
}
rank_loadings <- data.frame(matrix(ncol=ncol(loadings), nrow=nrow(loadings)))
colnames(rank_loadings) <- colnames(loadings)
for(i in 1:length(list)) {
  rank_loadings[,i] = loadings_df[[i]]
}
rank_loadings <- setNames(rank_loadings, paste0(names(loadings), '_', 'Loadings'))

#Combine dfs of ranked genes and loadings and reorder columns
rank_PC <- cbind(rank_genes, rank_loadings)
rank_PC <- rank_PC[,order(colnames(rank_PC))] 
rank_PC <- rank_PC %>% relocate(c("PC10_Gene","PC10_Loadings"), .after = last_col())

#Save table of PC Loadings Ranked
# write.csv(rank_PC, "Output/PCA_LoadingsRanked.csv")

#Save datafile of PC scores for link prediction
pc_genes <- genes[,1:4]
pc_genes <- cbind(pc_genes, pca1$x[,1:10])
#save(opvgenes, file='Output/opvgenes.RData')

#Clean environment
rm(list=setdiff(ls(), c("genes","pca1","relvar","relvar_per")))

```

### PCA(1) visualizations
Do all of the dimensions spark joy? 

```{r pca1_viz}

#Vizualize variance: screeplots, cumulative variance, etc.
#Vizualize individuals/scores
#Vizualize variables/loadings: by virus family, etc.
#Vizualize centroid
#Visualize scores by cluster via hierarchical cluster analysis (k-means)

#Screeplot variance (eigenvalues) to show the decreasing rate at which variance is explained by additional PCs
screeplot(pca1, type="lines", npcs=15, main="Scree plot of Eigenvalues for the first 10 PCs")
abline(h=1, col="red", lty=5)
legend("topright", legend=c("Eigenvalue = 1"), col=c("red"), lty=5, cex=1)
### suggests cutoff at PC10

#Screeplot cumulative variance to show the % variance explained by additional PCs
screeplot <- barplot(relvar_per[1:10], xlab='PC', ylab='Percentage of explained variances', main='Screeplot of explained variances', names.arg=1:10, las=1, ylim=c(0,max(relvar_per)+10), col='gray')
text(screeplot, 0, y=relvar_per[1:10], label=relvar_per[1:10],cex=0.8, pos=3, col="red")
# fviz_eig(pca, choice=c("variance"), main = "Scree plot of explained variances") # these values agree with pca_relvar (variance explained)

#Plot cumulative variance to show the proportion of variance explained with each add'l PC
cumpro <- cumsum(pca1$sdev^2 / sum(pca1$sdev^2))
plot(cumpro[0:15], xlab = "Dimension", ylab = "Proportion of explained variance", main = "Cumulative variance plot")
abline(v = 10, col="blue", lty=5)
abline(h = 0.7, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC10"), col=c("blue"), lty=5, cex=1)

#Plot sequences 
fviz_pca_ind(pca1) + ggtitle("PCA Plot of Sequences")
### with ellipses
fviz_pca_ind(pca1, geom.ind = "point", pointshape = 21, pointsize = 2, 
             col.ind = "black", addEllipses = TRUE, label = "var",
             col.var = "black", repel = TRUE,
             alpha.ind = 0.7) +
             ggtitle("PCA Plot of Sequences") + theme(plot.title = element_text(hjust = 0.5))

#Plot sequences by virus species for dim 1 and 2
library(ggfortify)
autoplot(pca1, data = genes, colour = 'VirusSpecies') + ggtitle("Plot of Sequences by Virus Species")

#Plot gene loadings for dim 1 and 2
fviz_pca_var(pca1, 
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             label = c("ind", "ind.sup", "quali", "var", "quanti.sup")) +
             ggtitle("Plot of Gene Loadings for Dimensions 1 and 2")
### Here we see PC1 has large positive associations with a number of AGs like ADZ29556.1, SNB51281.1, and AGZ01283.1 that point in the same direction as PC1. PC2 has some moderately positive associations with AGs like BDQ10560.1
### QKE61192.1 - hypothetical protein [Vaccinia virus]
### QNP13375.1 - MPXV Viral membrane assembly proteins (VMAP) (Cop-A 30.5L)"

#Plot gene loadings for dim 3 and 4
fviz_pca_var(pca1, axes = c(3, 4),
             col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE) +
             ggtitle("Plot of Gene Loadings for Dimensions 3 and 4")

#Biplot sequences and gene loadings
fviz_pca_biplot(pca1, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
                repel = TRUE) +
                ggtitle("Biplot of Sequences and Gene Loadings")

#Biplot top 20 influential scores and loadings
fviz_pca_biplot(pca1, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, select.ind=list(contrib=20), select.var=list(contrib=20), max.overlaps=Inf) +
             ggtitle("Biplot of Top 20 Contributing Sequences and Gene Loadings")

rm(list=setdiff(ls(), c("genes","pca1")))

```

## (2) PCA Alternative Analysis 
What happens when we exclude accessory genes present in only one virus species?

```{r pca2}

#Drop accessory genes that are present in only one virus species (all 0's except for one)
genes2 <- genes[c(1:4,4 + which(colSums(genes[-(1:4)])>1))]
### 985 variables to 686 variables

#Apply PCA using stats::prcomp 
pca2 <- prcomp(genes2[,5:686])

#Plot cumulative variance to show the proportion of variance explained with each add'l PC
cumpro <- cumsum(pca2$sdev^2 / sum(pca2$sdev^2))
plot(cumpro[0:15], xlab = "Dimension", ylab = "Proportion of explained variance", main = "Cumulative variance plot")
abline(v = 10, col="blue", lty=5)
abline(h = 0.7, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC10"), col=c("blue"), lty=5, cex=1)

#Biplot sequences and gene loadings
fviz_pca_biplot(pca2, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
               repel = TRUE) +
               ggtitle("Biplot of Sequences and Gene Loadings")

#Biplot top 20 influential scores and loadings
fviz_pca_biplot(pca2, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, select.ind=list(contrib=20), select.var=list(contrib=20), max.overlaps=Inf) +
             ggtitle("Biplot of Top 20 Contributing Sequences and Gene Loadings")

### Summary: Compared to PCA.1, there's an increase in the proportion of variance explained by the first 10 dimensions from 0.696 to 0.712. No noticeable difference in the spatial distribution of scores and vectors. 

```

## (3) PCA Alternative Analysis 
What happens when we drop duplicate observations within the same host-virus links (sequences with the same identical presence/absence of accessory genes as another sequence of the same host-virus link)?

```{r pca3}

#Identify observations of the same host-virus links with identical presence/absence of accessory genes
genes3 <- genes
genes3$dup <- duplicated(genes3[,-c(1:2)])
table(genes3$dup)
### 42 dups

#Drop duplicate observations
genes3 <- genes3[genes3$dup==FALSE,]
genes3$dup=NULL
### 197 obs to 155 obs

#Apply PCA using stats::prcomp 
pca3 <- prcomp(genes3[,5:985])

#Plot cumulative variance to show the proportion of variance explained with each add'l PC
cumpro <- cumsum(pca3$sdev^2 / sum(pca3$sdev^2))
plot(cumpro[0:15], xlab = "Dimension", ylab = "Proportion of explained variance", main = "Cumulative variance plot")
abline(v = 10, col="blue", lty=5)
abline(h = 0.7, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC10"), col=c("blue"), lty=5, cex=1)

#Biplot sequences and gene loadings
fviz_pca_biplot(pca3, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
               repel = TRUE) +
               ggtitle("Biplot of Sequences and Gene Loadings")

#Biplot top 20 influential scores and loadings
fviz_pca_biplot(pca3, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, select.ind=list(contrib=20), select.var=list(contrib=20), max.overlaps=Inf) +
             ggtitle("Biplot of Top 20 Contributing Sequences and Gene Loadings")

### Summary: Compared to PCA.1, there is a decrease in the proportion of variance explained by the first ten PCs from 0.696 to 0.680. As in previous PCAs, biplot of top 20 contributing sequences and gene loadings show the most influential sequences in the third quadrant. 

```

## (4) PCA Alternative Analysis 
What happens if we exclude the potential outliers from PCA, and then predict their scores and loadings?

```{r pca4}

#Create df excluding outliers identified in PCA.3
genes4 <- genes[!grepl("MT724769_1|MN346703_1|MT724770_1|DQ011155_1", genes$Genome),]

#Create df of outliers
outliers <- genes[grepl("MT724769_1|MN346703_1|MT724770_1|DQ011155_1", genes$Genome),]

#Apply PCA using stats::prcomp
pca4 <- prcomp(genes4[,5:985])
relvar <- pca4$sdev^2 / sum(pca4$sdev^2)
relvar_per <- round(relvar*100,1)

#Prediction of PCs for outliers
pred <- predict(pca4, newdata=outliers)
pca4_pred <- pca4
pca4_pred$x <- rbind(pca4_pred$x, pred)

#Plot of individuals by virus species w/ outliers in shaded bullets
COLOR <- c(1:length(unique(genes$VirusSpecies)))
pc <- c(1,2)
plot(pca4$x[,pc], cex=1, col=COLOR,
     xlab=paste0("PC 1", "(", relvar_per[pc[1]], "%)"), 
     ylab=paste0("PC 2", "(", relvar_per[pc[2]], "%)"))
points(pred[,pc], pch=16) + abline(h = 0, v=0, lty = 2) +
title("Plot of Sequences and Outliers") + theme(plot.title = element_text(hjust = 0.5))

#Biplot of individuals and variables
fviz_pca_biplot(pca4_pred, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE) +
             ggtitle("Biplot of Sequences and Gene Loadings")

#Biplot of top 20 contributing individuals and variables
fviz_pca_biplot(pca4_pred, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, select.ind=list(contrib=20), select.var=list(contrib=20)) +
             ggtitle("Biplot of Sequences and Gene Loadings")

#Clean environment
rm(list=setdiff(ls(), c("genes", "pca1","outliers")))

### Summary: Predicted scores of outliers cluster in the fourth quadrant with other sequences. As in previous PCAs, biplot of top 20 contributing sequences and gene loadings show the most influential sequences in the third quadrant.

```

## PCA Hierarchical Cluster Analysis

```{r pca1_cluster}

#Extract coordinates for individual sequences
ind.coord <- pca1$x
rownames(ind.coord) <- 1:nrow(ind.coord)
db <- cbind(genes$VirusSpecies, ind.coord)

#HCA on a set of dissimilarities for objects being clustered, wherein each object is assigned its own cluster iteratively, at each stage joining the 2 most similar clusters (bottom-up dendogram until only one cluster left). 
clusters <- hclust(dist(db[,2:3]))
plot(clusters)
abline(h = 8, col="red", lty=5)
abline(h = 4, col="blue", lty=5)

#Cluster cut
clusterCut <- cutree(clusters, 6)
table(clusterCut)

#Prop tables by virus species
mytable<-table(clusterCut, genes$VirusSpecies)
mytable2 <- data.frame(prop.table(mytable,2))
ggplot(mytable2, aes(x = Var2, y = Freq, fill = clusterCut)) +
  geom_col() +
  labs(fill='Cluster') +
  theme(axis.title.x = element_blank(), axis.text.x = element_text(angle=45,hjust=1)) +
  ggtitle("Distribution by Virus Species")

#Re-run PCA to color by cluster  
  #add cluster to original db
  genes1<-data.frame(cbind(genes,clusterCut))
  genes1$clusterCut <- as.factor(genes1$clusterCut)

#Run PCA as before, but now grouping by cluster
pca1 <- prcomp(genes1[,5:985])      #scaling/centering not appropriate
# pca_relvar <- pca$sdev^2 / sum(pca$sdev^2)
# pca_relvar_per <- round(pca_relvar*100,1)

fviz_pca_ind(pca1, geom.ind = "point", pointshape = 21, 
             pointsize = 2, 
             fill.ind = genes1$clusterCut, 
             col.ind = "black", 
             addEllipses = TRUE,
             label = "var",
             col.var = "black",
             repel = TRUE,
             legend.title = "Cluster",
             alpha.ind = 0.5) +
  ggtitle("PCA Plot of Sequences by Cluster") +
  theme(plot.title = element_text(hjust = 0.5))

fviz_pca_biplot(pca1, geom.ind = "point", pointshape = 21, 
             pointsize = 2, 
             fill.ind = genes1$clusterCut,
             col.ind = "black",
             label = "var",
             repel = TRUE,
             legend.title = "Cluster",
             addEllipses = TRUE,
             pallete = "lancet",
             alpha.ind = 0,
             col.var = "grey40") +
    ggtitle("PCA Biplot of Sequences and Gene Loadings by Cluster")

#Create a table of sequences by cluster
db_cluster <- dplyr::select(genes1, Sequence, VirusSpecies, HostGenus,clusterCut)
# write.csv(db.cluster,"clusters.csv", row.names = F)

#Are the MPXV sequences in cluster 3 the same as the outliers in PCA4?
print(db_cluster[(db_cluster$VirusSpecies=="Monkeypox virus" & db_cluster$clusterCut==3),])
print(outliers[,1:4])

#Clean environment
rm(list=setdiff(ls(), c("genes")))

```


### MCA of viral accessory genes
Multiple Correspondence Analysis (MCA) for dimension reduction of categorical variables.

```{r mca}

#Subset data and reformat gene variables as factor
genes_cat <- subset(genes,select=-c(Genome,VirusSpecies,HostGenus))
genes_cat[] <- lapply(genes_cat, as.character)
rownames <- genes$Sequence
genes_cat[,-1] <- lapply(genes_cat[,-1], factor)
genes_cat$Sequence=NULL
rownames(genes_cat) <- rownames
#str(genes_cat)

#Apply MCA using FactoMineR::MCA
mca = MCA(genes_cat, graph = FALSE)
# pca_relvar <- pca$sdev^2 / sum(pca$sdev^2)
# pca_relvar_per <- round(pca_relvar*100,1)

#List and summarize MCA results
print(mca)
# summary(mca)
head(mca$ind$coord) #sequence (individuals)
head(mca$var$coord) #genes (variables)

#Screeplot - Variance (Eigenvalues)
#mca$eig
fviz_eig(mca, addlabels = TRUE, ylim = c(0, 25))

#Plots of individuals
fviz_mca_ind(mca, repel=TRUE)

#Plots of MCA variables 1 and 2
fviz_mca_var(mca, repel = TRUE) ##

#Biplot
fviz_mca_biplot(mca, repel = TRUE)
fviz_mca_biplot(mca, repel = FALSE, select.ind=list(contrib=20), select.var=list(contrib=20))

#Clean environment
rm(list=ls())

```

# 2. Data Preparation

### Load data for merging: i.e., Host-pox/viral traits (PC), taxonomy data, host traits, and host tree

```{r prep_raw}

#(1) Load raw data
load("Data_raw.RData")
load("Output/opvgenes.RData")


#(2) Pox data:  host-OPV interactions detected via PCR/isolation from Virion database *note additional interactions from pc_genes below
##virion <- vroom('https://github.com/viralemergence/virion/blob/main/Virion/Virion.csv.gz')
poxdata <- virion %>% filter(VirusGenus == "orthopoxvirus" & (DetectionMethod %in% c("PCR/Sequencing","Isolation/Observation"))) 

#(3) Viral traits data (& Host-pox links): host-OPV linked interactions & principal components of OPV genes (viral traits) extracted from genome sequence data 
wgsdata <- pc_genes

#(3) Taxa: mammal species taxonomy from vertlife
##vertlife <- read.csv(url('https://data.vertlife.org/mammaltree/taxonomy_mamPhy_5911species.csv'))
taxa <- vertlife

#(4) Host traits: mammal traits from the COMBINE database <https://doi.org/10.1002/ecy.3344>
##path: ecy3344-sup-0001-datas1.zip > COMBINE_archives > trait_data_imputed.csv)
hostTraits <- combine

#(5) Host tree: mammal phylogeny tree from Dryad, <https://doi.org/10.5061/dryad.tb03d03>
##path: Data_S8_finalFigureFiles > _DATA > MamPhy_fullPosterior_BDvr_Completed_5911sp_topoCons_NDexp_MCC_v2_target.tre)
hostTree <- dryad

#(6) Clean environment
rm(virion, vertlife, dryad, combine, opvgenes, pc_genes)
```

### Merge host-OPV interactions from Virion with host-OPV intx from genome annotations (Stephanie)

```{r prep_poxdata}

### Clean up Virion data ###

#(1) Exclude if host genus or virus is NA; exclude variola (smallpox) virus
poxdata <- poxdata[!is.na(poxdata$HostGenus),]
poxdata <- poxdata[!is.na(poxdata$Virus),]
poxdata <- poxdata[!(poxdata$Virus=="variola virus"),]
#In this model, we keep vaccinia virus!

#(2) Aggregate data at the host genus level
poxdata$link <- 1
poxdata <- aggregate(link~HostGenus+Virus, data=poxdata, mean)
poxdata$link=NULL

#(3) Rename/reformat variables
poxdata <- plyr::rename(poxdata,c('HostGenus'='genus','Virus'='virus'))
poxdata$genus <- str_to_title(poxdata$genus)

#(4) Add datasource variable
poxdata$virion <- 1

### Clean up genomic data ###

#(5) For WGS data, extract host genus name
wgsdata$genus <- sapply(strsplit(wgsdata$HostGenus,' '),function(x) paste(x[1],sep=' '))

#(6) Reformat virus variable
wgsdata$virus <- tolower(wgsdata$VirusSpecies)

#(7) Drop unnecessary variables
wgsdata$dup=NULL
wgsdata$Accession=NULL
wgsdata$HostGenus=NULL
wgsdata$VirusSpecies=NULL

#(8) Add datasource variable
wgsdata$wgs <- 1

### Merge ###

#(10) Check for mismatched virus names between poxdata and wgsdata
wgsdata$virus[!wgsdata$virus %in% poxdata$virus]
# @Steph: Is cetacean pox virus entry 1 or 2?

#(11) Check for mismatched genus names between poxdata and wgsdata
wgsdata$genus[!wgsdata$genus %in% poxdata$genus]
# @Steph: Is cetacean pox virus entry 1 or 2?

#(12) Change "Gliridae" to "Graphiurus"
wgsdata$genus <- ifelse(wgsdata$genus=="Gliridae", "Graphiurus", wgsdata$genus)

#(13) Merge poxdata w/ wgsdata
poxdata <- merge(poxdata,wgsdata,by=c('virus','genus'),all=TRUE)

#(14) Create data source variable
poxdata$source <- ifelse(poxdata$wgs==1 & is.na(poxdata$virion),"wgs", ifelse(poxdata$virion==1 & is.na(poxdata$wgs),"virion","both"))

#(15) Remove virion and wgs vars; clean environment
poxdata$virion=NULL
poxdata$wgs=NULL
rm(wgsdata)

#(15) Replace sequence==NA with "NA", as this var will be our unique identifier for WGS links
poxdata$sequence <- ifelse(is.na(poxdata$sequence),"NA",poxdata$sequence)

```

### Merge poxdata with broader mammal taxa to create pseudoabsences

```{r prep_pseudo}

#(1) Drop duplicate genera in taxa
gtaxa <- taxa[!duplicated(taxa$gen),]
gtaxa <- gtaxa[c('gen','fam','ord')]
gtaxa <- plyr::rename(gtaxa, c('gen'='genus'))

#(2) Check for mismatched genus names between poxdata and taxa before merging poxdata with taxa
poxdata$genus[!poxdata$genus %in% gtaxa$genus]
poxdata <- merge(gtaxa,poxdata,by='genus',all.x=TRUE)

#(3) To keep only genera from orders in which positive associations exist, first subset known host-virus associations
keep <- subset(poxdata, !is.na(poxdata$source))

#(4) Next, create a new variable <keep> in poxdata denoting observations with the same host taxonomic order as that of known associations
poxdata$keep <- ifelse(poxdata$ord %in% keep$ord,TRUE,FALSE)

#(5) View/evaluate which taxonomics orders will be kept and which orders will be discarded
uniq <- unique(poxdata[c("ord","keep")])

#(6) Keep only observations with the same host taxonomic order as that of known associations
poxdata <- subset(poxdata,keep==TRUE)
poxdata$keep=NULL

#(7) Create binary variable for known host-OPV associations/links
poxdata$link=ifelse(is.na(poxdata$source),0,1)

#(8) Reorder variables
poxdata <- poxdata %>% select(link, virus, genus, fam, ord, source, everything())

#(9) Clean environment
rm(taxa,gtaxa,keep,uniq)

```

### Aggregate hostTraits to genus-level

```{r prep_traits}

#(1) Observe variable names
colnames(hostTraits)

#(2) To aggregate continuous/integer variables, use the median as the summary measure
hostTraits_continuous=aggregate(cbind(adult_mass_g,brain_mass_g,adult_body_length_mm,adult_forearm_length_mm,
                                   max_longevity_d,maturity_d,female_maturity_d,male_maturity_d,
                                   age_first_reproduction_d,gestation_length_d,teat_number_n,
                                   litter_size_n,litters_per_year_n,interbirth_interval_d,
                                   neonate_mass_g,weaning_age_d,weaning_mass_g,generation_length_d,
                                   dispersal_km,density_n_km2,home_range_km2,social_group_n,
                                   dphy_invertebrate,dphy_vertebrate,dphy_plant,
                                   det_inv,det_vend,det_vect,det_vfish,det_vunk,det_scav,det_fruit,det_nect,det_seed,det_plantother,det_diet_breadth_n,
                                   upper_elevation_m,lower_elevation_m,altitude_breadth_m,habitat_breadth_n) 
                             ~ order+family+genus, data=hostTraits, FUN=median, na.action=na.pass, na.rm=TRUE)
##'na.action=na.pass, na.rm=TRUE' is specified such that if species w/in a genus has a combination of real values & NAs, the median of real values will be returned (as opposed to omitting the genus or returning NA)

#(3) To aggregate binary variables, use the mean as the summary measure
hostTraits$fossoriality[hostTraits$fossoriality==2]<-0  #recode 0/1
hostTraits_binary=aggregate(cbind(hibernation_torpor,fossoriality,freshwater,marine,terrestrial_non.volant,terrestrial_volant,
                               island_dwelling,disected_by_mountains,glaciation) ~ order+family+genus, data=hostTraits, FUN=mean, na.action=na.pass, na.rm=TRUE)

#(4) To aggregate categorical variables, first transform the variables to binary
hostTraits_cat <- hostTraits
hostTraits_cat$trophic_herbivores <- ifelse(hostTraits_cat$trophic_level==1,1,0)
hostTraits_cat$trophic_omnivores <- ifelse(hostTraits_cat$trophic_level==2,1,0)
hostTraits_cat$trophic_carnivores <- ifelse(hostTraits_cat$trophic_level==3,1,0)
hostTraits_cat$activity_nocturnal <- ifelse(hostTraits_cat$activity_cycle==1,1,0)
hostTraits_cat$activity_crepuscular <- ifelse(hostTraits_cat$activity_cycle==2,1,0) #nocturnal/crepuscular, cathemeral, crepuscular or diurnal/crepuscular
hostTraits_cat$activity_diurnal <- ifelse(hostTraits_cat$activity_cycle==3,1,0)
hostTraits_cat$forager_marine <- ifelse(hostTraits_cat$foraging_stratum=="M",1,0)
hostTraits_cat$forager_ground <- ifelse(hostTraits_cat$foraging_stratum=="G",1,0) 
hostTraits_cat$forager_scansorial <- ifelse(hostTraits_cat$foraging_stratum=="S",1,0)
hostTraits_cat$forager_arboreal <- ifelse(hostTraits_cat$foraging_stratum=="Ar",1,0)
hostTraits_cat$forager_aerial <- ifelse(hostTraits_cat$foraging_stratum=="A",1,0)
hostTraits_cat$island_end_marine <- ifelse(hostTraits_cat$island_endemicity=="Exclusively marine",1,0)
hostTraits_cat$island_end_mainland <- ifelse(hostTraits_cat$island_endemicity=="Occurs on mainland",1,0)
hostTraits_cat$island_end_lgbridge <- ifelse(hostTraits_cat$island_endemicity=="Occurs on large land bridge islands",1,0)
##hostTraits_cat$island_end_smbridge <- ifelse(hostTraits_cat$island_endemicity=="Occurs on small land bridge islands",1,0)
hostTraits_cat$island_end_isolated <- ifelse(hostTraits_cat$island_endemicity=="Occurs only on isolated islands",1,0)
hostTraits_cat$biogeo_afrotropical <- ifelse(grepl("Afrotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_antarctic <- ifelse(grepl("Antarctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_australasian <- ifelse(grepl("Australasian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_indomalayan <- ifelse(grepl("Indomalayan",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_nearctic <- ifelse(grepl("Nearctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_neotropical <- ifelse(grepl("Neotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_oceanian <- ifelse(grepl("Oceanian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_palearctic <- ifelse(grepl("Palearctic",hostTraits_cat$biogeographical_realm),1,0)

#(5) To aggregate transformed categorical-to-binary variables, use the mean as the summary measure
hostTraits_cat=aggregate(cbind(trophic_herbivores,trophic_omnivores,trophic_carnivores,
                            activity_nocturnal,activity_crepuscular,activity_diurnal,
                            forager_marine,forager_ground,forager_scansorial,forager_arboreal,forager_aerial,
                            island_end_marine,island_end_mainland,island_end_lgbridge,island_end_isolated,
                            biogeo_afrotropical,biogeo_antarctic,biogeo_australasian,biogeo_indomalayan,biogeo_nearctic,biogeo_neotropical,biogeo_oceanian,biogeo_palearctic)
                       ~ order+family+genus, data=hostTraits_cat, FUN=mean, na.action=na.pass, na.rm=TRUE)

#(6) Merge continuous variables with binary variables and simplify dataframe
hostTraits <- full_join(hostTraits_continuous, hostTraits_binary, by = c("order","family","genus"),keep=TRUE)
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits=subset(hostTraits, select=-c(order.y,family.y,genus.y))

#(7) Merge transformed categorical variables and simplify dataframe
hostTraits <- full_join(hostTraits, hostTraits_cat, by = c("order","family","genus"),keep=TRUE)
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits <- subset(hostTraits, select=-c(order.y,family.y,genus.y))

#(8) Clean environment
rm(hostTraits_binary,hostTraits_cat,hostTraits_continuous)

```

### Collapse hostTree to genus-level

```{r prep_tree}

#(1) Reformat
hostTree$tip.label[hostTree$tip.label=="_Anolis_carolinensis"] <- "Anolis_carolinensis"

#(2) Create dataframe linking tip labels with their corresponding categories (genus and species)
tdata <- data.frame(matrix(NA,nrow=length(hostTree$tip.label),ncol=0))
tdata$genus <- sapply(strsplit(hostTree$tip.label,'_'),function(x) paste(x[1],sep='_'))
tdata$species <- hostTree$tip.label

#(3) Collapse tree to genus level
hostTree <- makeCollapsedTree(tree=hostTree,df=tdata[c('genus','species')])

#(4) Clean environment
rm(tdata)

```

### Check for mismatched genera names in poxdata, hostTraits and hostTree

```{r prep_names}

#(1) Check if all poxdata genera are in hostTree
poxdata$gtip <- poxdata$genus
hostTree$gtip <- hostTree$tip.label
poxdata$intree <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTree$gtip),'missing','upham')

#(2) Check if all poxdata genera are in hostTraits
hostTraits$gtip <- hostTraits$genus
poxdata$intraits <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTraits$gtip),'missing','traits')

#(3) Create a dataframe of just the observations with mismatched names
fix <- poxdata[c('gtip','intree','intraits')]
fix <- fix[fix$intree=='missing'|fix$intraits=='missing',]
fix <- unique(fix)

#(4) For those with mismatched names, identify homotypic synonyms or proxy species via IUCN (https://www.iucnredlist.org/) and NCBI (http://www.ncbi.nlm.nih.gov/taxonomy)
fix$treename <- NA
fix$traitname <- NA
fix$proxy <- NA
fix$proxy <- ifelse(fix$gtip=="Calassomys","Delomys",fix$proxy)
  ##source: https://academic.oup.com/jmammal/article/95/2/201/860032
fix$traitname <- ifelse(fix$gtip=="Liomys","Heteromys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Oreonax","Lagothrix",fix$traitname)
  ##source: https://www.iucnredlist.org/species/39924/192307818
fix$traitname <- ifelse(fix$gtip=="Paralomys","Phyllotis",fix$traitname)
  ##source: https://www.iucnredlist.org/species/17226/22333354
fix$traitname <- ifelse(fix$gtip=="Pearsonomys","Geoxus",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Pipanacoctomys","Tympanoctomys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/136557/78324400#taxonomy
fix$traitname <- ifelse(fix$gtip=="Pseudalopex","Lycalopex",fix$traitname)
  ##source: https://www.iucnredlist.org/species/6926/87695615
## hostTraits$genus[which(grepl('Tympanoctomys',hostTraits$genus))]

#(5) Merge revised names with poxdata
fix <- subset(fix, select=-c(intree,intraits))
poxdata <- merge(poxdata,fix,by='gtip',all.x=T)

#(6) If 'treename' is missing, first relabel as NA, then relabel with 'gtip'
poxdata$treename <- ifelse(poxdata$treename=='',NA,as.character(poxdata$treename))
poxdata$treename <- ifelse(is.na(poxdata$treename),as.character(poxdata$gtip),as.character(poxdata$treename))

#(7) If 'traitname' is missing, first relabel as NA; If 'traitname' is NA and missing in 'intraits', then relabel with 'proxy'; If 'traitname' is not NA and missing in 'intraits', then relabel with 'traitname'
poxdata$traitname <- ifelse(poxdata$traitname=='',NA,as.character(poxdata$traitname))
poxdata$traitname <- ifelse(poxdata$intraits=='missing' & is.na(poxdata$traitname),as.character(poxdata$proxy),
                      ifelse(poxdata$intraits=='missing' & !is.na(poxdata$traitname),as.character(poxdata$traitname),
                             as.character(poxdata$gtip)))

#(8) Simplify and clean environment
poxdata <- subset(poxdata, select=-c(intree,intraits,proxy))
rm(fix)

```

### Merge poxdata with hostTraits and trim hostTree to mirror poxdata

```{r prep_merge}

#(2) Merge traits with poxdata
hostTraits$traitname <- hostTraits$gtip
poxdata <- merge(poxdata,hostTraits,by=c('traitname'),all.x=T)

#(3) Clean up poxdata
poxdata <- plyr::rename(poxdata,c('gtip.x'='gtip','genus.x'='genus'))
poxdata <- subset(poxdata,select=-c(order, family, genus.y, gtip.y))

#(4) Trim hostTree (remove species tip) to mirror poxdata
hostTree <- keep.tip(hostTree,hostTree$tip.label[hostTree$tip.label%in%poxdata$treename])
hostTree$gtip <- NULL
hostTree=makeLabel(hostTree)

#(5) Clean environment
rm(hostTraits)

```

### Add PubMed citations and evolutionary distinctiveness measure

```{r prep_cites_ed}

#(1) Load library for PubMed citations
library(easyPubMed)

#(2) Create function to count citations
counter=function(name){
  as.numeric(as.character(get_pubmed_ids(gsub('_','-',name))$Count))
}
citations=c()

#(3) Extract unique genera from poxdata
treename <- unique(poxdata$treename)

#(4) Apply counter function while looping through treenames
for(i in 1:length(treename)) {
  citations[i]=counter(treename[i])
  print(i)
}

#(5) Compile citation numbers
cites <- data.frame(treename=treename,cites=citations)

#(6) Merge cites with poxdata
poxdata <- merge(poxdata,cites,by='treename')

#(7) Load library for evolutionary distinctiveness (ed) measure
library(picante)  #before loading picante, make sure latest version of nlme package is loaded
ed <- evol.distinct(hostTree,type='equal.splits') #calculates ed measures for a suite of species by equal splits and fair proportions; returns species score

#(8) Rename variables in ed
ed <- plyr::rename(ed,c('Species'='treename','w'='ed_equal'))

#(9) Merge ed with poxdata
poxdata <- merge(poxdata,ed,by='treename')

#(10) Clean environment
rm(cites,ed,citations,i,treename,counter)

## consider adding viral genome length, viral richness (number of virus detected in each genera), and host range (number of hosts from which each virus was)

```

### Add all possible host-OPV combinations for link prediction model

```{r prep_link}

#(1) Create a dataframe of all possible host-OPV combinations (for mammal genera that exist in orders w/ known OPV predictions) by identifying all unique virus species and host genus of known associations and using the {expand.grid} function
uniq_virus <- unique(poxdata$virus[!is.na(poxdata$virus)])
uniq_genus <- unique(poxdata$genus[!is.na(poxdata$genus)])
combinations <- expand.grid(uniq_virus, uniq_genus)
combinations <- plyr::rename(combinations,c('Var1'='virus','Var2'='genus'))

#(2) Create two dataframes: one subsetting host-OPV interaction/link data from poxdata (excluding host trait data), and the other subsetting unique host trait data (i.e., all other variables) which we will merge back in later
linkdata <- poxdata[,grepl("link|virus|genus|source|sequence|PC", names(poxdata))]
hostTraits <- poxdata[,!grepl("link|virus|source|sequence|PC", names(poxdata))] # include genus b/c we will merge on it later
hostTraits <- hostTraits[!duplicated(hostTraits$genus),]

#(3) Merge linkdata with all possible combinations (drop observations if virus NA)
linkdata <- merge(linkdata, combinations, by=c("virus","genus"),all=TRUE)
linkdata <- linkdata[!is.na(linkdata$virus),]

#(4) Merge linkdata with hostTraits
linkdata <- merge(linkdata, hostTraits, by=c("genus"))

#(5) Reorder variables
linkdata <- linkdata %>% select(source, sequence, link, virus, genus, fam, ord, gtip, traitname, treename, PC1, PC2, PC3, PC4, PC5, PC6, everything())

#(6) Reclassify NAs as pseudo-absences for viral detection
linkdata$link=ifelse(is.na(linkdata$link),0,linkdata$link)

### Next, we need to impute values of PC variables where data exist for that virus.

#(7) First let's subset virus and PC variables, and drop rows w/ NA
pc <- linkdata[,grepl("virus|PC", names(linkdata))]
pc <- pc[!is.na(pc$PC1),]

#(8) Let's take a quick look at which virus do not have PC data
setdiff(unique(linkdata$virus),unique(pc$virus))

#(9) Next, we obtain the median value of each PC variable for each virus using aggregate function (dot notation), and rename PC variables
pc_median=aggregate(. ~virus, data=pc, FUN=median)
colnames(pc_median)[c(-1)] <- paste(colnames(pc_median)[c(-1)], "_med", sep="")

#(10) Merge PC median variables w/ poxdata
linkdata <- merge(linkdata,pc_median,by=c("virus"),all.x=TRUE)

#(11) Get PC colnames and replace NA values of PC vars w/ median PC values using for-loop
pc_names <- colnames(pc)[c(-1)]
for(i in pc_names) {
  linkdata[,i] <- ifelse(is.na(linkdata[,i]),linkdata[,paste(i,"_med",sep="")],linkdata[,i])
}

#(12) Drop median PC variables
pc_med_names <- colnames(pc_median)[c(-1)]
for(i in pc_med_names) {
  linkdata[,i]=NULL
}

#(13) Clean environment
rm(combinations, hostTraits, uniq_virus, uniq_genus, pc, pc_median, pc_names, pc_med_names, i, poxdata)

```

### Save cleaned data

```{r prep_save}

#(1) Reorder variables
linkdata <- linkdata %>% select(source, sequence, link, virus, genus, fam, ord, gtip, traitname, treename, cites, ed_equal, everything())

#(2) Save dataframes for analysis **poxdata_temp.RData is for practice analysis**
save(linkdata, hostTree, file='Output/LinkData_clean.RData')

```


# 3. Boosted Regression Trees (BRT)

### Load required packages and set system

```{r brt_load}

#(1) Libraries for BRT model
library(gbm)
library(fastDummies)
library(rsample)
library(ROCR)
library(sciplot)
library(ggplot2)
library(pdp)
library(PresenceAbsence)
library(tidyr)
library(viridis)
library(caper)
library(phylofactor)
library(ggtree)
library(treeio)
library(caret) 
library(InformationValue)
library(mgcv)

#(2) Clean environment
rm(list=ls()) 
graphics.off()

```

### Create taxonomic variables as predictors for the model

```{r brt_taxo}

#(1) Load data and clean environment
load("Output/LinkData_clean.RData")
data <- linkdata
rm(linkdata)

#(2) Ensure all accessory gene variables are numeric
PC_columns <- colnames(data[which(grepl("PC",names(data)))])
data[,c(PC_columns)] <- lapply(data[c(PC_columns)],as.numeric)
str(data)
# 
# #(1) Classify true negatives
# data$type=ifelse(data$pcr==0 & data$competence==0,"true negative","other")
# 
# #(2) Which species is competent but no PCR record?
# set=data
# set$treename[set$pcr==0 & set$competence==1]
# 
# #(3) Tabulate PCR/infection and isolation
# set$inf=ifelse(set$pcr==0,"PCR negative","PCR positive")
# set$iso=ifelse(set$competence==0,"no isolation","isolation")
# table(set$inf,set$iso)

#(4) Make binary variables for each taxonomic family; remove any duplicates
dums=dummy_cols(data["fam"])
dums=dums[!duplicated(dums$fam),]

#(5) Ensure all family vars are factor
for(i in 1:ncol(dums)){
  dums[,i]=factor(dums[,i])
}

#(6) Merge family taxa variables with dataset as predictors
data=merge(data,dums,by="fam",all.x=T)

#(7) Drop unnecessary columns and clean environment
data$traitname=NULL
rm(dums, PC_)

```

### Assess variation and availability of data

```{r brt_var}

#(1) Mode function
mode.prop <- function(x) {                
  ux <- unique(x[is.na(x)==FALSE])        # creates array of unique values
  tab <- tabulate(match(na.omit(x), ux))  # creates array of the frequency (number of times) a unique value appears in a column 
  max(tab)/length(x[is.na(x)==FALSE])     # max-frequency / number of elements in each column that are not NA
}

#(2) Assess variation across columns (2 indicates columns)
vars=data.frame(apply(data,2,function(x) mode.prop(x)),
                apply(data,2,function(x) length(unique(x))))    # number of unique elements in each column

#(3) Get names
vars$variables=rownames(vars)
names(vars)=c("var","uniq","column")

# ## round values
# vars$var=round(vars$var,2)

#(4)Label variables "cut" if homogeneous (100%)
vars$keep=ifelse(vars$var<1,"keep","cut")
vars$keep=ifelse(vars$column%in%c('fam','source','sequence','link','virus','genus','ord','gtip','treename','cites','ed_equal'),'keep',vars$keep) # ensures we keep these columns
vars=vars[order(vars$keep),]

#(5) Trim (creates array of column names to cut and removes from df)
keeps=vars[-which(vars$keep=="cut"),]$column

#(6) Drop if no variation
data=data[keeps]
rm(keeps,vars)

#(7) Assess missing values
mval=data.frame(apply(data,2,function(x) length(x[!is.na(x)])/nrow(data))) # proportion of values that are not NA

#(8) Get names
mval$variables=rownames(mval)
names(mval)=c("comp","column")
# 
# #(9) visualize distribution of NA
# png("Figure S1.png", width=4,height=4,units="in",res=600)
# ggplot(mval[!mval$column%in%c("gen","treename","pcr","competence","tip.label","fam"),],
#        aes(comp))+
#   geom_histogram(bins=50)+
#   geom_vline(xintercept=0.70,linetype=2,size=0.5)+
#   theme_bw()+
#   theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
#   theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
#   theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
#   labs(y="frequency",
#        x="trait coverage across mammal species (genus)")+
#   scale_x_continuous(labels = scales::percent)
# dev.off()

#(10) Label variables "cut" if >30% values are NA
mval$keep=ifelse(mval$comp>=0.70,"keep","cut")
table(mval$keep)
mval=mval[order(mval$keep),]

#(11) Trim (creates array of column names to cut and removes from df)
keeps=mval[-which(mval$keep=="cut"),]$column

#(12) Drop if not well represented
data=data[keeps]
rm(keeps,mval)

#(14) Save list of covariates and their coverage as table S1
set <- subset(data,select=-c(virus,gen,fam,ord,gtip,treename,type,studies,sampled))
ts1=data.frame(apply(set,2,function(x) length(x[!is.na(x)])/nrow(set)))

#(15) Rename and reorder columns
ts1$variables=rownames(ts1)
names(ts1)=c("coverage","feature")
rownames(ts1)=NULL
ts1=ts1[!ts1$feature%in%c("pcr","competence"),]
ts1 <- subset(ts1,select=c(feature,coverage))
# 
# #(16) Save Table S1 to results
# write.csv(ts1, "TableS1.csv")

#(17) Check that binary variables are numeric and not factor
str(set)

```

### Model tuning to asses model performance for each combination of tuning parameters

```{r brt_tuning}

#(1) Hyperparameter tuning ifelse
#hok="ok"
hok="notok"
if(hok!="ok"){
  
  ## hyperparameter grid
  hgrid=expand.grid(n.trees=5000,                              #creates df from all combinations of factor vars (1*3*3*1*10=90 obs & 5 vars)
                    interaction.depth=c(2,3,4),
                    shrinkage=c(0.01,0.001,0.0005),
                    n.minobsinnode=4,
                    seed=seq(1,10,by=1))
  # hgrid=expand.grid(n.trees=500,                              #creates df from all combinations of factor vars (1*3*3*1*10=90 obs & 5 vars)
  #                   interaction.depth=c(2,3,4),
  #                   shrinkage=c(0.1,0.01,0.005),
  #                   n.minobsinnode=4,
  #                   seed=seq(1,10,by=1))
  # fix trees
  hgrid$n.trees=ifelse(hgrid$shrinkage<0.001,hgrid$n.trees*3,hgrid$n.trees)
  
  ## trees, depth, shrink, min, prop 
  hgrid$id=with(hgrid,paste(n.trees,interaction.depth,shrinkage,n.minobsinnode))   #creates var 'id' concatenating values from each of the specified columns in hgrid
  
  ## sort by id then seed
  hgrid=hgrid[order(hgrid$id,hgrid$seed),]
  
  ## now add rows
  hgrid$row=1:nrow(hgrid)                                        #adds var 'row' based on row number in hgrid
  
  ## factor id
  hgrid$id2=factor(as.numeric(factor(hgrid$id)))                 #creates 9-level factor var 'id2' 
  
  
  ## function to assess each hyperpar combination
  hfit=function(row,response){
    
    ## make new data
    ndata=set
    
    ## correct response
    ndata$response=ndata[response][,1]                           #creates var 'response'
    
    ## remove raw
    ndata$pcr=NULL
    ndata$competence=NULL
    
    ## use rsample to split
    set.seed(hgrid$seed[row])                                    #sets seed value of 1-10
    split=initial_split(ndata,prop=0.7,strata="response")        #creates single binary split of data into training set and testing set, where 70% of data is retained for modeling/analysis and resampling is created within the 'response' var
    
    ## test and train
    dataTrain=training(split)
    dataTest=testing(split)
    
    ## yTest and yTrain
    yTrain=dataTrain$response                                    #create array of just response values from training and testing set
    yTest=dataTest$response
    
    ## BRT
    set.seed(1)
    gbmOut=gbm(response ~ . ,data=dataTrain,                     #y~x; gbmOut contains list of 29 elements including train.error and valid.error referenced later in gbm.perf()
               n.trees=hgrid$n.trees[row],                       #total number of trees to fit (number of iterations; default is 100)
               distribution="bernoulli",
               shrinkage=hgrid$shrinkage[row],                   #equiv to learning rate or step-size reduction (smaller learning rate requires more trees, default is 0.1)
               interaction.depth=hgrid$interaction.depth[row],   #max depth of each tree (highest level of variable interactions allowed; default is 1)
               n.minobsinnode=hgrid$n.minobsinnode[row],         #min. number of obs in terminal nodes of trees
               cv.folds=5,class.stratify.cv=TRUE,                #no. of cross-val folds to perform; for cv.folds>1, returns estimate of generalization error in 'cv.error'
               bag.fraction=0.5,train.fraction=1,                #fraction of training set obs randomly selected to propose next tree in expansion - this is why we set.seed()
               n.cores=5,                                        #no. of CPU cores to use
               verbose=F)
               # par.details=(gbmParallel(num_threads=5)),
    
    ## performance
    par(mfrow=c(1,1),mar=c(4,4,1,1))                             #sets graphical parameters such that subsequent figure are drawn in a nr-by-nc array by mfrows respectively and gives the number of lines of margin to be specified on the four sides of the plot c(bottom, L, top, R) -> see 'best.iter' plot below 
    best.iter=gbm.perf(gbmOut,method="cv")                       #estimates optimal number of boosting iterations and plots 'training.error' performance measure; cv method extracts this optimal number using cross-validation
    
    ## predict with test data
    preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")  #number of trees based on the optimal number of boosting iterations as set above (5,352)
    
    ## known
    result=dataTest$response
    
    # ##estimate threshold value for classification of predicted probability
    # #library(pROC)
    # analysis <- roc(result,preds)  #roc([actual values],[predicted values])
    # e <- cbind(analysis$thresholds,analysis$sensitivities+analysis$specificities) #pulls each array and binds them into dataframe: 1st column are thresholds, 2nd column are sensitivities + specificities
    # 
    # ##optimum threshold value
    # opt_t <- subset(e,e[,2]==max(e[,2]))[,1] #subsets dataframe and returns the max (sens+spec) value of 2nd column of e 
    # #threshold<-opt_t #set as threshold value
    # #threshold = 0.2
    
    ## sensitivity and specificity                              #e.g., test run produced sensitivity of 0 b/c no predictedScores were > 0.5; and specificity of 1 b/c all predictedScores were <0.5
    sen=InformationValue::sensitivity(result,preds)              #calculates sensitivity (# of obs with event AND predicted to have event, divided by # of obs w/ event) for a given logit model where input is the actual binary flag (as numerica vector) for the response variable and the predicted probability scores for each observation; if predicted value is above the threshold (defaults to 0.5), it will be considered an event (1) or else a non-event (0)
    spec=InformationValue::specificity(result,preds)             #calculates specificity (# of obs w/o event AND predicted to not have event, divided by # of obs w/o event)  
    
    ## AUC on train
    auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))   #compute Information Retrieval measures for pairwise loss for a single group, where input is the observed value and the predicted value
    
    ## AUC on test
    auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
    
    ## print
    print(paste("hpar row ",row," done; test AUC is ",auc_test,sep=""))  #prints "hpar row [x] done; test AUC is []"
    
    ## save outputs
    return(list(best=best.iter,                    #saves optimal number of iterations, AUC on training set, AUC on testing set, specificity, sensitivity, and row number as a list
                trainAUC=auc_train,
                testAUC=auc_test,
                spec=spec,
                sen=sen,
                wrow=row))
  }
  
  ## run the function for PCR
  hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="pcr"))
  
  ## get results
  hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
                      sapply(hpars,function(x) x$testAUC),
                      sapply(hpars,function(x) x$spec),
                      sapply(hpars,function(x) x$sen),
                      sapply(hpars,function(x) x$wrow),
                      sapply(hpars,function(x) x$best))
  names(hresults)=c("trainAUC","testAUC",
                    "spec","sen","row","best")
  
  ## combine and save
  hsearch=merge(hresults,hgrid,by="row")
  
  ## save
  hsearch$type="PCR"
  
  ## rerun the function for competence
  hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="competence"))
  
  ## get results
  hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
                      sapply(hpars,function(x) x$testAUC),
                      sapply(hpars,function(x) x$spec),
                      sapply(hpars,function(x) x$sen),
                      sapply(hpars,function(x) x$wrow),
                      sapply(hpars,function(x) x$best))
  names(hresults)=c("trainAUC","testAUC",
                    "spec","sen","row","best")
  
  ## combine and save
  csearch=merge(hresults,hgrid,by="row")
  
  ## assign data type
  csearch$type="competence"
  
  ## combine
  search=rbind.data.frame(csearch,hsearch)
  search$type=factor(search$type,levels=c("PCR","competence"))
  
  ## export
  write.csv(search,"Output/par tuning data summary.csv")
  
}else{
  
  ## load
  search=read.csv("Output/par tuning data summary.csv")
  
}

```

### Model tuning results: Figure S2

```{r brt_tuning_results}

#(1) Convert parameters to factor and relabel values
search$shrinkage=factor(search$shrinkage)
lvl=rev(sort(unique(search$shrinkage)))  #sorts unique shrinkage par from large to small
search$shrinkage=factor(search$shrinkage,levels=lvl); rm(lvl)  #applies as factor
search$interaction.depth=factor(search$interaction.depth)
search$type=plyr::revalue(search$type,    #replace specified values w/ new values
                          c("PCR"="RT-PCR",
                            "competence"="virus isolation"))

#(2) PCR beta regression for AUC
mod=gam(testAUC~interaction.depth*shrinkage,   #gen additive models (gam) w/ integrated smoothness estimation
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

#(3) Competence beta regression for AUC
mod=gam(testAUC~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

#(4) PCR beta regression for sensitivity
mod=gam(sen~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

#(5) Competence beta regression for sensitivity
mod=gam(sen~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)


#(6) PCR beta regression for specificity
mod=gam(spec~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

#(7) Competence beta regression for specificity
mod=gam(spec~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

#(8) Recast from wide to long
search2=gather(search,measure,value,testAUC:sen)

#(9) Relabel values and convert to factor 
search2$measure=plyr::revalue(search2$measure,
                              c("sen"="sensitivity",  
                                "spec"="specificity",
                                "testAUC"="test AUC"))
search2$measure=factor(search2$measure,
                       levels=c("test AUC","sensitivity","specificity"))

#(10) Visualize - Figure S2
png("Output/Figure S2.png",width=5,height=8,units="in",res=600)
set.seed(1)
ggplot(search2,aes(shrinkage,value,
                   colour=interaction.depth,fill=interaction.depth))+
  geom_boxplot(alpha=0.25)+
  geom_point(alpha=0.75,
             position = position_jitterdodge(dodge.width=0.75))+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  facet_grid(measure~type,scales="free_y",switch="y")+
  theme(strip.placement="outside",
        strip.background=element_blank())+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        strip.text=element_text(size=12))+
  theme(legend.position="top")+
  scale_color_brewer(palette="Pastel2")+
  scale_fill_brewer(palette="Pastel2")+
  guides(colour=guide_legend(title="interaction depth"),
         fill=guide_legend(title="interaction depth"))+
  labs(y=NULL,
       x="learning rate")+
  scale_y_continuous(n.breaks=4)
dev.off()

#(11) To determine optimal parameters for model training, subset tuning results by number of trees
search_nt5000 <- search[search$n.trees==5000,]
search_nt15000 <- search[search$n.trees==15000,]
search_nt5000_sh0.01 <- search_nt5000[search_nt5000$shrinkage==0.010,]  #subset models with shrinkage==0.010

#(12) Plot best.iter by type (pcr/competence) to see max number of trees to include
search_nt5000 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt15000 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt5000_sh0.01 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 

#(13) Clean
rm(search,search2,hok,mod,search_nt5000,search_nt15000,search_nt5000_sh0.01)

```

### BRT function for applying across multiple data partitions

```{r brt_partition}

#(1) BRT function to use different data partitions
brt_part=function(seed,response){
  
  ## make new data
  ndata=set
  
  ## correct response
  ndata$response=ndata[response][,1]
  
  ## remove raw
  ndata$pcr=NULL
  ndata$competence=NULL
  
  ## fix cites if response
  if(response=="cites"){
    
    ## plus 1 for 0
    ndata$cites=ifelse(ndata$cites==0,1,ndata$cites)
    
  }else{
    
    ndata=ndata
    
  }
  
  ## use rsample to split
  set.seed(seed)
  split=initial_split(ndata,prop=0.7,strata="response")
  
  ## test and train
  dataTrain=training(split)
  dataTest=testing(split)
  
  ## yTest and yTrain
  yTrain=dataTrain$response
  yTest=dataTest$response
  
  ## dist
  dist=ifelse(response=="cites","poisson","bernoulli")
  
  ## n.trees
  nt=ifelse(response=="cites",10000,
     ifelse(response=="pcr",4500,5000)) #see plots of best.iter 
  
  ## BRT
  set.seed(1)
  gbmOut=gbm(response ~ . ,data=dataTrain,
             n.trees=nt,
             distribution=dist,
             shrinkage=0.01, #see plots of best.iter 
             interaction.depth=3,
             n.minobsinnode=4,
             cv.folds=5,class.stratify.cv=TRUE,
             bag.fraction=0.5,train.fraction=1,
             n.cores=5,
             verbose=F)
            # par.details=(gbmParallel(num_threads=5)),

  ## performance
  par(mfrow=c(1,1),mar=c(4,4,1,1))                         
  best.iter=gbm.perf(gbmOut,method="cv")  #estimates optimal number of boosting iterations for a gbm object                 
  
  ## predict with test data
  preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")
  
  ## known
  result=dataTest$response
  
  ## sensitivity and specificity
  sen=InformationValue::sensitivity(result,preds)
  spec=InformationValue::specificity(result,preds)
  
  ## AUC on train
  auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))
  
  ## AUC on test
  auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
  
  ## skip if poisson
  if(response=="cites"){
    
    perf=NA
    
  }else{
    
    ## inner loop if yTest is all 0
    if(var(yTest)==0){
      
      perf=NA
    }else{
      
      ## ROC
      pr=prediction(preds,dataTest$response)                     
      perf=performance(pr,measure="tpr",x.measure="fpr")         #pr=prediction object; measure=performance measure for evaluation; x.measure=second perf measure (2-D)
      perf=data.frame(perf@x.values,perf@y.values)
      names(perf)=c("fpr","tpr")
      
      ## add seed
      perf$seed=seed
      
    }
  }
  
  ## relative importance
  bars=summary(gbmOut,n.trees=best.iter,plotit=F)
  bars$rel.inf=round(bars$rel.inf,2)

  ## predict with cites
  preds=predict(gbmOut,data,n.trees=best.iter,type="response")
  #pred_data=data[c("gtip",'treename',"fam","ord","pcr","competence")]
  pred_data=data[c("virus","gtip",'treename',"fam","ord","pcr","competence")]
  pred_data$pred=preds
  pred_data$type=response
  
  ## predict with mean cites
  pdata=data
  pdata$cites=mean(pdata$cites)
  pred_data$cpred=predict(gbmOut,pdata,n.trees=best.iter,type="response")
  
  ## sort
  pred_data=pred_data[order(pred_data$pred,decreasing=T),]
  
  ## print
  print(paste("BRT ",seed," done; test AUC = ",auc_test,sep=""))
  
  ## save outputs
  return(list(mod=gbmOut,
              best=best.iter,
              trainAUC=auc_train,
              testAUC=auc_test,
              spec=spec,
              sen=sen,
              roc=perf,
              rinf=bars,
              predict=pred_data,
              traindata=dataTrain,
              testdata=dataTest,
              seed=seed))
}

```

### Apply BRT function across 100 partitions to generate ensemble

```{r brt_ensemble}

#(1) apply across 100 splits each
# smax=101
smax=100
pcr_brts=lapply(1:smax,function(x) brt_part(seed=x,response="pcr"))
comp_brts=lapply(1:smax,function(x) brt_part(seed=x,response="competence"))

#(2) run wos brts
pm_brts=lapply(1:(smax-1),function(x) brt_part(seed=x,response="cites"))

#(3) save results to wd
save(pcr_brts,comp_brts,pm_brts,file="Output/LinkData_results.RData")

```

# 4. BRT Figures

### Load required packages and set system

```{r perf_load}

#(1) Libraries for BRT figures
library(tidyr)
library(ggplot2)
library(sciplot)
library(fastDummies)
library(caper)
library(ape)
library(phylofactor)
library(treeio)
library(ggtree)
library(plotrix)
library(rstatix)
library(ggrepel)
library(ggpubr)
library(plyr)

#(2) Clean environment
rm(list=ls()) 
graphics.off()

```

### Evaluate performance measures: 
How accurately did infection and competence BRT models distinguish OPV positive and negative species?

```{r perf_auc}

#### If needed, increase vector memory in R environment and reboot R before proceeding (https://stackoverflow.com/questions/51295402/r-on-macos-error-vector-memory-exhausted-limit-reached)

#(1) Load data
load("Output/LinkData_results.RData")

#(2) Index non-missing
pcr_keep=which(!is.na(sapply(pcr_brts,function(x) x$testAUC)))
comp_keep=which(!is.na(sapply(comp_brts,function(x) x$testAUC)))

#(3) All
keep=intersect(pcr_keep,comp_keep)

#(4) Trim
pcr_brts=pcr_brts[keep]
comp_brts=comp_brts[keep]

#(5) Get net AUC
mean(c(sapply(pcr_brts,function(x) x$testAUC),sapply(comp_brts,function(x) x$testAUC)))
se(c(sapply(pcr_brts,function(x) x$testAUC),sapply(comp_brts,function(x) x$testAUC)))

#(6) Get net sensitivity
mean(c(sapply(pcr_brts,function(x) x$sen),sapply(comp_brts,function(x) x$sen)))
se(c(sapply(pcr_brts,function(x) x$sen),sapply(comp_brts,function(x) x$sen)))

#(7) Get net specificity
mean(c(sapply(pcr_brts,function(x) x$spec),sapply(comp_brts,function(x) x$spec)))
se(c(sapply(pcr_brts,function(x) x$spec),sapply(comp_brts,function(x) x$spec)))

#(8) Get net AUC for cites
mean(sapply(pm_brts,function(x) x$testAUC))
se(sapply(pm_brts,function(x) x$testAUC))

#(9) Clean environment
rm(pm_brts)

#(10) Get independent AUC for PCR and comp
mean(sapply(pcr_brts,function(x) x$testAUC))
se(sapply(pcr_brts,function(x) x$testAUC))
mean(sapply(comp_brts,function(x) x$testAUC))
se(sapply(comp_brts,function(x) x$testAUC))

```

# 5. Mapping Host Distributions
To be continued...


