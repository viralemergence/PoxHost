---
title: "Orthopoxvirus Host-Trait Model Code"
author: "Katie Tseng, Dan Becker, Colin Carlson, Pilar Fernandez, and Stephanie Seifer"
output:
  pdf_document:
  latex_engine: xelatex
  toc: yes
html_document:
  fig_height: 6
  fig_width: 6
  highlight: tango
  theme: journal
editor_options: 
  chunk_output_type: console
---

Introduction
============  

The following code reproduces the analyses from <...>, pertaining to the host-trait model - the model trained on host traits alone based on two evidence types: PCR positivity vs. virus isolation. Please note that these models in the code are referred to as the infection vs. competence models, but in the manuscript, are referred to as the exposure vs. susceptible model, respectively.  The code is subdivided into three parts (see Table of Contents below). To reproduce the analyses pertaining to the link prediction model, please see the markdown file *LinkPrediction_Code.Rmd* located in the [PoxHost repository][1].

Before running the following script, download the following data file to your working directory: *~/data/hosttrait_rawdata.RData* (the raw data file) 

[1]: <https://github.com/viralemergence/PoxHost> "PoxHost"

Table of Contents
=================

1. Data Preparation {r prep}

2. Phylogenetic Analysis {r phylo}

3. BRT Model {r brt}

### *Before proceeding, we recommend setting knit options* and your working directory**

```{r knitr}

knitr::opts_chunk$set(eval=F)

```

1. Data Preparation
===================

### *Load required packages and set system*

```{r prep_load}

# Libraries for preparing data for analysis
library(ape)
library(dplyr)
library(nlme)
library(tidyverse)
library(stringr)
library(vroom) 
## treespace dependencies include XQuartz v2.7.11 (https://www.xquartz.org/releases/XQuartz-2.7.11.html) and 'rgl' (https://stackoverflow.com/a/66127391/2554330)
library(rgl) # >install.packages("rgl"); >options(rgl.useNULL=TRUE)
library(treespace) 

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("/Users/katietseng/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost")

```

### *Load raw data*

```{r prep_raw}

# Load raw data
load("data/hosttrait_rawdata.RData")

# Pox data: host-OPV interactions detected via PCR/isolation from Virion database
##virion <- vroom('https://github.com/viralemergence/virion/blob/main/Virion/Virion.csv.gz')
poxdata <- virion %>% filter(VirusGenus == "orthopoxvirus" & (DetectionMethod %in% c("PCR/Sequencing","Isolation/Observation"))) 

# Taxa: mammal species taxonomy from vertlife
##vertlife <- read.csv(url('https://data.vertlife.org/mammaltree/taxonomy_mamPhy_5911species.csv'))
taxa <- vertlife

# Host traits: mammal traits from the COMBINE database <https://doi.org/10.1002/ecy.3344>
##path: ecy3344-sup-0001-datas1.zip > COMBINE_archives > trait_data_imputed.csv)
hostTraits <- combine

# Host tree: mammal phylogeny tree from Dryad, <https://doi.org/10.5061/dryad.tb03d03>
##path: Data_S8_finalFigureFiles > _DATA > MamPhy_fullPosterior_BDvr_Completed_5911sp_topoCons_NDexp_MCC_v2_target.tre)
hostTree <- dryad

# Clean environment
rm(virion, vertlife, dryad, combine)

```

### *Prepare poxdata, aggregating host-virus interactions to the genus-level*  
We collapse our dataframe of host-virus interactions to the host genus-level. For each unique host genus-virus interaction, we create binary variables for whether detection of OPV occurred via PCR or virus isolation (competence) and save as a numeric variable the number of studies for which evidence of OPV detection exists.

```{r prep_poxdata}

# Exclude if host genus
poxdata <- poxdata[!is.na(poxdata$HostGenus),]

# Exclude if virus is NA
poxdata <- poxdata[!is.na(poxdata$Virus),]

# Exclude variola (smallpox) virus
poxdata <- poxdata[!(poxdata$Virus=="variola virus"),]

# Extract PCR-positive df 
pcr <- subset(poxdata[which(poxdata$DetectionMethod=="PCR/Sequencing"),], select=c("Host","HostGenus","Virus"))

# Where species name is NA, replace with "sp."
pcr$Host <- ifelse(is.na(pcr$Host),"sp.",pcr$Host)

# Collapse dataframe to species level, summing the number of observations
pcr$pcr <- 1
pcr <- aggregate(.~Host+HostGenus+Virus, data=pcr, sum)

# Extract virus isolation data 
competence <- subset(poxdata[which(poxdata$DetectionMethod=="Isolation/Observation"),], select=c("Host","HostGenus","Virus"))

# Where species name is NA, replace with "sp."
competence$Host <- ifelse(is.na(competence$Host),"sp.",competence$Host)

# Collapse dataframe to species level, summing the number of observations
competence$competence <- 1
competence <- aggregate(.~Host+HostGenus+Virus, data=competence, sum)

# Merge PCR and competence data
poxdata <- merge(pcr, competence, by=c("Host","HostGenus","Virus"), all=TRUE)

# Create studies variable, summing the number of studies identifying pcr-positive and competent hosts
poxdata$studies <- ifelse(is.na(poxdata$pcr),0,poxdata$pcr) + ifelse(is.na(poxdata$competence),0,poxdata$competence)

# Create binary variables for whether OPV was detected via PCR or competence/virus isolation
poxdata$pcr=ifelse(is.na(poxdata$pcr),0,1)
poxdata$competence=ifelse(is.na(poxdata$competence),0,1)

# Extract binary PCR data for every unique host genus and virus pair in poxdata, classifying a pair as PCR-positive if ANY species within the genus was PCR-positive
bin_pcr <- aggregate(pcr~HostGenus+Virus, data=poxdata, max)

# Extract binary competence data for every unique host genus and virus pair in poxdata, classifying a pair as competent if virus isolation was confirmed for ANY species within the genus.
bin_competence <- aggregate(competence~HostGenus+Virus, data=poxdata, max)

# Extract studies data, summing the number of studies for every unique host genus and virus pair in poxdata
sum_studies <- aggregate(studies~HostGenus+Virus, data=poxdata, sum)

# Merge variables of binary PCR, binary competence and studies
poxdata <- merge(bin_pcr,bin_competence)
poxdata <- merge(poxdata,sum_studies)

# Rename and reformat variables
poxdata <- plyr::rename(poxdata,c('HostGenus'='gen','Virus'='virus'))
poxdata$gen <- str_to_title(poxdata$gen)

# Clean environment
rm(pcr,competence,bin_pcr, bin_competence, sum_studies)

```

### *Merge poxdata with broader mammal taxa to create pseudoabsences*
To allow for out-of-sample predictions, we merge our dataset of known host-virus interactions with the broader mammal taxa from Vertlife to create pseudoabsences. We only keep host genera belonging to orders with known interactions. We also use this opportunity to match the taxonomic names in poxdata to those of the mammal taxonomy from Vertlife.

```{r prep_pseudo}

# Drop duplicate genera in taxa 
gtaxa <- taxa[!duplicated(taxa$gen),]

# Subset only the variables we need from taxa: genus, family, and order
gtaxa <- gtaxa[c('gen','fam','ord')]

# Check for mismatched names between mammal taxa and poxdata
poxdata$gen[!poxdata$gen %in% taxa$gen]

# Merge poxdata with taxa
poxdata <- merge(gtaxa,poxdata,by='gen',all.x=TRUE)

# Keep only genera if they belong to an order with a known interaction, by first subsetting known interactions
keep <- subset(poxdata, pcr==1 | competence==1)

# Denote whether an order in poxdata has a known OPV interaction
poxdata$keep <- ifelse(poxdata$ord %in% keep$ord,TRUE,FALSE)

# Only keep orders (and their associated genera) with a known interaction
poxdata <- subset(poxdata,keep==TRUE)
poxdata$keep=NULL

# Create binary variable for sampled host-OPV pairs
poxdata$sampled=ifelse(is.na(poxdata$pcr) & is.na(poxdata$competence),0,1)

# Calculate the number of pseudoabsences
length(which(is.na(poxdata$virus)))

# Reclassify NAs as pseudo-absences for viral detection
poxdata$pcr=ifelse(is.na(poxdata$pcr),0,poxdata$pcr)
poxdata$competence=ifelse(is.na(poxdata$competence),0,poxdata$competence)
poxdata$studies=ifelse(is.na(poxdata$studies),0,poxdata$studies)

# Replace any potential NA taxonomic values with taxa data based on host genera
poxdata=merge(poxdata,gtaxa,by='gen',all.x=TRUE)
poxdata <- plyr::rename(poxdata,c('fam.y'='fam','ord.y'='ord'))
poxdata$fam.x=NULL
poxdata$ord.x=NULL

# Clean environment
rm(taxa,gtaxa,keep)

```

### *Collapse hostTraits to genus-level*
In preparation of merging host traits with our poxdata, we collapse species-level observations to the genus-level using summary measures. For continuous and integer variables, we take the median. For binary variables, we take the mean as a measure of the proportion of species in a genus having the variable outcome or trait. For categorical variables, we transform the variables into multiple binary variables and then take the mean.

```{r prep_traits}

# Observe variable names
colnames(hostTraits)

# To aggregate continuous/integer variables, use the median as the summary measure
hostTraits_continuous=aggregate(cbind(adult_mass_g,brain_mass_g,adult_body_length_mm,adult_forearm_length_mm,
                                   max_longevity_d,maturity_d,female_maturity_d,male_maturity_d,
                                   age_first_reproduction_d,gestation_length_d,teat_number_n,
                                   litter_size_n,litters_per_year_n,interbirth_interval_d,
                                   neonate_mass_g,weaning_age_d,weaning_mass_g,generation_length_d,
                                   dispersal_km,density_n_km2,home_range_km2,social_group_n,
                                   dphy_invertebrate,dphy_vertebrate,dphy_plant,
                                   det_inv,det_vend,det_vect,det_vfish,det_vunk,det_scav,det_fruit,det_nect,det_seed,det_plantother,det_diet_breadth_n,
                                   upper_elevation_m,lower_elevation_m,altitude_breadth_m,habitat_breadth_n) 
                             ~ order+family+genus, data=hostTraits, FUN=median, na.action=na.pass, na.rm=TRUE)
##'na.action=na.pass, na.rm=TRUE' is specified such that if species w/in a genus has a combination of real values & NAs, the median of real values will be returned (as opposed to omitting the genus or returning NA)

# To aggregate binary variables, use the mean as the summary measure
hostTraits$fossoriality[hostTraits$fossoriality==2]<-0  #recode 0/1
hostTraits_binary=aggregate(cbind(hibernation_torpor,fossoriality,freshwater,marine,terrestrial_non.volant,terrestrial_volant,
                               island_dwelling,disected_by_mountains,glaciation) ~ order+family+genus, data=hostTraits, FUN=mean, na.action=na.pass, na.rm=TRUE)

# To aggregate categorical variables, first transform the variables to binary
hostTraits_cat <- hostTraits

unique(hostTraits_cat$trophic_level)
hostTraits_cat$trophic_herbivores <- ifelse(hostTraits_cat$trophic_level==1,1,0)
hostTraits_cat$trophic_omnivores <- ifelse(hostTraits_cat$trophic_level==2,1,0)
hostTraits_cat$trophic_carnivores <- ifelse(hostTraits_cat$trophic_level==3,1,0)

unique(hostTraits_cat$activity_cycle)
hostTraits_cat$activity_nocturnal <- ifelse(hostTraits_cat$activity_cycle==1,1,0)
hostTraits_cat$activity_crepuscular <- ifelse(hostTraits_cat$activity_cycle==2,1,0)
hostTraits_cat$activity_diurnal <- ifelse(hostTraits_cat$activity_cycle==3,1,0)

unique(hostTraits_cat$foraging_stratum)
hostTraits_cat$forager_marine <- ifelse(hostTraits_cat$foraging_stratum=="M",1,0)
hostTraits_cat$forager_ground <- ifelse(hostTraits_cat$foraging_stratum=="G",1,0) 
hostTraits_cat$forager_scansorial <- ifelse(hostTraits_cat$foraging_stratum=="S",1,0)
hostTraits_cat$forager_arboreal <- ifelse(hostTraits_cat$foraging_stratum=="Ar",1,0)
hostTraits_cat$forager_aerial <- ifelse(hostTraits_cat$foraging_stratum=="A",1,0)

unique(hostTraits_cat$island_endemicity)
hostTraits_cat$island_end_marine <- ifelse(hostTraits_cat$island_endemicity=="Exclusively marine",1,0)
hostTraits_cat$island_end_mainland <- ifelse(hostTraits_cat$island_endemicity=="Occurs on mainland",1,0)
hostTraits_cat$island_end_lgbridge <- ifelse(hostTraits_cat$island_endemicity=="Occurs on large land bridge islands",1,0)
hostTraits_cat$island_end_isolated <- ifelse(hostTraits_cat$island_endemicity=="Occurs only on isolated islands",1,0)

unique(hostTraits_cat$biogeographical_realm)
hostTraits_cat$biogeo_afrotropical <- ifelse(grepl("Afrotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_antarctic <- ifelse(grepl("Antarctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_australasian <- ifelse(grepl("Australasian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_indomalayan <- ifelse(grepl("Indomalayan",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_nearctic <- ifelse(grepl("Nearctic",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_neotropical <- ifelse(grepl("Neotropical",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_oceanian <- ifelse(grepl("Oceanian",hostTraits_cat$biogeographical_realm),1,0)
hostTraits_cat$biogeo_palearctic <- ifelse(grepl("Palearctic",hostTraits_cat$biogeographical_realm),1,0)

# To aggregate transformed categorical-to-binary variables, use the mean as the summary measure
hostTraits_cat=aggregate(cbind(trophic_herbivores,trophic_omnivores,trophic_carnivores,
                            activity_nocturnal,activity_crepuscular,activity_diurnal,
                            forager_marine,forager_ground,forager_scansorial,forager_arboreal,forager_aerial,
                            island_end_marine,island_end_mainland,island_end_lgbridge,island_end_isolated,
                            biogeo_afrotropical,biogeo_antarctic,biogeo_australasian,biogeo_indomalayan,biogeo_nearctic,biogeo_neotropical,biogeo_oceanian,biogeo_palearctic)
                       ~ order+family+genus, data=hostTraits_cat, FUN=mean, na.action=na.pass, na.rm=TRUE)

# Merge continuous variables with binary variables
hostTraits <- full_join(hostTraits_continuous, hostTraits_binary, by = c("order","family","genus"),keep=TRUE)

# Rename variables and keep only those needed
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits=subset(hostTraits, select=-c(order.y,family.y,genus.y))

# Merge transformed categorical variables
hostTraits <- full_join(hostTraits, hostTraits_cat, by = c("order","family","genus"),keep=TRUE)

# Rename variables and keep only those needed
hostTraits <- plyr::rename(hostTraits,c('order.x'='order','family.x'='family','genus.x'='genus'))
hostTraits <- subset(hostTraits, select=-c(order.y,family.y,genus.y))

# Clean environment
rm(hostTraits_binary,hostTraits_cat,hostTraits_continuous)

```

### *Trim hostTree to genus-level*
In preparation of trimming the host tree to mirror our poxdata, we trim the tree tips to the genus-level.

```{r prep_tree}

# Relabel 
hostTree$tip.label[hostTree$tip.label=="_Anolis_carolinensis"] <- "Anolis_carolinensis"

# Create dataframe of the species and genus represented in our mammal tree (based on tip label)
tdata <- data.frame(matrix(NA,nrow=length(hostTree$tip.label),ncol=0))
tdata$genus <- sapply(strsplit(hostTree$tip.label,'_'),function(x) paste(x[1],sep='_'))
tdata$species <- hostTree$tip.label

# Collapse tree to genus level
hostTree <- makeCollapsedTree(tree=hostTree,df=tdata[c('genus','species')])

# Clean environment
rm(tdata)

```

### *Check for mismatched genera names in poxdata, hostTraits and hostTree*

```{r prep_names}

# Check if all poxdata genera are in hostTree
poxdata$gtip <- poxdata$gen
hostTree$gtip <- hostTree$tip.label
poxdata$intree <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTree$gtip),'missing','upham')

# Check if all poxdata genera are in hostTraits
hostTraits$gtip <- hostTraits$genus
poxdata$intraits <- ifelse(poxdata$gtip%in%setdiff(poxdata$gtip,hostTraits$gtip),'missing','traits')

# Create a dataframe of just the observations with mismatched names
fix <- poxdata[c('gtip','intree','intraits')]
fix <- fix[fix$intree=='missing'|fix$intraits=='missing',]
fix <- unique(fix)

# For those with mismatched names, identify homotypic synonyms or proxy species via IUCN (https://www.iucnredlist.org/) and NCBI (http://www.ncbi.nlm.nih.gov/taxonomy)
fix$treename <- NA
fix$traitname <- NA
fix$proxy <- NA
fix$proxy <- ifelse(fix$gtip=="Calassomys","Delomys",fix$proxy)
  ##source: https://academic.oup.com/jmammal/article/95/2/201/860032
fix$traitname <- ifelse(fix$gtip=="Liomys","Heteromys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Oreonax","Lagothrix",fix$traitname)
  ##source: https://www.iucnredlist.org/species/39924/192307818
fix$traitname <- ifelse(fix$gtip=="Paralomys","Phyllotis",fix$traitname)
  ##source: https://www.iucnredlist.org/species/17226/22333354
fix$traitname <- ifelse(fix$gtip=="Pearsonomys","Geoxus",fix$traitname)
  ##source: https://www.iucnredlist.org/species/40768/22345036
fix$traitname <- ifelse(fix$gtip=="Pipanacoctomys","Tympanoctomys",fix$traitname)
  ##source: https://www.iucnredlist.org/species/136557/78324400#taxonomy
fix$traitname <- ifelse(fix$gtip=="Pseudalopex","Lycalopex",fix$traitname)
  ##source: https://www.iucnredlist.org/species/6926/87695615
## hostTraits$genus[which(grepl('Tympanoctomys',hostTraits$genus))]

# Merge revised names with poxdata
fix <- subset(fix, select=-c(intree,intraits))
poxdata <- merge(poxdata,fix,by='gtip',all.x=T)

# If 'treename' is missing, first relabel as NA, then relabel with 'gtip'
poxdata$treename <- ifelse(poxdata$treename=='',NA,as.character(poxdata$treename))
poxdata$treename <- ifelse(is.na(poxdata$treename),as.character(poxdata$gtip),as.character(poxdata$treename))

# If 'traitname' is missing, first relabel as NA; If 'traitname' is NA and missing in 'intraits', then relabel with 'proxy'; If 'traitname' is not NA and missing in 'intraits', then relabel with 'traitname'
poxdata$traitname <- ifelse(poxdata$traitname=='',NA,as.character(poxdata$traitname))
poxdata$traitname <- ifelse(poxdata$intraits=='missing' & is.na(poxdata$traitname),as.character(poxdata$proxy),
                      ifelse(poxdata$intraits=='missing' & !is.na(poxdata$traitname),as.character(poxdata$traitname),
                             as.character(poxdata$gtip)))

# Simplify and clean environment
poxdata <- subset(poxdata, select=-c(intree,intraits,proxy))
rm(fix)

```

### *Merge poxdata with hostTraits and trim hostTree to mirror poxdata*

```{r prep_merge}

# Merge traits with poxdata
hostTraits$traitname <- hostTraits$gtip
poxdata <- merge(poxdata,hostTraits,by=c('traitname'),all.x=T)

# Clean up poxdata
poxdata <- plyr::rename(poxdata,c('gtip.x'='gtip'))
poxdata <- subset(poxdata,select=-c(order, family, genus, gtip.y))

# Trim hostTree to mirror poxdata
hostTree <- keep.tip(hostTree,hostTree$tip.label[hostTree$tip.label%in%poxdata$treename])
hostTree$gtip <- NULL
hostTree=makeLabel(hostTree)

# Clean environment
rm(hostTraits)

```

### *Add PubMed citations and evolutionary distinctiveness measure*
We add two additional predictors to our model: (1) the number of PubMed citations per genus as a proxy for sampling effort, and (2) the evolutionary distinctiveness.

```{r prep_cites_ed}

# Load library for PubMed citations
library(easyPubMed)

# Create function to count citations
counter=function(name){
  as.numeric(as.character(get_pubmed_ids(gsub('_','-',name))$Count))
}
citations=c()

# Extract unique genera from poxdata
treename <- unique(poxdata$treename)

# Apply 'counter' function while looping through treenames
for(i in 1:length(treename)) {
  citations[i]=counter(treename[i])
  print(i)
}

# Compile citation numbers in new dataframe
cites <- data.frame(treename=treename,cites=citations)

# Merge cites with poxdata
poxdata <- merge(poxdata,cites,by='treename')

# Load library for evolutionary distinctiveness (ed) measure
library(picante)  #before loading picante, make sure the latest version of the nlme package is loaded
ed <- evol.distinct(hostTree,type='equal.splits') #calculates ed measures for a suite of species by equal splits and fair proportions; returns species score

# Rename variables in ed dataframe
ed <- plyr::rename(ed,c('Species'='treename','w'='ed_equal'))

# Merge ed with poxdata
poxdata <- merge(poxdata,ed,by='treename')

# Clean environment
rm(cites,ed,citations,i,treename,counter)

### Run on June 19, 2023 ###

```

### *Collapse poxdata to genus-level*
Up to this point, each observation has represented a unique host-virus interaction, where some mammal genera are associated (host) with multiple viruses. Here, we drop our 'virus' variable and we collapse our poxdata to the genus-level retaining only unique mammal genera characterized as OPV hosts based on PCR positivity or virus isolation (competence).

```{r prep_genus}

# Remove virus variable
poxdata <- subset(poxdata,select=-c(virus))

# Extract binary PCR data for every unique host genus in poxdata, classifying a genus as PCR positive if they were PCR positive for ANY OPV species.
agg_pcr <- aggregate(pcr~gen, data=poxdata, max)

# Extract binary competence data for every unique host genus in poxdata, classifying a genus as competent if virus isolation was confirmed for ANY OPV species.
agg_competence <- aggregate(competence~gen, data=poxdata, max)

# Extract studies data, summing the number of studies for every unique host genus in poxdata
agg_studies <- aggregate(studies~gen, data=poxdata, sum)

# Drop old variables from poxdata
poxdata$pcr=NULL
poxdata$competence=NULL
poxdata$studies=NULL

# Remove duplicate genera
poxdata <- poxdata[!duplicated(poxdata$gen),]

# merge pcr, competence, and studies data back in
poxdata <- list(poxdata,agg_pcr,agg_competence,agg_studies) %>% reduce(full_join, by='gen')

# Reorder variables
poxdata <- poxdata %>% 
  dplyr::relocate(gen,fam,ord,gtip,treename,traitname,pcr,competence,studies,sampled,cites,ed_equal)

# Clean environment
rm(agg_competence,agg_pcr,agg_studies)

```

### *Save cleaned data*

```{r prep_save}

#Save cleaned data for analysis
save(poxdata, hostTree, file="data/hosttrait_cleandata.RData")

```


2. Phylogenetic Analysis
========================

### *Load required packages and set system*

```{r phylo_load}

# Libraries for phylogenetic analysis
library(ape)
library(caper)
library(data.table)
library(BiocManager)  ## BiocManager::install(c("Biostrings","ggtree"))
library(phylofactor)  ## devtools::install_github('reptalex/phylofactor'); more info at: https://reptalex.github.io/phylofactor/)
library(treeio)       ## BiocManager::install("treeio")
library(ggtree)
library(dplyr)

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("/Users/katietseng/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost")

```

### *Phylogenetic patterns*
We analyze the raw data comparing the proportion of host genera with known infection by evidence type (PCR vs. virus isolation) and exploring the strength of phylogenetic signal in PCR and virus isolation data.

```{r phylo_signal}

# Load data
load("data/hosttrait_cleandata.RData")
data <- poxdata

# Check that genus name in poxdata is also in hostTree
which(data$treename%in%setdiff(data$treename,hostTree$tip.label))

# Create variables label and Species (required in later functions)
data$label <- data$treename
data$Species <- data$treename  

# Merge phylogeny w/ data ensuring consistent structure & ordering using caper package
cdata=comparative.data(phy=hostTree,data=data,names.col=treename,vcv=T,na.omit=F,warn.dropped=T)
cdata$data$tree=NULL

# What proportion of genera have evidence of infection?
nrow(data)
data %>% count(pcr==1)
round(prop.table(table(data$pcr)),4)*100 
data %>% count(competence==1)
round(prop.table(table(data$competence)),4)*100
##values in each cell are divided by the sum of the 4 cells

# Does the raw data display a phylogenetic signal in response?
set.seed(1)
mod1 <- phylo.d(cdata,binvar=pcr,permut=10000); mod1
set.seed(1)
mod2 <- phylo.d(cdata,binvar=competence,permut=10000); mod2
## D of 0 = Brownian model, D of 1 = random (no phylogenetic signal)

```

### *Phylofactorization*
We conduct phylofactorization using phylofactor::gpf and determine the number of phylogenetic factors (aka clades) to retain by creating a function that applies Holm's sequentially rejective 5% cutoff to adjust for the family-wise error rate.

```{r phylo_factor}

# Create dataframe of taxonomy from cdata
cdata$data$taxonomy=paste(cdata$data$ord,cdata$data$fam,cdata$data$gen,sep='; ')
taxonomy <- data.frame(cdata$data$taxonomy)
names(taxonomy) <- "taxonomy"
taxonomy$Species <- rownames(cdata$data)
taxonomy <- taxonomy[c("Species","taxonomy")]

# Create function to apply Holm rejection procedure, where pf=phylofactor and FWER=family-wise error rate (alpha .05)
HolmProcedure <- function(pf,FWER=0.05){        
  ## get split variable
  cs=names(coef(pf$models[[1]]))[-1]       
      ### returns names of model coefficients (var names) extracted by 'coef' in 
      ### the 1st list element of 'pf$models' minus the 1st element among those 
      ### names; double brackets access a list element
  split=ifelse(length(cs)>1,cs[3],cs[1])         
      ### returns 3rd element in 'cs' if length of the number of elements in 
      ### 'cs' >1; else returns 1st element
  
  ## obtain p values
  if (pf$models[[1]]$family$family%in%c('gaussian',"Gamma","quasipoisson")){                  
      ### if fam$fam of 1st list element of pf$models is in columns 'gaussian'...
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|t|)'])  
      ### then to each element of pf$models, apply summary function w/ argument
      ### 'fit' and assign output to 'pvals'; 
      ### specifically, we use 'summary(fit)' to call the output of 'pf$models',
      ### extracting the 'coefficients' section, whereby we index the column 
      ### named 'Pr(>|t\)' and split the data in that column; see sample output 
      ### of linear model of R for reference (https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R) 
  } else {
    pvals <- sapply(pf$models,FUN=function(fit) summary(fit)$coefficients[split,'Pr(>|z|)'])  
      ### else extract p-val based on z statistic
  }
  D <- length(pf$tree$tip.label)                                                              
      ### returns number of elements in pf$tree$tip.label
  
  ## this is the line for Holm's sequentially rejective cutoff, where HB = Target alpha / (n â€“ rank + 1)
  keepers <- pvals<=(FWER/(2*D-3 - 2*(0:(pf$nfactors-1))))                                    
      ### returns TRUE/FALSE if p-values are <= to 0.05/(n-rank+1)
  
  if (!all(keepers)){                            
      ### if not all pvals were keepers (i.e., all items in keepers were true)...
    nfactors <- min(which(!keepers))-1           
      ### then assign nfactors to minimum/earliest position of items in keepers that were false, minus 1.
  } else {
    nfactors <- pf$nfactors                      
      ###:else, assign nfactors as the value of pf$nfactors
  }
  return(nfactors)
}

## get species in a clade
cladeget=function(pf,factor){                        
  ### creates function 'cladeget' w/ arguments 'pf' and 'factor'
  spp=pf$tree$tip.label[pf$groups[[factor]][[1]]]    
    ### returns n'th element of the pf$tree$tip.label based on the value of 
    ### the first component inside the n'th ('factor') component of  'pf$groups'
  return(spp)
}

# Summarize pf (phylofactor) object                               
pfsum=function(pf){                                  
  
  ## get formula
  chars=as.character(pf$frmla.phylo)[-1]  ### returns pf$frmla.phylo minus 1st element
  
  ## response                  
  resp=chars[1]               ###returns 1st element of chars              
  
  ## holm
  hp=HolmProcedure(pf)                      
  
  ## save model
  model=chars[2]                           
  
  ## set key
  setkey(pf$Data,'Species')   ### creates key on sorted pf$Datacolumn 'Species'
  
  ## make data
  dat=data.frame(pf$Data)                            
  
  ## make clade columns in data
  for(i in 1:hp){
    
    dat[,paste0(resp,'_pf',i)]=ifelse(dat$Species%in%cladeget(pf,i),'factor','other')   
    ### paste0 concatenates all elements w/o a separator
    
  }
  
  ## make data frame to store taxa name, response, mean, and other
  results=data.frame(matrix(ncol=6, nrow = hp))                        
  colnames(results)=c('factor','taxa','tips','node',"clade",'other')
  
  ## set taxonomy
  taxonomy=dat[c('Species','taxonomy')]                               
  taxonomy$taxonomy=as.character(taxonomy$taxonomy)
  
  ## loop
  for(i in 1:hp){
    
    ## get taxa
    tx=pf.taxa(pf,taxonomy,factor=i)$group1            #gets taxonomic order
    
    ## get tail
    tx=sapply(strsplit(tx,'; '),function(x) tail(x,1)) #gets tax family as list
    
    ## combine
    tx=paste(tx,collapse=', ')         #collapses tax family into single string
    
    # save
    results[i,'factor']=i         #returns index number in 'factor' column
    results[i,'taxa']=tx          #returns string element (tx) in 'taxa' column
    
    ## get node
    tips=cladeget(pf,i)
    node=ggtree::MRCA(pf$tree,tips)         
    ### MRCA = finds Most Recent Common Ancestor among a vector of tips 
    results[i,'tips']=length(tips)
    results[i,'node']=ifelse(is.null(node) & length(tips)==1,'species',
                             ifelse(is.null(node) & length(tips)!=1,NA,node))
    
    ## get means
    ms=(tapply(dat[,resp],dat[,paste0(resp,'_pf',i)],FUN=mean))   
    ### tapply takes mean of '1 vs. 0' (dat[,resp]) by 'other'/'factor' type (dat[,paste...]
    
    ## add in
    results[i,'clade']=ms['factor']
    results[i,'other']=ms['other']
    
  }
  
  ## return
  return(list(set=dat,results=results))       #returns number of clades with significantly greater propensity of infection adjusting for FWER using Holm rejection procedure
}

# Conduct phylofactorization of infection data
set.seed(1)
pcr_pf=gpf(Data=cdata$data,tree=cdata$phy,
           frmla.phylo=pcr~phylo,
           family=binomial,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize infection PF results
HolmProcedure(pcr_pf)
pcr_pf_results=pfsum(pcr_pf)$results        

# Conduct phylofactorization of competence data
set.seed(1)
hc_pf=gpf(Data=cdata$data,tree=cdata$phy,     
          frmla.phylo=competence~phylo,
          family=binomial,algorithm='phylo',nfactors=2,min.group.size=5)

# Summarize competence PF results
HolmProcedure(hc_pf)
hc_pf_results=pfsum(hc_pf)$results       

```

### *Plot results of phylofactorization*
Figure: *tree_phylofactor_raw.png*

```{r phylo_results}

# Save tree for plotting
cdata$data$infect=factor(cdata$data$pcr)
cdata$data$comp=factor(cdata$data$competence)
dtree=treeio::full_join(as.treedata(cdata$phy),cdata$data,by="label")

# Fix palette for plotting
AlberPalettes <- c("YlGnBu","Reds","BuPu", "PiYG")
AlberColours <- sapply(AlberPalettes, function(a) RColorBrewer::brewer.pal(5, a)[4])
afun=function(x){
  a=AlberColours[1:x]
  return(a)
}

# Make low and high, and set x max
pcols=afun(2)
plus=1
pplus=plus+1

# Fix taxa font formatting
pcr_pf_results$taxa
pcr_pf_results$taxa[1]="Rodentia"
hc_pf_results$taxa
hc_pf_results$taxa[1]="italic(Felidae)"

# Plot PCR positivity w/ ggtree
pcr_gg=ggtree(dtree,size=0.25)+
  geom_tippoint(aes(colour=infect),shape=15)+
  scale_colour_manual(values=c("grey80","black"))+
  guides(colour="none")   

# Add clades (Rodentia) to plot
for(i in 1:nrow(pcr_pf_results)){
  
  pcr_gg=pcr_gg+
    geom_hilight(node=pcr_pf_results$node[i],
                 alpha=0.25,
                 fill=ifelse(pcr_pf_results$clade>
                               pcr_pf_results$other,pcols[2],pcols[1])[i])+
    geom_cladelabel(node=pcr_pf_results$node[i],
                    label=pcr_pf_results$taxa[i],
                    offset=pplus,
                    hjust=0.75,
                    offset.text=pplus*2,
                    parse=T,
                    angle=90)
}
pcr_gg=pcr_gg

# Plot competence w/ ggtree
comp_gg=ggtree(dtree,size=0.25)+
  geom_tippoint(aes(colour=comp),shape=15)+
  scale_colour_manual(values=c("grey80","black"))+
  guides(colour=F)

# Add clades (Felidae) to plot
for(i in 1:nrow(hc_pf_results)){
  
  comp_gg=comp_gg+
    geom_hilight(node=hc_pf_results$node[i],
                 alpha=0.25,
                 fill=ifelse(hc_pf_results$clade>
                               hc_pf_results$other,pcols[2],pcols[1])[i])+
    geom_cladelabel(node=hc_pf_results$node[i],
                    label=hc_pf_results$taxa[i],
                    offset=pplus,
                    hjust=0.75,
                    offset.text=pplus*2,
                    parse=T,
                    angle=90)
}
comp_gg=comp_gg

# Print tree figures for infection and competence
library(ggpubr)
png("figures/additional/hosttrait/tree_phylofactor_raw.png",width=6,height=6,units="in",res=300)
ggarrange(pcr_gg,comp_gg,ncol=2,widths=c(1.2,1),
          labels=c("(a) RT-PCR","(b) virus isolation"),
          label.x=c(-0.1,-0.2),
          font.label=list(face="plain",size=12))
dev.off()

```

### *Additional phylofactorization models*
We conduct phylofactorization again on infection and competence data but using Pubmed citations as a weight variable in the model. Additionally, we conduct phylofactorization on citations themselves.

```{r phylo_cites}

# Create log-transformed variable of pubmed cites
cdata$data$logcites=log1p(cdata$data$cites)

# Conduct phylofactorization on PCR infection data with Pubmed cites as a weight variable
set.seed(1)
pcr_pf_pm=gpf(Data=cdata$data,tree=cdata$phy,
                 frmla.phylo=pcr~phylo,
                 weights=cdata$data$logcites,
                 family=binomial,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize the results
HolmProcedure(pcr_pf_pm)
pcr_pf_pm_results=pfsum(pcr_pf_pm)$results       

# Conduct phylofactorization on competence data with Pubmed cites as a weight variable
set.seed(1)
hc_pf_pm=gpf(Data=cdata$data,tree=cdata$phy,
                frmla.phylo=competence~phylo,
                weights=cdata$data$logcites,
                family=binomial,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize the results
HolmProcedure(hc_pf_pm)
hc_pf_pm_results=pfsum(hc_pf_pm)$results       

# Conduct phylofactorization on Pubmed cites themselves (where cites is not log1pm-transformed)
set.seed(1)
pm_pf=gpf(Data=cdata$data,tree=cdata$phy,
             frmla.phylo=cites~phylo,
             family=poisson,algorithm='phylo',nfactors=10,min.group.size=5)

# Summarize the results
HolmProcedure(pm_pf)
pm_pf_results=pfsum(pm_pf)$results

```


3. BRT Model
============
This chapter builds boosted regression tree models trained on infection and competence data to predict mammal hosts of Orthopoxviruses. An example of how to run this section's code on a high performance computing cluster (HPC) is available on the GitHub PoxHost repository: https://github.com/viralemergence/PoxHost/tree/0a1effef83dbd5f6f3d88c6d0c15c563eb499452/Tseng2022/HPC%20Example_01Jun2023.

### *Load required packages and set system*

```{r brt_load}

# Libraries for BRT model
library(gbm)
library(fastDummies)
library(rsample)
library(ROCR)
library(sciplot)
library(ggplot2)
library(pdp)
library(PresenceAbsence)
library(tidyr)
library(viridis)
library(caper)
# library(phylofactor)
library(ggtree)
library(treeio)
library(caret) 
library(InformationValue)
library(mgcv) #for beta regression on performance metrics

# Clean environment
rm(list=ls()) 
graphics.off()

# Set working directory
setwd("/Users/katietseng/Library/CloudStorage/OneDrive-WashingtonStateUniversity(email.wsu.edu)/Fernandez Lab/Projects (Active)/OPV Host Prediction/GitHub/PoxHost")

```

### *Create variables of taxonomic family as predictors for the model*

```{r brt_taxo}

# Load data and clean environment
load("data/hosttrait_cleandata.RData")
data <- poxdata
rm(poxdata)

# Classify true negatives
data$type=ifelse(data$pcr==0 & data$competence==0,"true negative","other")

# Which species is competent but not PCR positive?
set=data
set$treename[set$pcr==0 & set$competence==1]

# Tabulate PCR/infection and isolation
set$inf=ifelse(set$pcr==0,"PCR negative","PCR positive")
set$iso=ifelse(set$competence==0,"no isolation","isolation")
table(set$inf,set$iso)

# Make binary variables for each taxonomic family; remove any duplicates
dums=dummy_cols(data["fam"])
dums=dums[!duplicated(dums$fam),]

# Ensure all family vars are factor
for(i in 1:ncol(dums)){
  dums[,i]=factor(dums[,i])
}

# Merge family taxa variables with dataset as predictors
data=merge(data,dums,by="fam",all.x=T)

# Drop unnecessary columns and clean environment
data$traitname=NULL
rm(dums,set,i)

```

### *Assess variation and availability of data*
We explore the variation and availability of our data and drop variables if more than 30% of observations are missing/NA. We ask, are there zero or near-zero variance predictors? And what is the distribution of coverage among our traits?
Figure: *histogram_trait_coverage.png*
Table: *table_trait_coverage.csv*

```{r brt_var}

# Create mode function where for each variable, we extract the frequency of the most frequently occurring value for that variable and divide it by the number of non-NA elements in that variable
mode.prop <- function(x) {                
  ux <- unique(x[is.na(x)==FALSE])        # creates array of unique values
  tab <- tabulate(match(na.omit(x), ux))  # creates array of the frequency (number of times) a unique value appears in a column 
  max(tab)/length(x[is.na(x)==FALSE])     # max-frequency / number of elements in each column that are not NA
}

# Assess variation across columns (2 indicates columns)
vars=data.frame(apply(data,2,function(x) mode.prop(x)),
                apply(data,2,function(x) length(unique(x))))    # number of unique elements in each column

# Get names
vars$variables=rownames(vars)
names(vars)=c("var","uniq","column")

# # Round values
# vars$var=round(vars$var,2)

# Label variables "cut" if homogeneous (100%)
vars$keep=ifelse(vars$var<1,"keep","cut")
vars$keep=ifelse(vars$column%in%c('fam','virus','gen','pcr','competence','fam'),'keep',vars$keep) # ensures we keep these columns
vars=vars[order(vars$keep),]

# Trim (creates array of column names to cut and removes from df)
keeps=vars[-which(vars$keep=="cut"),]$column

# Drop if no variation
data=data[keeps]
rm(keeps,vars)

# Assess missing values
mval=data.frame(apply(data,2,function(x) length(x[!is.na(x)])/nrow(data))) # proportion of values that are not NA

# Get names
mval$variables=rownames(mval)
names(mval)=c("comp","column")

# Exclude observations of non-predictor variables from mval dataframe
mval_hist <- mval[-(1:9),]
nrow(mval_hist)

# Plot frequency distribution of coverage among 185 traits
png("figures/supplementary/s9fig_histogram_trait_coverage.png", width=4,height=4,units="in",res=600)
ggplot(mval_hist[!mval_hist$column%in%c("gen","treename","pcr","competence","tip.label","fam"),],
       aes(comp))+
  geom_histogram(bins=50)+
  geom_vline(xintercept=0.60,linetype=2,linewidth=0.5)+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  labs(y="Frequency",
       x="Trait coverage across mammal genera")+
  scale_x_continuous(labels = scales::percent)
dev.off()

# Label variables "cut" if >40% values are NA
mval$keep=ifelse(mval$comp>=0.60,"keep","cut")
table(mval$keep)
mval=mval[order(mval$keep),]

# Trim (creates array of column names to cut and removes from df)
keeps=mval[-which(mval$keep=="cut"),]$column

# Drop if not well represented
data=data[keeps]

# Subset data to include only predictor and response variables
set <- subset(data,select=-c(gen,fam,ord,gtip,treename,type,studies,sampled))
## this dataframe will also be used in the next code block

# Create dataframe of trait coverage
table1=data.frame(apply(set,2,function(x) length(x[!is.na(x)])/nrow(set)))
## apply(X, MARGIN,...): "2" indicates applying the function over columns (as opposed to "1")

# Generate 'variable' column from rownames
table1$variables=rownames(table1)

# Rename columns and drop rownames
names(table1)=c("Coverage","Feature")
rownames(table1)=NULL

# Drop predictor variables from list
table1=table1[!table1$Feature%in%c("pcr","competence"),]
table1 <- subset(table1,select=c(Feature,Coverage))

# Output table of trait coverage
write.csv(table1, "figures/other/hosttrait/table_trait_coverage.csv")

# # If running on HPC, save table to Output folder
# write.csv(table1, "Output/table_trait_coverage.csv")

# Check that binary variables are numeric and not factor (with the exception of fam_* variables)
str(set)

# Clean environment
rm(keeps,mval,mval_hist,table1)

```

### Tuning to asses model performance for each combination of tuning parameters
We create a hyperparamter 'grid' that represents different combinations of parameter values to which we tune the model.
Table: *par_tuning_data_summary.csv*

```{r brt_tuning}

# Hyperparameter tuning ifelse
#hok="ok"
hok="notok"
if(hok!="ok"){
  
  ## hyperparameter grid
  hgrid=expand.grid(n.trees=5000,   #creates df from all combinations of factor vars (1*3*3*1*10=90 obs & 5 vars)
                    interaction.depth=c(2,3,4),
                    shrinkage=c(0.01,0.001,0.0005),
                    n.minobsinnode=4,
                    seed=seq(1,10,by=1))

  # fix trees
  hgrid$n.trees=ifelse(hgrid$shrinkage<0.001,hgrid$n.trees*3,hgrid$n.trees)
  
  ## trees, depth, shrink, min, prop 
  hgrid$id=with(hgrid,paste(n.trees,interaction.depth,shrinkage,n.minobsinnode))   #creates var 'id' concatenating values from each of the specified columns in hgrid
  
  ## sort by id then seed
  hgrid=hgrid[order(hgrid$id,hgrid$seed),]
  
  ## now add rows
  hgrid$row=1:nrow(hgrid)                                        #adds var 'row' based on row number in hgrid
  
  ## factor id
  hgrid$id2=factor(as.numeric(factor(hgrid$id)))                 #creates 9-level factor var 'id2' 
  
  ## function to assess each hyperpar combination
  hfit=function(row,response){
    
    ## make new data
    ndata=set
    
    ## correct response
    ndata$response=ndata[response][,1]                           #creates var 'response'
    
    ## remove raw
    ndata$pcr=NULL
    ndata$competence=NULL
    
    ## use rsample to split
    set.seed(hgrid$seed[row])                                    #sets seed value of 1-10
    split=initial_split(ndata,prop=0.7,strata="response")        #creates single binary split of data into training set and testing set, where 70% of data is retained for modeling/analysis and resampling is created within the 'response' var
    
    ## test and train
    dataTrain=training(split)
    dataTest=testing(split)
    
    ## yTest and yTrain
    yTrain=dataTrain$response                                    #create array of just response values from training and testing set
    yTest=dataTest$response
    
    ## BRT
    set.seed(1)
    gbmOut=gbm(response ~ . ,data=dataTrain,                     #y~x; gbmOut contains list of 29 elements including train.error and valid.error referenced later in gbm.perf()
               n.trees=hgrid$n.trees[row],                       #total number of trees to fit (number of iterations; default is 100)
               distribution="bernoulli",
               shrinkage=hgrid$shrinkage[row],                   #equiv to learning rate or step-size reduction (smaller learning rate requires more trees, default is 0.1)
               interaction.depth=hgrid$interaction.depth[row],   #max depth of each tree (highest level of variable interactions allowed; default is 1)
               n.minobsinnode=hgrid$n.minobsinnode[row],         #min. number of obs in terminal nodes of trees
               cv.folds=5,class.stratify.cv=TRUE,                #no. of cross-val folds to perform; for cv.folds>1, returns estimate of generalization error in 'cv.error'
               bag.fraction=0.5,train.fraction=1,                #fraction of training set obs randomly selected to propose next tree in expansion - this is why we set.seed()
               n.cores=5,                                        #no. of CPU cores to use
               verbose=F)
               # par.details=(gbmParallel(num_threads=5)),
    
    ## performance
    par(mfrow=c(1,1),mar=c(4,4,1,1))                             #sets graphical parameters such that subsequent figure are drawn in a nr-by-nc array by mfrows respectively and gives the number of lines of margin to be specified on the four sides of the plot c(bottom, L, top, R) -> see 'best.iter' plot below 
    best.iter=gbm.perf(gbmOut,method="cv")                       #estimates optimal number of boosting iterations and plots 'training.error' performance measure; cv method extracts this optimal number using cross-validation
    
    ## predict with test data
    preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")  #number of trees based on the optimal number of boosting iterations as set above (5,352) 

    ## known
    result=dataTest$response
    
    # ##estimate threshold value for classification of predicted probability
    # #library(pROC)
    # analysis <- roc(result,preds)  #roc([actual values],[predicted values])
    # e <- cbind(analysis$thresholds,analysis$sensitivities+analysis$specificities) #pulls each array and binds them into dataframe: 1st column are thresholds, 2nd column are sensitivities + specificities
    # 
    # ##optimum threshold value
    # opt_t <- subset(e,e[,2]==max(e[,2]))[,1] #subsets dataframe and returns the max (sens+spec) value of 2nd column of e 
    # #threshold<-opt_t #set as threshold value
    # #threshold = 0.2
    
    ## sensitivity and specificity                              #e.g., test run produced sensitivity of 0 b/c no predictedScores were > 0.5; and specificity of 1 b/c all predictedScores were <0.5
    sen=InformationValue::sensitivity(result,preds)              #calculates sensitivity (# of obs with event AND predicted to have event, divided by # of obs w/ event) for a given logit model where input is the actual binary flag (as numerica vector) for the response variable and the predicted probability scores for each observation; if predicted value is above the threshold (defaults to 0.5), it will be considered an event (1) or else a non-event (0)
    spec=InformationValue::specificity(result,preds)             #calculates specificity (# of obs w/o event AND predicted to not have event, divided by # of obs w/o event)  
    
    ## AUC on train
    auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))   #compute Information Retrieval measures for pairwise loss for a single group, where input is the observed value and the predicted value
    
    ## AUC on test
    auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
    
    ## print
    print(paste("hpar row ",row," done; test AUC is ",auc_test,sep=""))  #prints "hpar row [x] done; test AUC is []"
    
    ## save outputs
    return(list(best=best.iter,                    #saves optimal number of iterations, AUC on training set, AUC on testing set, specificity, sensitivity, and row number as a list
                trainAUC=auc_train,
                testAUC=auc_test,
                spec=spec,
                sen=sen,
                wrow=row))
  }
  
  ## run the function for PCR
  hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="pcr"))
  
  ## get results
  hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
                      sapply(hpars,function(x) x$testAUC),
                      sapply(hpars,function(x) x$spec),
                      sapply(hpars,function(x) x$sen),
                      sapply(hpars,function(x) x$wrow),
                      sapply(hpars,function(x) x$best))
  names(hresults)=c("trainAUC","testAUC",
                    "spec","sen","row","best")
  
  ## combine and save
  hsearch=merge(hresults,hgrid,by="row")
  
  ## save
  hsearch$type="PCR"
  
  ## rerun the function for competence
  hpars=lapply(1:nrow(hgrid),function(x) hfit(x,response="competence"))
  
  ## get results
  hresults=data.frame(sapply(hpars,function(x) x$trainAUC),
                      sapply(hpars,function(x) x$testAUC),
                      sapply(hpars,function(x) x$spec),
                      sapply(hpars,function(x) x$sen),
                      sapply(hpars,function(x) x$wrow),
                      sapply(hpars,function(x) x$best))
  names(hresults)=c("trainAUC","testAUC",
                    "spec","sen","row","best")
  
  ## combine and save
  csearch=merge(hresults,hgrid,by="row")
  
  ## assign data type
  csearch$type="competence"
  
  ## combine
  search=rbind.data.frame(csearch,hsearch)
  search$type=factor(search$type,levels=c("PCR","competence"))
  
  ## export
  write.csv(search,"figures/other/hosttrait/par_tuning_data_summary.csv")
  
  # ## If running on HPC, export to Output folder
  # write.csv(search,"Output/par_tuning_data_summary.csv")
  
}else{
  
  ## load
  search=read.csv("figures/other/hosttrait/par_tuning_data_summary.csv")
  
  # ## If running on HPC, load from Output folder
  # search=read.csv("Output/par_tuning_data_summary.csv")

}

```

### *Assess model tuning results*
We fit a beta regression model using mgcv::gam to explore the main and interaction effects of tuning parameters, interaction depth and shrinkage, on performance metrics: AUC, sensitivity, and specificity. This model is appropriate for analyzing continuous response variables bounded b/w 0-1 (i.e., beta distributions). Using ANOVA, we determine whether the coefficients b/w the two interaction depths, the two shrinkage rates, and the four possible interactions b/w them are significantly different. We then plot the performance of BRTs based on various parameter combinations. Finally, we assess the distribution of best.iter (optimal # of iterations) to determine the max # of trees to use for model training.
Figure: *boxplot_brt_tuning.png*

```{r brt_tuning_results}

# Load model tuning results
search=read.csv("figures/other/hosttrait/par_tuning_data_summary.csv")

# # If running on HPC, load model tuning results from Output folder
# search=read.csv("Output/par_tuning_data_summary.csv")

# Convert parameters to factor and relabel values
search$shrinkage=factor(search$shrinkage)  
lvl=rev(sort(unique(search$shrinkage)))    #sorts unique shrinkage par from large to small
search$shrinkage=factor(search$shrinkage,levels=lvl); rm(lvl)  #applies as factor
search$interaction.depth=factor(search$interaction.depth)
search$type=plyr::revalue(search$type,     #replace specified values w/ new values
                          c("PCR"="RT-PCR",
                            "competence"="virus isolation"))

# Fit beta regression model to the test AUCs of our PCR-based BRTs; ANOVA
mod=gam(testAUC~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to test AUCs of our competence-based BRTs; ANOVA
mod=gam(testAUC~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to sensitivities of our PCR-based BRTs; ANOVA
mod=gam(sen~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to sensitivities of our competence-based BRTs; ANOVA
mod=gam(sen~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to specificities of our PCR-based BRTs; ANOVA
mod=gam(spec~interaction.depth*shrinkage,
        data=search[search$type=="RT-PCR",],method="REML",family=betar)
anova(mod)

# Fit beta regression model to specificities of our competence-based BRTs; ANOVA
mod=gam(spec~interaction.depth*shrinkage,
        data=search[search$type=="virus isolation",],method="REML",family=betar)
anova(mod)

# To plot model tuning performance, transform dataframe from wide to long
search_long=gather(search,measure,value,testAUC:sen)

# Relabel values and convert to factor 
search_long$measure=plyr::revalue(search_long$measure,
                              c("sen"="sensitivity",  
                                "spec"="specificity",
                                "testAUC"="test AUC"))
search_long$measure=factor(search_long$measure,
                       levels=c("test AUC","sensitivity","specificity"))

# Boxplot performance of model tuning w/ various parameter combinations
png("figures/supplementary/s10fig_boxplot_brt_tuning_hosttrait.png",width=5,height=8,units="in",res=600)
set.seed(1)
ggplot(search_long,aes(shrinkage,value,
                   colour=interaction.depth,fill=interaction.depth))+
  geom_boxplot(alpha=0.25)+
  geom_point(alpha=0.75,
             position = position_jitterdodge(dodge.width=0.75))+
  theme_bw()+
  theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank())+
  theme(axis.title.x=element_text(margin=margin(t=10,r=0,b=0,l=0)))+
  theme(axis.title.y=element_text(margin=margin(t=0,r=10,b=0,l=0)))+
  facet_grid(measure~type,scales="free_y",switch="y")+
  theme(strip.placement="outside",
        strip.background=element_blank())+
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12),
        strip.text=element_text(size=12))+
  theme(legend.position="top")+
  scale_color_viridis(discrete=TRUE,option="D")+
  scale_fill_viridis(discrete=TRUE,option="D")+
  guides(colour=guide_legend(title="interaction depth"),
         fill=guide_legend(title="interaction depth"))+
  labs(y=NULL,
       x="learning rate")+
  scale_y_continuous(n.breaks=4)
dev.off()

# To determine optimal parameters for model training, subset tuning results by number of trees
search_nt5000 <- search[search$n.trees==5000,]
search_nt15000 <- search[search$n.trees==15000,]
search_nt5000_sh0.01 <- search_nt5000[search_nt5000$shrinkage==0.010,]  #subset models with shrinkage==0.010
search_nt5000_sh0.001 <- search_nt5000[search_nt5000$shrinkage==0.001,]  #subset models with shrinkage==0.010

# Plot best.iter by evidence type (pcr vs. virus isolation) to see max number of trees to include
search_nt5000 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt15000 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt5000_sh0.01 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 
search_nt5000_sh0.001 %>%
  ggplot( aes(x=best, fill=type)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
  scale_fill_manual(values=c("#69b3a2", "#404080")) 

# Clean
rm(search,search_long,hok,mod,search_nt5000,search_nt15000,search_nt5000_sh0.01, search_nt5000_sh0.001)

```

### *BRT function for applying across multiple data partitions*
We create our BRT function for model training, where we apply the function across multiple data partitions.

```{r brt_partition}

# BRT function to use different data partitions
brt_part=function(seed,response){
  
  ## Make new dataset
  ndata=set
  
  ## Correct response variable
  ndata$response=ndata[response][,1]
  
  ## Remove raw response variables
  ndata$pcr=NULL
  ndata$competence=NULL
  
  ## For BRT where cites is the response variable...
  if(response=="cites"){
    
    ## We add 1 to cites if cites equals 0
    ndata$cites=ifelse(ndata$cites==0,1,ndata$cites)
    
  }else{
    
    ndata=ndata
    
  }
  
  ## Use rsample package to split data
  set.seed(seed)
  split=initial_split(ndata,prop=0.7,strata="response")
  
  ## Create test and train datasets
  dataTrain=training(split)
  dataTest=testing(split)
  
  ## Get response variable for test dataset and train dataset
  yTrain=dataTrain$response
  yTest=dataTest$response
  
  ## Save distribution
  dist=ifelse(response=="cites","poisson","bernoulli")
  
  ## Save number of trees based on previous plots of optimal iterations
  nt=ifelse(response=="cites",10000,
     ifelse(response=="pcr",4500,5000)) #see plots of best.iter 
  
  ## Run BRTs using gbm package
  set.seed(1)
  gbmOut=gbm(response ~ . ,data=dataTrain,
             n.trees=nt,
             distribution=dist,
             shrinkage=0.01, #see plots of best.iter 
             interaction.depth=3,
             n.minobsinnode=4,
             cv.folds=5,class.stratify.cv=TRUE,
             bag.fraction=0.5,train.fraction=1,
             n.cores=5,
             verbose=F)
            # par.details=(gbmParallel(num_threads=5)),

  ## Get optimal number of iterations using gbm.perf & set plotting parameters for performance chart generated by gbm.perf
  par(mfrow=c(1,1),mar=c(4,4,1,1))                         
  best.iter=gbm.perf(gbmOut,method="cv")  #estimates optimal number of boosting iterations for a gbm object     
  
  ## Predict with test data, applying the optimal number of iterations as n.trees
  preds=predict(gbmOut,dataTest,n.trees=best.iter,type="response")
  
  ## Save known associations
  result=dataTest$response
  
  ## Get sensitivity and specificity
  sen=InformationValue::sensitivity(result,preds)
  spec=InformationValue::specificity(result,preds)
  
  ## Get AUC from model training
  auc_train=gbm.roc.area(yTrain,predict(gbmOut,dataTrain,n.trees=best.iter,type="response"))
  
  ## Get AUC from model test
  auc_test=gbm.roc.area(yTest,predict(gbmOut,dataTest,n.trees=best.iter,type="response"))
  
  ## Skip if poisson
  if(response=="cites"){
    
    perf=NA
    
  }else{
    
    ## Inner loop if yTest is all 0
    if(var(yTest)==0){
      
      perf=NA
    }else{
      
      ## To construct an ROC curve, create a prediction object using the predicted probabilities and the true class labels (known responses)
      pr=prediction(preds,dataTest$response)    
      
      ## Next, calculate the desired performance measures specified by the 'measures' argument
      perf=performance(pr,measure="tpr",x.measure="fpr")         #pr=prediction object; measure=performance measure for evaluation; x.measure=second perf measure (2-D)
      
      ## Create a dataframe of those performance values
      perf=data.frame(perf@x.values,perf@y.values)
      
      ## Rename columns
      names(perf)=c("fpr","tpr")
      
      ## Add seed
      perf$seed=seed
      
    }
  }
  
  ## Get relative importance
  bars=summary(gbmOut,n.trees=best.iter,plotit=F)
  bars$rel.inf=round(bars$rel.inf,2)

  ## Predict with cites
  preds=predict(gbmOut,data,n.trees=best.iter,type="response")
  pred_data=data[c("gtip",'treename',"fam","ord","pcr","competence")]
  pred_data$pred=preds
  pred_data$type=response
  
  ## Predict with mean cites
  pdata=data
  pdata$cites=mean(pdata$cites)
  pred_data$cpred=predict(gbmOut,pdata,n.trees=best.iter,type="response")
  
  ## Sort by decreasing predicted probability
  pred_data=pred_data[order(pred_data$pred,decreasing=T),]
  
  ## Print
  print(paste("BRT ",seed," done; test AUC = ",auc_test,sep=""))
  
  ## Save outputs
  return(list(mod=gbmOut,
              best=best.iter,
              trainAUC=auc_train,
              testAUC=auc_test,
              spec=spec,
              sen=sen,
              roc=perf,
              rinf=bars,
              predict=pred_data,
              traindata=dataTrain,
              testdata=dataTest,
              seed=seed))
}

```

### *Apply BRT function across 100 partitions to generate ensemble*

```{r brt_ensemble}

# Apply across 100 splits each
smax=100
pcr_brts=lapply(1:(smax-1),function(x) brt_part(seed=x,response="pcr"))
comp_brts=lapply(1:(smax-1),function(x) brt_part(seed=x,response="competence"))

# Run wos brts
pm_brts=lapply(1:(smax-1),function(x) brt_part(seed=x,response="cites"))

# Note: we sequence from 1:(smax-1) b/c for some reason, the commands generates an extra BRT model (101) if we do not minus one.

# Save results to data folder
saveRDS(pcr_brts, "data/pcr_brts.rds")
saveRDS(comp_brts, "data/comp_brts.rds")
saveRDS(pm_brts, "data/pm_brts.rds")

# # If running on HPC, save results to Output folder
# saveRDS(pcr_brts, "Output/pcr_brts.rds")
# saveRDS(comp_brts, "Output/comp_brts.rds")
# saveRDS(pm_brts, "Output/pm_brts.rds")

```